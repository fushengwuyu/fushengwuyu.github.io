<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  
  <title>Hexo</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <meta name="description" content="1. 准备模型使用tf.keras训练一个简单的线性回归模型，保存为protobuf文件。 1234567891011121314151617181920212223242526272829303132import tensorflow as tffrom tensorflow.keras import models,layers,optimizers## 样本数量n &#x3D; 800## 生成测试用数">
<meta property="og:type" content="article">
<meta property="og:title" content="Hexo">
<meta property="og:url" content="http://example.com/2021/07/20/tensorflow%20serving/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:description" content="1. 准备模型使用tf.keras训练一个简单的线性回归模型，保存为protobuf文件。 1234567891011121314151617181920212223242526272829303132import tensorflow as tffrom tensorflow.keras import models,layers,optimizers## 样本数量n &#x3D; 800## 生成测试用数">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="http://example.com/home/sunshine/Documents/%E5%8D%9A%E5%AE%A2/assets/1584583823994.png">
<meta property="og:image" content="http://example.com/home/sunshine/Documents/%E5%8D%9A%E5%AE%A2/assets/1584585981550.png">
<meta property="og:image" content="https://gitee.com/fushengwuyu1993/images/raw/master/imgs/1584608837466.png">
<meta property="article:published_time" content="2021-07-20T02:01:26.997Z">
<meta property="article:modified_time" content="2021-07-20T02:01:23.593Z">
<meta property="article:author" content="John Doe">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://example.com/home/sunshine/Documents/%E5%8D%9A%E5%AE%A2/assets/1584583823994.png">
  
    <link rel="alternate" href="/atom.xml" title="Hexo" type="application/atom+xml">
  
  
    <link rel="shortcut icon" href="/favicon.png">
  
  
    
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/typeface-source-code-pro@0.0.71/index.min.css">

  
  
<link rel="stylesheet" href="/css/style.css">

  
    
<link rel="stylesheet" href="/fancybox/jquery.fancybox.min.css">

  
<meta name="generator" content="Hexo 5.4.0"></head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">Hexo</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://example.com"></form>
      </div>
    </div>
  </div>
</header>

      <div class="outer">
        <section id="main"><article id="post-tensorflow serving" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2021/07/20/tensorflow%20serving/" class="article-date">
  <time class="dt-published" datetime="2021-07-20T02:01:26.997Z" itemprop="datePublished">2021-07-20</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h5 id="1-准备模型"><a href="#1-准备模型" class="headerlink" title="1. 准备模型"></a>1. 准备模型</h5><p>使用tf.keras训练一个简单的线性回归模型，保存为protobuf文件。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras <span class="keyword">import</span> models,layers,optimizers</span><br><span class="line"></span><br><span class="line"><span class="comment">## 样本数量</span></span><br><span class="line">n = <span class="number">800</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## 生成测试用数据集</span></span><br><span class="line">X = tf.random.uniform([n,<span class="number">2</span>],minval=-<span class="number">10</span>,maxval=<span class="number">10</span>) </span><br><span class="line">w0 = tf.constant([[<span class="number">2.0</span>],[-<span class="number">1.0</span>]])</span><br><span class="line">b0 = tf.constant(<span class="number">3.0</span>)</span><br><span class="line"></span><br><span class="line">Y = X@w0 + b0 + tf.random.normal([n,<span class="number">1</span>],</span><br><span class="line">    mean = <span class="number">0.0</span>,stddev= <span class="number">2.0</span>) <span class="comment"># @表示矩阵乘法,增加正态扰动</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## 建立模型</span></span><br><span class="line">tf.keras.backend.clear_session()</span><br><span class="line">inputs = layers.Input(shape = (<span class="number">2</span>,),name =<span class="string">&quot;inputs&quot;</span>) <span class="comment">#设置输入名字为inputs</span></span><br><span class="line">outputs = layers.Dense(<span class="number">1</span>, name = <span class="string">&quot;outputs&quot;</span>)(inputs) <span class="comment">#设置输出名字为outputs</span></span><br><span class="line">linear = models.Model(inputs = inputs,outputs = outputs)</span><br><span class="line">linear.summary()</span><br><span class="line"></span><br><span class="line"><span class="comment">## 使用fit方法进行训练</span></span><br><span class="line">linear.<span class="built_in">compile</span>(optimizer=<span class="string">&quot;rmsprop&quot;</span>,loss=<span class="string">&quot;mse&quot;</span>,metrics=[<span class="string">&quot;mae&quot;</span>])</span><br><span class="line">linear.fit(X,Y,batch_size = <span class="number">8</span>,epochs = <span class="number">100</span>)  </span><br><span class="line"></span><br><span class="line">tf.<span class="built_in">print</span>(<span class="string">&quot;w = &quot;</span>,linear.layers[<span class="number">1</span>].kernel)</span><br><span class="line">tf.<span class="built_in">print</span>(<span class="string">&quot;b = &quot;</span>,linear.layers[<span class="number">1</span>].bias)</span><br><span class="line"></span><br><span class="line"><span class="comment">## 将模型保存成pb格式文件</span></span><br><span class="line">export_path = <span class="string">&quot;linear_model/&quot;</span></span><br><span class="line">version = <span class="string">&quot;1&quot;</span>       <span class="comment">#后续可以通过版本号进行模型版本迭代与管理</span></span><br><span class="line">linear.save(export_path+version, save_format=<span class="string">&quot;tf&quot;</span>) </span><br></pre></td></tr></table></figure>

<p>查看模型</p>
<blockquote>
<p>saved_model_cli show –dir=’linear_model/1’ –all</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br></pre></td><td class="code"><pre><span class="line">MetaGraphDef <span class="keyword">with</span> tag-<span class="built_in">set</span>: <span class="string">&#x27;serve&#x27;</span> contains the following SignatureDefs:</span><br><span class="line"></span><br><span class="line">signature_def[<span class="string">&#x27;__saved_model_init_op&#x27;</span>]:</span><br><span class="line">  The given SavedModel SignatureDef contains the following <span class="built_in">input</span>(s):</span><br><span class="line">  The given SavedModel SignatureDef contains the following output(s):</span><br><span class="line">    outputs[<span class="string">&#x27;__saved_model_init_op&#x27;</span>] tensor_info:</span><br><span class="line">        dtype: DT_INVALID</span><br><span class="line">        shape: unknown_rank</span><br><span class="line">        name: NoOp</span><br><span class="line">  Method name <span class="keyword">is</span>: </span><br><span class="line"></span><br><span class="line">signature_def[<span class="string">&#x27;serving_default&#x27;</span>]:   <span class="comment"># 注意signature_def</span></span><br><span class="line">  The given SavedModel SignatureDef contains the following <span class="built_in">input</span>(s):</span><br><span class="line">    inputs[<span class="string">&#x27;inputs&#x27;</span>] tensor_info:   <span class="comment"># 注意inputs</span></span><br><span class="line">        dtype: DT_FLOAT</span><br><span class="line">        shape: (-<span class="number">1</span>, <span class="number">2</span>)</span><br><span class="line">        name: serving_default_inputs:<span class="number">0</span></span><br><span class="line">  The given SavedModel SignatureDef contains the following output(s):</span><br><span class="line">    outputs[<span class="string">&#x27;outputs&#x27;</span>] tensor_info:</span><br><span class="line">        dtype: DT_FLOAT</span><br><span class="line">        shape: (-<span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">        name: StatefulPartitionedCall:<span class="number">0</span></span><br><span class="line">  Method name <span class="keyword">is</span>: tensorflow/serving/predict</span><br><span class="line">WARNING:tensorflow:From /usr/local/lib/python3<span class="number">.6</span>/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:<span class="number">1786</span>: calling BaseResourceVariable.__init__ (<span class="keyword">from</span> tensorflow.python.ops.resource_variable_ops) <span class="keyword">with</span> constraint <span class="keyword">is</span> deprecated <span class="keyword">and</span> will be removed <span class="keyword">in</span> a future version.</span><br><span class="line">Instructions <span class="keyword">for</span> updating:</span><br><span class="line">If using Keras <span class="keyword">pass</span> *_constraint arguments to layers.</span><br><span class="line"></span><br><span class="line">Defined Functions:</span><br><span class="line">  Function Name: <span class="string">&#x27;__call__&#x27;</span></span><br><span class="line">    Option <span class="comment">#1</span></span><br><span class="line">      <span class="type">Callable</span> <span class="keyword">with</span>:</span><br><span class="line">        Argument <span class="comment">#1</span></span><br><span class="line">          inputs: TensorSpec(shape=(<span class="literal">None</span>, <span class="number">2</span>), dtype=tf.float32, name=<span class="string">&#x27;inputs&#x27;</span>)</span><br><span class="line">        Argument <span class="comment">#2</span></span><br><span class="line">          DType: <span class="built_in">bool</span></span><br><span class="line">          Value: <span class="literal">True</span></span><br><span class="line">        Argument <span class="comment">#3</span></span><br><span class="line">          DType: NoneType</span><br><span class="line">          Value: <span class="literal">None</span></span><br><span class="line">    Option <span class="comment">#2</span></span><br><span class="line">      <span class="type">Callable</span> <span class="keyword">with</span>:</span><br><span class="line">        Argument <span class="comment">#1</span></span><br><span class="line">          inputs: TensorSpec(shape=(<span class="literal">None</span>, <span class="number">2</span>), dtype=tf.float32, name=<span class="string">&#x27;inputs&#x27;</span>)</span><br><span class="line">        Argument <span class="comment">#2</span></span><br><span class="line">          DType: <span class="built_in">bool</span></span><br><span class="line">          Value: <span class="literal">False</span></span><br><span class="line">        Argument <span class="comment">#3</span></span><br><span class="line">          DType: NoneType</span><br><span class="line">          Value: <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">  Function Name: <span class="string">&#x27;_default_save_signature&#x27;</span></span><br><span class="line">    Option <span class="comment">#1</span></span><br><span class="line">      <span class="type">Callable</span> <span class="keyword">with</span>:</span><br><span class="line">        Argument <span class="comment">#1</span></span><br><span class="line">          inputs: TensorSpec(shape=(<span class="literal">None</span>, <span class="number">2</span>), dtype=tf.float32, name=<span class="string">&#x27;inputs&#x27;</span>)</span><br><span class="line"></span><br><span class="line">  Function Name: <span class="string">&#x27;call_and_return_all_conditional_losses&#x27;</span></span><br><span class="line">    Option <span class="comment">#1</span></span><br><span class="line">      <span class="type">Callable</span> <span class="keyword">with</span>:</span><br><span class="line">        Argument <span class="comment">#1</span></span><br><span class="line">          inputs: TensorSpec(shape=(<span class="literal">None</span>, <span class="number">2</span>), dtype=tf.float32, name=<span class="string">&#x27;inputs&#x27;</span>)</span><br><span class="line">        Argument <span class="comment">#2</span></span><br><span class="line">          DType: <span class="built_in">bool</span></span><br><span class="line">          Value: <span class="literal">False</span></span><br><span class="line">        Argument <span class="comment">#3</span></span><br><span class="line">          DType: NoneType</span><br><span class="line">          Value: <span class="literal">None</span></span><br><span class="line">    Option <span class="comment">#2</span></span><br><span class="line">      <span class="type">Callable</span> <span class="keyword">with</span>:</span><br><span class="line">        Argument <span class="comment">#1</span></span><br><span class="line">          inputs: TensorSpec(shape=(<span class="literal">None</span>, <span class="number">2</span>), dtype=tf.float32, name=<span class="string">&#x27;inputs&#x27;</span>)</span><br><span class="line">        Argument <span class="comment">#2</span></span><br><span class="line">          DType: <span class="built_in">bool</span></span><br><span class="line">          Value: <span class="literal">True</span></span><br><span class="line">        Argument <span class="comment">#3</span></span><br><span class="line">          DType: NoneType</span><br><span class="line">          Value: <span class="literal">None</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>注意：请牢记上面的signature_def值和inputs值及其shape，在grpc调用的时候需要用到。</p>
<h5 id="2-tensorflow-serving-docker方式安装"><a href="#2-tensorflow-serving-docker方式安装" class="headerlink" title="2. tensorflow/serving docker方式安装"></a>2. tensorflow/serving docker方式安装</h5><ol>
<li><p>拉取镜像</p>
<blockquote>
<p> docker pull tensorflow/serving:latest</p>
</blockquote>
<p>在docker hub中有四中镜像。</p>
<ul>
<li>:latest</li>
<li>:lasest-gpu</li>
<li>:lasest-devel</li>
<li>:lasest-devel-gpu</li>
</ul>
<p>两种划分共有4种镜像。CPU、GPU、稳定版、开发版。稳定版在dockerfile中启动tensorflow_model_server服务，创建容器即启动服务。开发版需要在创建容器之后，进入容器，手动启动tensorflow_model_server服务。</p>
<p>以下都已稳定版为例。</p>
</li>
<li><p>启动容器</p>
<blockquote>
<p>docker run -t -p 8501:8501 -p 8500:8500 -v /root/mutimodel/linear_model:/models/linear_model -e MODEL_NAME=linear_model tensorflow/serving</p>
</blockquote>
<p> ==备注：路径只需到模型这一级，不能精确到版本级别，比如：/root/mutimodel/linear_model而不是/root/mutimodel/linear_model/1，服务会默认加载最大版本号的模型。==</p>
<p> 参数解释：</p>
<ul>
<li><p>-p : 端口映射，tensorflow serving提供了两种调用方式：gRPC和REST，<br>gRPC的默认端口是8500，REST的默认端口是8501.</p>
</li>
<li><p>-v：目录映射，需要注意的是，在新版的docker中，已经移除了–mount type=bind,source=%source_path,target=$target_path的挂载目录方式。</p>
</li>
<li><p>-e：设置变量。</p>
<ul>
<li>可选参数: MODLE_NAME（默认值：model）</li>
<li>可选参数：MODEL_BASE_PATH（默认值/models）</li>
</ul>
<p>启动容器之后，相当于在容器中启动服务：</p>
<blockquote>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tensorflow_model_server --port=8500 --rest_api_port=8501 --model_name=$&#123;MODEL_NAME&#125; --model_base_path=$&#123;MODEL_BASE_PATH&#125;/$&#123;MODEL_NAME&#125;</span><br></pre></td></tr></table></figure></blockquote>
</li>
</ul>
<p> 如果需要修改相关参数配置，可以通过如下命令：</p>
<blockquote>
<p>docker run -p 8501:8501 -v /root/mutimodel/linear_model:/models/linear_model -t –entrypoint=tensorflow_model_server tensorflow/serving  –port=8500 –model_name=linear_model –model_base_path=/models/linear_model –rest_api_port=8501</p>
</blockquote>
<p> 参数解释：</p>
<ul>
<li>-t –entrypoint=tensorflow_model_server tensorflow/serving：如果使用稳定版的docker，启动docker之后是不能进入容器内部bash环境的，–entrypoint的作用是允许你“间接”进入容器内部，然后调用tensorflow_model_server命令来启动TensorFlow Serving，这样才能输入后面的参数。</li>
</ul>
<p> tensorflow serving的详细参数如下：</p>
 <figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">Flags:</span><br><span class="line">    --port=8500                         int32   Port to listen on for gRPC API</span><br><span class="line">    --grpc_socket_path=&quot;&quot;               string  If non-empty, listen to a UNIX socket for gRPC API on the given path. Can be either relative or absolute path.</span><br><span class="line">    --rest_api_port=0                   int32   Port to listen on for HTTP/REST API. If set to zero HTTP/REST API will not be exported. This port must be different than the one specified in --port.</span><br><span class="line">    --rest_api_num_threads=16           int32   Number of threads for HTTP/REST API processing. If not set, will be auto set based on number of CPUs.</span><br><span class="line">    --rest_api_timeout_in_ms=30000      int32   Timeout for HTTP/REST API calls.</span><br><span class="line">    --enable_batching=false             bool    enable batching</span><br><span class="line">    --batching_parameters_file=&quot;&quot;       string  If non-empty, read an ascii BatchingParameters protobuf from the supplied file name and use the contained values instead of the defaults.</span><br><span class="line">    --model_config_file=&quot;&quot;              string  If non-empty, read an ascii ModelServerConfig protobuf from the supplied file name, and serve the models in that file. This config file can be used to specify multiple models to serve and other advanced parameters including non-default version policy. (If used, --model_name, --model_base_path are ignored.)</span><br><span class="line">    --model_name=&quot;default&quot;              string  name of model (ignored if --model_config_file flag is set)</span><br><span class="line">    --model_base_path=&quot;&quot;                string  path to export (ignored if --model_config_file flag is set, otherwise required)</span><br><span class="line">    --max_num_load_retries=5            int32   maximum number of times it retries loading a model after the first failure, before giving up. If set to 0, a load is attempted only once. Default: 5</span><br><span class="line">    --load_retry_interval_micros=60000000   int64   The interval, in microseconds, between each servable load retry. If set negative, it doesn&#x27;t wait. Default: 1 minute</span><br><span class="line">    --file_system_poll_wait_seconds=1   int32   Interval in seconds between each poll of the filesystem for new model version. If set to zero poll will be exactly done once and not periodically. Setting this to negative value will disable polling entirely causing ModelServer to indefinitely wait for a new model at startup. Negative values are reserved for testing purposes only.</span><br><span class="line">    --flush_filesystem_caches=true      bool    If true (the default), filesystem caches will be flushed after the initial load of all servables, and after each subsequent individual servable reload (if the number of load threads is 1). This reduces memory consumption of the model server, at the potential cost of cache misses if model files are accessed after servables are loaded.</span><br><span class="line">    --tensorflow_session_parallelism=0  int64   Number of threads to use for running a Tensorflow session. Auto-configured by default.Note that this option is ignored if --platform_config_file is non-empty.</span><br><span class="line">    --tensorflow_intra_op_parallelism=0 int64   Number of threads to use to parallelize the executionof an individual op. Auto-configured by default.Note that this option is ignored if --platform_config_file is non-empty.</span><br><span class="line">    --tensorflow_inter_op_parallelism=0 int64   Controls the number of operators that can be executed simultaneously. Auto-configured by default.Note that this option is ignored if --platform_config_file is non-empty.</span><br><span class="line">    --ssl_config_file=&quot;&quot;                string  If non-empty, read an ascii SSLConfig protobuf from the supplied file name and set up a secure gRPC channel</span><br><span class="line">    --platform_config_file=&quot;&quot;           string  If non-empty, read an ascii PlatformConfigMap protobuf from the supplied file name, and use that platform config instead of the Tensorflow platform. (If used, --enable_batching is ignored.)</span><br><span class="line">    --per_process_gpu_memory_fraction=0.000000  float   Fraction that each process occupies of the GPU memory space the value is between 0.0 and 1.0 (with 0.0 as the default) If 1.0, the server will allocate all the memory when the server starts, If 0.0, Tensorflow will automatically select a value.</span><br><span class="line">    --saved_model_tags=&quot;serve&quot;          string  Comma-separated set of tags corresponding to the meta graph def to load from SavedModel.</span><br><span class="line">    --grpc_channel_arguments=&quot;&quot;         string  A comma separated list of arguments to be passed to the grpc server. (e.g. grpc.max_connection_age_ms=2000)</span><br><span class="line">    --enable_model_warmup=true          bool    Enables model warmup, which triggers lazy initializations (such as TF optimizations) at load time, to reduce first request latency.</span><br><span class="line">    --version=false                     bool    Display version</span><br></pre></td></tr></table></figure>

<p> 容器启动成功。</p>
<blockquote>
<p>…<br>tensorflow_serving/servables/tensorflow/saved_model_warmup.cc:105] No warmup data file found at /models/linear_model/1/assets.extra/tf_serving_warmup_requests<br>2020-03-19 01:25:24.979107: I tensorflow_serving/core/loader_harness.cc:87] Successfully loaded servable version {name: linear_model version: 1}<br>2020-03-19 01:25:24.982357: I tensorflow_serving/model_servers/server.cc:358] Running gRPC ModelServer at 0.0.0.0:8500 …<br>2020-03-19 01:25:24.982960: I tensorflow_serving/model_servers/server.cc:378] Exporting HTTP/REST API at:localhost:8501 …<br>[evhttp_server.cc : 238] NET_LOG: Entering the event loop …</p>
</blockquote>
<p> 可以看到，启动了grpc的8500端口和RESR的8501端口。</p>
</li>
</ol>
<h5 id="2-REST调用"><a href="#2-REST调用" class="headerlink" title="2. REST调用"></a>2. REST调用</h5><ul>
<li></li>
</ul>
<p>​    REST api方式调用很简单，可以通过curl或者postman发送一个post请求，也可以用python的requests模拟一个post请求。这里我们使用postman工具。</p>
<p><img src="/home/sunshine/Documents/%E5%8D%9A%E5%AE%A2/assets/1584583823994.png" alt="1584583823994"></p>
<p>​    可以看到正确返回结果。</p>
<p>​    注意事项：</p>
<ul>
<li>请求参数：“inputs”，这里对应于模型中的signature_def下面的inputs值。</li>
<li>参数形状：参见tensor_info的shape：（-1, 2）。</li>
<li>参数类型：参见tensor_info的dtype：DT_FLOAT（对应于np.float32）</li>
</ul>
<h5 id="3-grpc调用"><a href="#3-grpc调用" class="headerlink" title="3. grpc调用"></a>3. grpc调用</h5><ol>
<li><p>安装相应的包</p>
<blockquote>
<p> pip install tensorflow-serving-api</p>
</blockquote>
</li>
<li><p>编写代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> grpc</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> tensorflow_serving.apis <span class="keyword">import</span> predict_pb2</span><br><span class="line"><span class="keyword">from</span> tensorflow_serving.apis <span class="keyword">import</span> prediction_service_pb2_grpc</span><br><span class="line"></span><br><span class="line">options = [(<span class="string">&#x27;grpc.max_send_message_length&#x27;</span>, <span class="number">1000</span> * <span class="number">1024</span> * <span class="number">1024</span>),</span><br><span class="line">           (<span class="string">&#x27;grpc.max_receive_message_length&#x27;</span>, <span class="number">1000</span> * <span class="number">1024</span> * <span class="number">1024</span>)]</span><br><span class="line"></span><br><span class="line">channel = grpc.insecure_channel(<span class="string">&#x27;ip:8500&#x27;</span>, options=options)</span><br><span class="line">stub = prediction_service_pb2_grpc.PredictionServiceStub(channel)</span><br><span class="line"></span><br><span class="line">x = [[<span class="number">1.0</span>, <span class="number">2.0</span>]]</span><br><span class="line"></span><br><span class="line">request = predict_pb2.PredictRequest()</span><br><span class="line">request.model_spec.name = <span class="string">&quot;linear_model&quot;</span></span><br><span class="line">request.model_spec.signature_name = <span class="string">&#x27;serving_default&#x27;</span></span><br><span class="line">request.inputs[<span class="string">&#x27;inputs&#x27;</span>].CopyFrom(tf.make_tensor_proto(x, shape=(<span class="number">1</span>, <span class="number">2</span>)))</span><br><span class="line">response = stub.Predict(request, <span class="number">10.0</span>)</span><br><span class="line">output = tf.make_ndarray(response.outputs[<span class="string">&quot;outputs&quot;</span>])[<span class="number">0</span>][<span class="number">0</span>]</span><br><span class="line"><span class="built_in">print</span>(output)</span><br></pre></td></tr></table></figure>

<p>注意事项：</p>
<ul>
<li>request.model_spec.name：模型名</li>
<li>request.model_spec.signature_name：必须与模型中定义的一致，参照signature_def值（参见第一节查看模型）</li>
<li>request.inputs[‘inputs’]：inputs的key参见tensor_info的inputs值（第一节查看模型）</li>
</ul>
</li>
</ol>
<h5 id="4-多模型部署"><a href="#4-多模型部署" class="headerlink" title="4. 多模型部署"></a>4. 多模型部署</h5><p>​    单一模型部署，上面的方式即可完成。对于多个模型统一部署，基本流程与单模型一致，不同之处在于需要借助模型的配置文件来完成。</p>
<ol>
<li>model.config</li>
</ol>
<p>新建mutimodel文件夹，放置多个模型，并建一配置文件model.config.</p>
<blockquote>
<p>mutimodel</p>
<p>├── linear_model<br>│   └── 1<br>│       ├── assets<br>│       ├── saved_model.pb<br>│       └── variables<br>│           ├── variables.data-00000-of-00001<br>│           └── variables.index<br>├── model.config<br>├── router_model<br>│   └── 1<br>│       ├── assets<br>│       ├── saved_model.pb<br>│       └── variables<br>│           ├── variables.data-00000-of-00001<br>│           └── variables.index<br>└── textcnn_model<br>    └── 1<br>        ├── assets<br>        ├── saved_model.pb<br>        └── variables<br>            ├── variables.data-00000-of-00001<br>            └── variables.index</p>
<p>12 directories, 10 files</p>
</blockquote>
<p>​    model.conf配置如下：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">model_config_list &#123;</span><br><span class="line">  config &#123;</span><br><span class="line">    name: &#x27;linear&#x27;,</span><br><span class="line">    model_platform: &quot;tensorflow&quot;,</span><br><span class="line">    base_path: &#x27;/models/mutimodel/linear_model&#x27;</span><br><span class="line">  &#125;,</span><br><span class="line">  config &#123;</span><br><span class="line">    name: &#x27;textcnn&#x27;,</span><br><span class="line">    model_platform: &quot;tensorflow&quot;,</span><br><span class="line">    base_path: &#x27;/models/mutimodel/textcnn_model&#x27;</span><br><span class="line">  &#125;,</span><br><span class="line">  config &#123;</span><br><span class="line">    name: &#x27;router&#x27;,</span><br><span class="line">    model_platform: &quot;tensorflow&quot;,</span><br><span class="line">    base_path: &#x27;/models/mutimodel/router_model&#x27;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<ol start="2">
<li>启动容器</li>
</ol>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker run -p 8501:8501 -p 8500:8500 -v /root/mutimodel/:/models/mutimodel  -t tensorflow/serving --model_config_file=/models/mutimodel/model.config</span><br></pre></td></tr></table></figure>

<blockquote>
<p>…<br>2020-03-19 0/models/mutimodel/router_model/1/assets.extra/tf_serving_warmup_requests<br>2020-03-19 02:42:58.197083: I tensorflow_serving/core/loader_harness.cc:87] Successfully loaded servable version {name: router version: 1}<br>2020-03-19 02:42:58.199987: I tensorflow_serving/model_servers/server.cc:358] Running gRPC ModelServer at 0.0.0.0:8500 …<br>2020-03-19 02:42:58.200632: I tensorflow_serving/model_servers/server.cc:378] Exporting HTTP/REST API at:localhost:8501 …<br>[evhttp_server.cc : 238] NET_LOG: Entering the event loop …</p>
</blockquote>
<p>REST api 测试。</p>
<p><img src="/home/sunshine/Documents/%E5%8D%9A%E5%AE%A2/assets/1584585981550.png" alt="1584585981550"></p>
<p>正常访问。</p>
<h5 id="5-版本控制"><a href="#5-版本控制" class="headerlink" title="5. 版本控制"></a>5. 版本控制</h5><ol>
<li><p>服务端配置</p>
<p>tensorflow serving服务默认只会读取最大版本号的版本（按数字来标记版本号），实际上，我们可以通过提供不同的版本的模型，比如提供稳定版、测试版，来实现版本控制，只需要在在配置文件中配置model_version_policy。</p>
<figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">model_config_list &#123;</span><br><span class="line">  config &#123;</span><br><span class="line">    name: &#x27;linear&#x27;,</span><br><span class="line">    model_platform: &quot;tensorflow&quot;,</span><br><span class="line">    base_path: &#x27;/models/mutimodel/linear_model&#x27;</span><br><span class="line">    model_version_policy&#123;</span><br><span class="line">      specific&#123;</span><br><span class="line">            version: 1,</span><br><span class="line">            version: 2</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    version_labels&#123;</span><br><span class="line">        key: &quot;stable&quot;,</span><br><span class="line">        value: 1    </span><br><span class="line">    &#125;</span><br><span class="line">    version_labels&#123;</span><br><span class="line">        key: &quot;test&quot;,</span><br><span class="line">        value: 2    </span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>这里我们同时提供版本号为1和版本号为2的版本，并分别为其取别名stable和test。这样做的好处在于，用户只需要定向到stable或者test版本，而不必关心具体的某个版本号，同时，在不通知用户的情况下，可以调整版本号，比如版本2稳定后，可以升级为稳定版，只需要将stable对应的value改为2即可。同样，若需要版本回滚，将value修改为之前的1即可。</p>
<p>启动服务</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker run -p 8501:8501 -p 8500:8500 -v /root/mutimodel/:/models/mutimodel  -t tensorflow/serving --model_config_file=/models/mutimodel/model.config --allow_version_labels_for_unavailable_models=true</span><br></pre></td></tr></table></figure>

<p>说明：根据官方说明，添加别名只能针对已经加载的模型（先启动服务，再更新配置文件），若想在启动服务的时候设置别名，需要设置allow_version_labels_for_unavailable_models=true。</p>
<p>官方说明如下：</p>
<blockquote>
<p>Please note that labels can only be assigned to model versions that are <em>already</em> loaded and available for serving. Once a model version is available, one may reload the model config on the fly to assign a label to it. This can be achieved using a<a target="_blank" rel="noopener" href="https://github.com/tensorflow/serving/blob/master/tensorflow_serving/apis/model_service.proto#L22">HandleReloadConfigRequest</a> RPC or if the server is set up to periodically poll the filesystem for the config file, as described <a target="_blank" rel="noopener" href="https://www.tensorflow.org/tfx/serving/serving_config#reloading_model_server_configuration">above</a>.</p>
<p>If you would like to assign a label to a version that is not yet loaded (for ex. by supplying both the model version and the label at startup time) then you must set the <code>--allow_version_labels_for_unavailable_models</code> flag to true, which allows new labels to be assigned to model versions that are not loaded yet.</p>
</blockquote>
</li>
<li><p>客户端调用</p>
<p>特别说明：version_label设置别名的方式只适用于grpc调用方式，而不适用与REST调用。</p>
<ul>
<li><p>REST 调用，直接制定版本号。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">curl -d &#x27;&#123;&quot;inputs&quot;:[[1.0, 2.0]]&#125;&#x27; -X POST http://localhost:8501/v1/models/linear/versions/1:predict</span><br><span class="line">&#123;</span><br><span class="line">    &quot;outputs&quot;: [</span><br><span class="line">        [</span><br><span class="line">            2.18523026</span><br><span class="line">        ]</span><br><span class="line">    ]</span><br></pre></td></tr></table></figure></li>
<li><p>gRPC方式</p>
<p>使用别名：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">channel = grpc.insecure_channel(<span class="string">&#x27;49.233.155.170:8500&#x27;</span>)</span><br><span class="line">stub = prediction_service_pb2_grpc.PredictionServiceStub(channel)</span><br><span class="line">x = [[<span class="number">1.0</span>, <span class="number">2.0</span>]]</span><br><span class="line">request = predict_pb2.PredictRequest()</span><br><span class="line">request.model_spec.name = <span class="string">&quot;linear&quot;</span></span><br><span class="line">request.model_spec.version_label = <span class="string">&quot;stable&quot;</span></span><br><span class="line">request.model_spec.signature_name = <span class="string">&#x27;serving_default&#x27;</span></span><br><span class="line">request.inputs[<span class="string">&#x27;inputs&#x27;</span>].CopyFrom(tf.make_tensor_proto(x, shape=(<span class="number">1</span>, <span class="number">2</span>)))</span><br><span class="line">response = stub.Predict(request, <span class="number">10.0</span>)</span><br><span class="line">output = tf.make_ndarray(response.outputs[<span class="string">&quot;outputs&quot;</span>])[<span class="number">0</span>][<span class="number">0</span>]</span><br><span class="line"><span class="built_in">print</span>(output)</span><br></pre></td></tr></table></figure>

<p>使用版本号：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">channel = grpc.insecure_channel(<span class="string">&#x27;49.233.155.170:8500&#x27;</span>)</span><br><span class="line">stub = prediction_service_pb2_grpc.PredictionServiceStub(channel)</span><br><span class="line">x = [[<span class="number">1.0</span>, <span class="number">2.0</span>]]</span><br><span class="line">request = predict_pb2.PredictRequest()</span><br><span class="line">request.model_spec.name = <span class="string">&quot;linear&quot;</span></span><br><span class="line">request.model_spec.version.value = <span class="number">1</span></span><br><span class="line">request.model_spec.signature_name = <span class="string">&#x27;serving_default&#x27;</span></span><br><span class="line">request.inputs[<span class="string">&#x27;inputs&#x27;</span>].CopyFrom(tf.make_tensor_proto(x, shape=(<span class="number">1</span>, <span class="number">2</span>)))</span><br><span class="line">response = stub.Predict(request, <span class="number">10.0</span>)</span><br><span class="line">output = tf.make_ndarray(response.outputs[<span class="string">&quot;outputs&quot;</span>])[<span class="number">0</span>][<span class="number">0</span>]</span><br><span class="line"><span class="built_in">print</span>(output)</span><br></pre></td></tr></table></figure>

<p>==区别：model_spec.version_label与model_spec.version.value。==</p>
</li>
</ul>
</li>
</ol>
<h5 id="6-热更新"><a href="#6-热更新" class="headerlink" title="6. 热更新"></a>6. 热更新</h5><p>服务启动后，可以通过重新加载配置文件的方式来实现模型的热更新。可以通过一下两种方式来实现。</p>
<ol>
<li><p><a target="_blank" rel="noopener" href="https://github.com/tensorflow/serving/blob/master/tensorflow_serving/apis/model_service.proto#L22">HandleReloadConfigRequest</a> （grpc）</p>
<p>比如我们想新增模型textcnn和router。先更新其配置文件model.config为：</p>
<figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">model_config_list &#123;</span><br><span class="line">  config &#123;</span><br><span class="line">    name: &quot;linear&quot;</span><br><span class="line">    base_path: &quot;/models/mutimodel/linear_model&quot;</span><br><span class="line">    model_platform: &quot;tensorflow&quot;</span><br><span class="line">    model_version_policy &#123;</span><br><span class="line">      specific &#123;</span><br><span class="line">        versions: 1</span><br><span class="line">        versions: 2</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    version_labels &#123;</span><br><span class="line">      key: &quot;stable&quot;</span><br><span class="line">      value: 1</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  config &#123;</span><br><span class="line">    name: &quot;textcnn&quot;</span><br><span class="line">    base_path: &quot;/models/mutimodel/textcnn_model&quot;</span><br><span class="line">    model_platform: &quot;tensorflow&quot;</span><br><span class="line">  &#125;</span><br><span class="line">  config &#123;</span><br><span class="line">    name: &quot;router&quot;</span><br><span class="line">    base_path: &quot;/models/mutimodel/router_model&quot;</span><br><span class="line">    model_platform: &quot;tensorflow&quot;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>gRPC代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> google.protobuf <span class="keyword">import</span> text_format</span><br><span class="line"><span class="keyword">from</span> tensorflow_serving.apis <span class="keyword">import</span> model_management_pb2</span><br><span class="line"><span class="keyword">from</span> tensorflow_serving.apis <span class="keyword">import</span> model_service_pb2_grpc</span><br><span class="line"><span class="keyword">from</span> tensorflow_serving.config <span class="keyword">import</span> model_server_config_pb2</span><br><span class="line"></span><br><span class="line">config_file = <span class="string">&quot;model.config&quot;</span></span><br><span class="line">stub = model_service_pb2_grpc.ModelServiceStub(channel)</span><br><span class="line">request = model_management_pb2.ReloadConfigRequest()</span><br><span class="line"></span><br><span class="line"><span class="comment"># # read config file</span></span><br><span class="line">config_content = <span class="built_in">open</span>(config_file, <span class="string">&quot;r&quot;</span>).read()</span><br><span class="line">model_server_config = model_server_config_pb2.ModelServerConfig()</span><br><span class="line">model_server_config = text_format.Parse(text=config_content, message=model_server_config)</span><br><span class="line">request.config.CopyFrom(model_server_config)</span><br><span class="line">request_response = stub.HandleReloadConfigRequest(request, <span class="number">10</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> request_response.status.error_code == <span class="number">0</span>:</span><br><span class="line">    <span class="built_in">open</span>(config_file, <span class="string">&quot;w&quot;</span>).write(<span class="built_in">str</span>(request.config))</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;TF Serving config file updated.&quot;</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;Failed to update config file.&quot;</span>)</span><br><span class="line">        <span class="built_in">print</span>(request_response.status.error_code)</span><br><span class="line">        <span class="built_in">print</span>(request_response.status.error_message)</span><br></pre></td></tr></table></figure>

<p>测试textcnn模型。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">   </span><br><span class="line">(train_data, train_labels), (test_data, test_labels) = datasets.imdb.load_data(num_words=<span class="number">10000</span>)</span><br><span class="line">test_data = pad_sequences(test_data, maxlen=<span class="number">200</span>)</span><br><span class="line">test_data = test_data.astype(np.float32)</span><br><span class="line">request = predict_pb2.PredictRequest()</span><br><span class="line">request.model_spec.name = <span class="string">&#x27;textcnn&#x27;</span></span><br><span class="line">request.model_spec.signature_name = <span class="string">&#x27;serving_default&#x27;</span></span><br><span class="line">request.inputs[<span class="string">&#x27;input_1&#x27;</span>].CopyFrom(tf.make_tensor_proto(np.array(test_data[<span class="number">0</span>]), shape=(<span class="number">1</span>, <span class="number">200</span>)))</span><br><span class="line">   </span><br><span class="line">start = time.time()</span><br><span class="line">response = stub.Predict(request, <span class="number">10.0</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;cost time = &quot;</span>, time.time() - start)</span><br><span class="line">res_from_server_np = tf.make_ndarray(response.outputs[<span class="string">&quot;dense&quot;</span>])[<span class="number">0</span>][<span class="number">0</span>]</span><br><span class="line">label = <span class="number">1</span> <span class="keyword">if</span> res_from_server_np &gt; <span class="number">0.5</span> <span class="keyword">else</span> <span class="number">0</span></span><br><span class="line"><span class="built_in">print</span>(label)</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cost time =  0.1668863296508789</span><br><span class="line">0</span><br></pre></td></tr></table></figure>

<p>模型新增成功。</p>
</li>
<li><p>–model_config_file_poll_wait_seconds</p>
</li>
</ol>
<p>在启动服务的时候，指定重新加载配置文件的时间间隔60s。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker run -p 8501:8501 -p 8500:8500 -v /root/mutimodel/:/models/mutimodel  -t tensorflow/serving --model_config_file=/models/mutimodel/model.config --allow_version_labels_for_unavailable_models=true --model_config_file_poll_wait_seconds=60</span><br></pre></td></tr></table></figure>

<p>立即调用textcnn，可以看到报如下错误。很明显，此时服务并没有加载textcnn模型。</p>
<blockquote>
<p>grpc._channel._Rendezvous: &lt;_Rendezvous of RPC that terminated with:<br>    status = StatusCode.NOT_FOUND<br>    details = “Servable not found for request: Latest(textcnn)”<br>    debug_error_string = “{“created”:”@1584608241.949779831”,”description”:”Error received from peer ipv4:49.233.155.170:8500”,”file”:”src/core/lib/surface/call.cc”,”file_line”:1055,”grpc_message”:”Servable not found for request: Latest(textcnn)”,”grpc_status”:5}”</p>
<blockquote>
</blockquote>
</blockquote>
<p>60s之后，观察到服务出现变化，显示已经加载模型textcnn和router。</p>
<p><img src="https://gitee.com/fushengwuyu1993/images/raw/master/imgs/1584608837466.png" alt="1584608837466"></p>
<p>此时，再次调用textcnn模型</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cost time =  0.1185760498046875</span><br><span class="line">0</span><br></pre></td></tr></table></figure>

<p>正确返回，模型更新成功。</p>
<p>引用：</p>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/zong596568821xp/article/details/102953720">https://blog.csdn.net/zong596568821xp/article/details/102953720</a></p>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/weixin_44899143/article/details/90715186?depth_1-utm_source=distribute.pc_relevant.none-task&amp;utm_source=distribute.pc_relevant.none-task#model_config_file_43">https://blog.csdn.net/weixin_44899143/article/details/90715186?depth_1-utm_source=distribute.pc_relevant.none-task&amp;utm_source=distribute.pc_relevant.none-task#model_config_file_43</a></p>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/JerryZhang__/article/details/86516428">https://blog.csdn.net/JerryZhang__/article/details/86516428</a></p>
<p><a target="_blank" rel="noopener" href="https://stackoverflow.com/questions/54440762/tensorflow-serving-update-model-config-add-additional-models-at-runtime">https://stackoverflow.com/questions/54440762/tensorflow-serving-update-model-config-add-additional-models-at-runtime</a></p>
<p><a target="_blank" rel="noopener" href="https://www.tensorflow.org/tfx/serving/serving_config">https://www.tensorflow.org/tfx/serving/serving_config</a></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2021/07/20/tensorflow%20serving/" data-id="ckrbf91k4000ndao462nx6j0l" data-title="" class="article-share-link">Share</a>
      
      
      
    </footer>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2021/07/20/vim%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          (no title)
        
      </div>
    </a>
  
  
    <a href="/2021/07/20/rasa%E6%96%87%E6%A1%A3/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title"></div>
    </a>
  
</nav>

  
</article>


</section>
        
          <aside id="sidebar">
  
    

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tags</h3>
    <div class="widget">
      <ul class="tag-list" itemprop="keywords"><li class="tag-list-item"><a class="tag-list-link" href="/tags/python/" rel="tag">python</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/" rel="tag">数据库</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E7%AC%94%E8%AE%B0/" rel="tag">笔记</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E8%BF%90%E7%BB%B4/" rel="tag">运维</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tag Cloud</h3>
    <div class="widget tagcloud">
      <a href="/tags/python/" style="font-size: 10px;">python</a> <a href="/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/" style="font-size: 20px;">数据库</a> <a href="/tags/%E7%AC%94%E8%AE%B0/" style="font-size: 10px;">笔记</a> <a href="/tags/%E8%BF%90%E7%BB%B4/" style="font-size: 10px;">运维</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/07/">July 2021</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2021/07/20/pycharm+Ubuntu/">(no title)</a>
          </li>
        
          <li>
            <a href="/2021/07/20/l4t_docker%E9%81%87%E5%88%B0%E7%9A%84%E9%97%AE%E9%A2%98/">(no title)</a>
          </li>
        
          <li>
            <a href="/2021/07/20/docker%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/">(no title)</a>
          </li>
        
          <li>
            <a href="/2021/07/20/%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96%E6%80%BB%E7%BB%93/">(no title)</a>
          </li>
        
          <li>
            <a href="/2021/07/20/%E4%B8%AD%E6%96%87%E6%96%87%E6%9C%AC%E7%BA%A0%E9%94%99%E8%B0%83%E7%A0%94/">(no title)</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      
      &copy; 2021 John Doe<br>
      Powered by <a href="https://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>

    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    


<script src="/js/jquery-3.4.1.min.js"></script>



  
<script src="/fancybox/jquery.fancybox.min.js"></script>




<script src="/js/script.js"></script>





  </div>
</body>
</html>