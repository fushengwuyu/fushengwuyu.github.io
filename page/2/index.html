<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.4.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">
  <link rel="stylesheet" href="//cdn.jsdelivr.net/gh/fancyapps/fancybox@3/dist/jquery.fancybox.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"example.com","root":"/","scheme":"Gemini","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":true,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta property="og:type" content="website">
<meta property="og:title" content="浮生物语的博客">
<meta property="og:url" content="http://example.com/page/2/index.html">
<meta property="og:site_name" content="浮生物语的博客">
<meta property="og:locale" content="zh_CN">
<meta property="article:author" content="sunshine">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="http://example.com/page/2/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : true,
    isPost : false,
    lang   : 'zh-CN'
  };
</script>

  <title>浮生物语的博客</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">浮生物语的博客</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">记录学习</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a>

  </li>
        <li class="menu-item menu-item-commonweal">

    <a href="/404.html/" rel="section"><i class="fa fa-heartbeat fa-fw"></i>公益 404</a>

  </li>
  </ul>
</nav>




</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content index posts-expand">
            
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2021/07/20/pycharm+Ubuntu/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="sunshine">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="浮生物语的博客">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2021/07/20/pycharm+Ubuntu/" class="post-title-link" itemprop="url">pycharm+Ubuntu20.04</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2021-07-20 00:00:00" itemprop="dateCreated datePublished" datetime="2021-07-20T00:00:00+08:00">2021-07-20</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2021-08-20 11:33:17" itemprop="dateModified" datetime="2021-08-20T11:33:17+08:00">2021-08-20</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E8%BF%90%E7%BB%B4/" itemprop="url" rel="index"><span itemprop="name">运维</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>ubuntu20.04 安装pycharm遇到的问题</p>
<ol>
<li><p>pycharm2019.3不能输入中文</p>
<p>无解，网上试过各种办法均不能解决。升级至pycharm2021专业版解决问题，可以输入中文，但是中文提示光标不跟随，一直龟缩在左下角，严重影响体验。</p>
</li>
<li><p>pycharm2021 中文光标不跟随问题</p>
<ul>
<li><p>下载工具：链接: <a target="_blank" rel="noopener" href="https://pan.baidu.com/s/1WLYPbtMfqpaJxcb8YbT1sw">https://pan.baidu.com/s/1WLYPbtMfqpaJxcb8YbT1sw</a>  密码: ddaf</p>
</li>
<li><p>解压</p>
</li>
<li><p>在pycharm的安装目录的pycharm.sh加入已下内容</p>
<p><img src="https://gitee.com/fushengwuyu1993/images/raw/master/imgs/image-20210618150122742.png" alt="image-20210618150122742"></p>
</li>
</ul>
</li>
<li><p>pycharm2021专业版激活</p>
<ul>
<li><p>下载插件：链接: <a target="_blank" rel="noopener" href="https://pan.baidu.com/s/1scwJQySV333_g086NQodVw">https://pan.baidu.com/s/1scwJQySV333_g086NQodVw</a>  密码: pth0</p>
</li>
<li><p>从本地安装插件，不解压，直接选择压缩包</p>
<p><img src="https://gitee.com/fushengwuyu1993/images/raw/master/imgs/image-20210618150328562.png" alt="image-20210618150328562"></p>
</li>
<li><p><code>help-&gt;Eval Reset </code> </p>
</li>
</ul>
<p>​     <img src="https://gitee.com/fushengwuyu1993/images/raw/master/imgs/image-20210618150625417.png" alt="image-20210618150625417"></p>
<p>每次启动ide，会自动重置试用时间。达到无限激活的功能。</p>
</li>
</ol>
<p>​     </p>
<p>​     </p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2021/07/20/rasa%E6%96%87%E6%A1%A3/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="sunshine">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="浮生物语的博客">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2021/07/20/rasa%E6%96%87%E6%A1%A3/" class="post-title-link" itemprop="url">rasa总结文档</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2021-07-20 00:00:00" itemprop="dateCreated datePublished" datetime="2021-07-20T00:00:00+08:00">2021-07-20</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2021-08-20 11:33:31" itemprop="dateModified" datetime="2021-08-20T11:33:31+08:00">2021-08-20</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/NLP/" itemprop="url" rel="index"><span itemprop="name">NLP</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h3 id="1-基本命令"><a href="#1-基本命令" class="headerlink" title="1. 基本命令"></a>1. 基本命令</h3><h4 id="1-1-训练模型"><a href="#1-1-训练模型" class="headerlink" title="1.1 训练模型"></a>1.1 训练模型</h4><p>无论是单独训练，还是2个模型一起训练，均可以使用rasa train命令实现（rasa nlu和rasa core合并为RASA），不同之处在于，提供的训练数据，若同时提供两份数据，则会同时训练nlu和core。</p>
<ul>
<li><p>训练nlu模型</p>
<blockquote>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python -m rasa train --config configs/zh_jieba_supervised_embeddings_config.yml --domain configs/domain.yml --data data/nlu/number_nlu.md data/stories/number_story.md</span><br></pre></td></tr></table></figure></blockquote>
</li>
<li><p>训练core模型</p>
<blockquote>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python -m rasa train --config configs/zh_jieba_supervised_embeddings_config.yml --domain configs/domain.yml --data data/stories/number_story.md</span><br></pre></td></tr></table></figure></blockquote>
</li>
<li><p>一起训练两个模型</p>
<blockquote>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python -m rasa train --config configs/zh_jieba_supervised_embeddings_config.yml --domain configs/domain.yml --data data/nlu/number_nlu.md data/stories/number_story.md</span><br></pre></td></tr></table></figure></blockquote>
</li>
</ul>
<h4 id="1-2-启动rasa"><a href="#1-2-启动rasa" class="headerlink" title="1.2 启动rasa"></a>1.2 启动rasa</h4><ul>
<li><p>不额外独立nlu服务</p>
<blockquote>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python -m rasa run --port 5005 --endpoints configs/endpoints.yml --credentials configs/credentials.yml </span><br></pre></td></tr></table></figure></blockquote>
</li>
<li><p>启动额外nlu服务</p>
<blockquote>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python -m rasa run --port 5005 --endpoints configs/endpoints.yml --credentials configs/credentials.yml --enable-api -m models/nlu-20190515-144445.tar.gz </span><br></pre></td></tr></table></figure></blockquote>
</li>
<li><p>单独启动nlu服务</p>
<blockquote>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rasa run --enable-api -m models/nlu-20190515-144445.tar.gz</span><br></pre></td></tr></table></figure></blockquote>
</li>
<li><p>调用第三方模型服务</p>
<blockquote>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rasa run --enable-api --log-file out.log --endpoints my_endpoints.yml</span><br></pre></td></tr></table></figure>

<p>在my_endpoints.yml中配置rasa模型的url</p>
<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">models:</span><br><span class="line">  url: http:<span class="comment">//my-server.com/models/2019-1222.tar.gz</span></span><br><span class="line">  wait_time_between_pulls: <span class="number">10</span>   # [optional](default: <span class="number">100</span>)</span><br></pre></td></tr></table></figure>

<p>rasa模型还可以存放在<a target="_blank" rel="noopener" href="https://aws.amazon.com/s3/">S3</a> , <a target="_blank" rel="noopener" href="https://cloud.google.com/storage/">GCS</a> and <a target="_blank" rel="noopener" href="https://azure.microsoft.com/services/storage/">Azure Storage</a> 云盘中，同样远程调用，这里不多赘述。</p>
<p><a target="_blank" rel="noopener" href="https://rasa.com/docs/rasa/user-guide/configuring-http-api/">https://rasa.com/docs/rasa/user-guide/configuring-http-api/</a></p>
</blockquote>
</li>
</ul>
<p>nlu服务开启后，post方式调用</p>
<p>post <a target="_blank" rel="noopener" href="http://localhost:5005/model/parse">http://localhost:5005/model/parse</a></p>
<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br></pre></td><td class="code"><pre><span class="line">input:</span><br><span class="line">&#123;<span class="attr">&quot;text&quot;</span>: <span class="string">&quot;明天成都的天气如何&quot;</span>&#125;</span><br><span class="line">output:</span><br><span class="line">&#123;</span><br><span class="line">    <span class="attr">&quot;intent&quot;</span>: &#123;</span><br><span class="line">        <span class="attr">&quot;name&quot;</span>: <span class="string">&quot;request_weather&quot;</span>,</span><br><span class="line">        <span class="attr">&quot;confidence&quot;</span>: <span class="number">0.5547698674</span></span><br><span class="line">    &#125;,</span><br><span class="line">    <span class="attr">&quot;entities&quot;</span>: [</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="attr">&quot;entity&quot;</span>: <span class="string">&quot;date_time&quot;</span>,</span><br><span class="line">            <span class="attr">&quot;value&quot;</span>: <span class="string">&quot;明天&quot;</span>,</span><br><span class="line">            <span class="attr">&quot;start&quot;</span>: <span class="number">0</span>,</span><br><span class="line">            <span class="attr">&quot;end&quot;</span>: <span class="number">2</span>,</span><br><span class="line">            <span class="attr">&quot;confidence&quot;</span>: <span class="literal">null</span>,</span><br><span class="line">            <span class="attr">&quot;extractor&quot;</span>: <span class="string">&quot;MitieEntityExtractor&quot;</span></span><br><span class="line">        &#125;,</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="attr">&quot;entity&quot;</span>: <span class="string">&quot;address&quot;</span>,</span><br><span class="line">            <span class="attr">&quot;value&quot;</span>: <span class="string">&quot;成都&quot;</span>,</span><br><span class="line">            <span class="attr">&quot;start&quot;</span>: <span class="number">2</span>,</span><br><span class="line">            <span class="attr">&quot;end&quot;</span>: <span class="number">4</span>,</span><br><span class="line">            <span class="attr">&quot;confidence&quot;</span>: <span class="literal">null</span>,</span><br><span class="line">            <span class="attr">&quot;extractor&quot;</span>: <span class="string">&quot;MitieEntityExtractor&quot;</span></span><br><span class="line">        &#125;</span><br><span class="line">    ],</span><br><span class="line">    <span class="attr">&quot;intent_ranking&quot;</span>: [</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="attr">&quot;name&quot;</span>: <span class="string">&quot;request_weather&quot;</span>,</span><br><span class="line">            <span class="attr">&quot;confidence&quot;</span>: <span class="number">0.5547698674</span></span><br><span class="line">        &#125;,</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="attr">&quot;name&quot;</span>: <span class="string">&quot;affirm&quot;</span>,</span><br><span class="line">            <span class="attr">&quot;confidence&quot;</span>: <span class="number">0.0898880708</span></span><br><span class="line">        &#125;,</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="attr">&quot;name&quot;</span>: <span class="string">&quot;deny&quot;</span>,</span><br><span class="line">            <span class="attr">&quot;confidence&quot;</span>: <span class="number">0.078563989</span></span><br><span class="line">        &#125;,</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="attr">&quot;name&quot;</span>: <span class="string">&quot;thanks&quot;</span>,</span><br><span class="line">            <span class="attr">&quot;confidence&quot;</span>: <span class="number">0.072717722</span></span><br><span class="line">        &#125;,</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="attr">&quot;name&quot;</span>: <span class="string">&quot;goodbye&quot;</span>,</span><br><span class="line">            <span class="attr">&quot;confidence&quot;</span>: <span class="number">0.0726876305</span></span><br><span class="line">        &#125;,</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="attr">&quot;name&quot;</span>: <span class="string">&quot;greet&quot;</span>,</span><br><span class="line">            <span class="attr">&quot;confidence&quot;</span>: <span class="number">0.0697155938</span></span><br><span class="line">        &#125;,</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="attr">&quot;name&quot;</span>: <span class="string">&quot;whattodo&quot;</span>,</span><br><span class="line">            <span class="attr">&quot;confidence&quot;</span>: <span class="number">0.0443638481</span></span><br><span class="line">        &#125;,</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="attr">&quot;name&quot;</span>: <span class="string">&quot;whoareyou&quot;</span>,</span><br><span class="line">            <span class="attr">&quot;confidence&quot;</span>: <span class="number">0.0172932785</span></span><br><span class="line">        &#125;</span><br><span class="line">    ],</span><br><span class="line">    <span class="attr">&quot;text&quot;</span>: <span class="string">&quot;明天成都的天气如何&quot;</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<h4 id="1-3-启动action"><a href="#1-3-启动action" class="headerlink" title="1.3 启动action"></a>1.3 启动action</h4><blockquote>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python -m rasa run actions --port 5055 --actions actions --debug</span><br></pre></td></tr></table></figure>
</blockquote>
<h3 id="2-NLU"><a href="#2-NLU" class="headerlink" title="2. NLU"></a>2. NLU</h3><p><img src="https://gitee.com/fushengwuyu1993/images/raw/master/imgs/1590138247599.png" alt="1590138247599"></p>
<p><img src="https://gitee.com/fushengwuyu1993/images/raw/master/imgs/1590138270872.png" alt="1590138270872"></p>
<h4 id="2-1-数据格式"><a href="#2-1-数据格式" class="headerlink" title="2.1 数据格式"></a>2.1 数据格式</h4><p>rasa支持markdown和json两种数据格式，同时提供了相互转化的命令。</p>
<p>nlu训练数据包含四个部分：</p>
<ul>
<li><p>Common Example</p>
<p>唯一必须提供数据。由三部分组成：intent、text、entities。</p>
<blockquote>
<p>## intent: 你的意图名称</p>
<p>- text</p>
</blockquote>
<p>text中可以不包括实体，如果有实体使用<code>[entityText](entityName)</code>来标记。</p>
</li>
<li><p>synonyms</p>
</li>
<li><p>Regular Expression Features</p>
</li>
<li><p>lookup tables</p>
</li>
</ul>
<h4 id="2-2-数据转化"><a href="#2-2-数据转化" class="headerlink" title="2.2 数据转化"></a>2.2 数据转化</h4><p>rasa提供了json和markdown格式的转化命令</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">usage: rasa data convert nlu [-h] [-v] [-vv] [--quiet] --data DATA --out OUT</span><br><span class="line">                             [-l LANGUAGE] -f &#123;json,md&#125;</span><br><span class="line"></span><br><span class="line">optional arguments:</span><br><span class="line">  -h, --help            show this help message and exit</span><br><span class="line">  --data DATA           Path to the file or directory containing Rasa NLU</span><br><span class="line">                        data. (default: None)</span><br><span class="line">  --out OUT             File where to save training data in Rasa format.</span><br><span class="line">                        (default: None)</span><br><span class="line">  -l LANGUAGE, --language LANGUAGE</span><br><span class="line">                        Language of data. (default: en)</span><br><span class="line">  -f &#123;json,md&#125;, --format &#123;json,md&#125;</span><br><span class="line">                        Output format the training data should be converted</span><br><span class="line">                        into. (default: None)</span><br><span class="line"></span><br><span class="line">Python Logging Options:</span><br><span class="line">  -v, --verbose         Be verbose. Sets logging level to INFO. (default:</span><br><span class="line">                        None)</span><br><span class="line">  -vv, --debug          Print lots of debugging statements. Sets logging level</span><br><span class="line">                        to DEBUG. (default: None)</span><br><span class="line">  --quiet               Be quiet! Sets logging level to WARNING. (default:</span><br><span class="line">                        None)</span><br></pre></td></tr></table></figure>

<p>example：</p>
<blockquote>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rasa data convert nlu --data M3-training_dataset_1564317234.json --out M3-training_dataset_1564317234.md -f md</span><br></pre></td></tr></table></figure>
</blockquote>
<h3 id="3-core"><a href="#3-core" class="headerlink" title="3. core"></a>3. core</h3><p>备注1： core模型是一个分类分为，类别数为domain中定义的action数。action主要分为以下4类：</p>
<ul>
<li><p>custom action</p>
</li>
<li><p>utterance：response、template</p>
</li>
<li><p>default actions</p>
<blockquote>
<p>[‘action_listen’, ‘action_restart’, ‘action_session_start’, ‘action_default_fallback’, ‘action_deactivate_form’, ‘action_revert_fallback_events’, ‘action_default_ask_affirmation’, ‘action_default_ask_rephrase’, ‘action_back’]</p>
</blockquote>
</li>
<li><p>forms（表单）</p>
</li>
</ul>
<p>action类别为各类action取交集后的结果。</p>
<p>备注2：用户可以直接像core发送请求，不经过nlu模块。参数格式：/intent{“entityName”: “entityValue”, …}</p>
<blockquote>
<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">	<span class="attr">&quot;sender&quot;</span>: <span class="string">&quot;kkkkkkk&quot;</span>,</span><br><span class="line">	<span class="attr">&quot;message&quot;</span>: <span class="string">&quot;/search_treat&#123;\&quot;disease\&quot;:\&quot;丛集性头痛\&quot;, \&quot;sure\&quot;:\&quot;丛集性头痛\&quot;&#125;&quot;</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">[</span><br><span class="line">    &#123;</span><br><span class="line">        &quot;recipient_id&quot;: &quot;kkkkkkk&quot;,</span><br><span class="line">        &quot;text&quot;: &quot;丛集性头痛的简介：从集性头痛(clusterheadaches)亦称偏头痛性神经痛、组胺性头痛、岩神经痛、蝶腭神经痛、Horton头痛等，.病员在某个时期内突然出现一系列的剧烈头痛。一般无前兆，疼痛多见于一侧眼眶或(及)额颞部，可伴同侧眼结膜充血、流泪、眼睑水肿或鼻塞、流涕，有时出现瞳孔缩小、垂睑、脸红、颊肿等症状。头痛多为非搏动性剧痛。病人坐立不安或前俯后仰地摇动，部分病员用拳击头部以缓解疼痛。&quot;</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">        &quot;recipient_id&quot;: &quot;kkkkkkk&quot;,</span><br><span class="line">        &quot;text&quot;: &quot;丛集性头痛的治疗方式有：药物治疗、支持性治疗&quot;</span><br><span class="line">    &#125;</span><br><span class="line">]</span><br></pre></td></tr></table></figure>
</blockquote>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2021/07/20/vim%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="sunshine">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="浮生物语的博客">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2021/07/20/vim%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/" class="post-title-link" itemprop="url">vim常用命令总结</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2021-07-20 00:00:00" itemprop="dateCreated datePublished" datetime="2021-07-20T00:00:00+08:00">2021-07-20</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2021-08-20 11:35:21" itemprop="dateModified" datetime="2021-08-20T11:35:21+08:00">2021-08-20</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E8%BF%90%E7%BB%B4/" itemprop="url" rel="index"><span itemprop="name">运维</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>vim常用命令</p>
<ol>
<li>行内移动<ul>
<li>w： 向前移动（单词）</li>
<li>b：向后移动（单词）</li>
<li>$： 移动到行末</li>
<li>^ ：移动到行首</li>
</ul>
</li>
<li>跨行移动<ul>
<li>↑，↓</li>
<li>数字+方向键：5↓代表向下移动5行</li>
<li>ctrl+f：向前翻页</li>
<li>ctrl+b：向后翻页</li>
<li>G（shift+g）：移动到文件末尾</li>
<li>gg：移动到文件开头</li>
<li>N+%：移动到文件的N%处，50+%表示移动到文件的中间位置</li>
<li>N+g：移动到文件的N行处，10+g表示移动到第10行。</li>
</ul>
</li>
<li>定向移动（查找）<ul>
<li>/text：查找text，使用n/N 向下/向上跳转。vim查找支持正则，如：/^$查找空白行。</li>
</ul>
</li>
<li>文件格式与编码<ul>
<li>:set list ：显示制表符和行尾， ：set nolist：取消显示</li>
<li>:set nu(number) ：显示行号，:set nonumber 取消显示</li>
<li>:set fileencoding：查看当前文件编码，当vim无法识别编码的时候，默认实用latin-1读取。:e ++enc=gb18030 强制使用gb18030编码重新打开。</li>
</ul>
</li>
<li>分屏<ul>
<li>vim -o file1 file2： 打开两个文件（默认水平分屏）</li>
<li>已经打开vim的情况下，:vs file2： 打开file2，vs指vertical split。</li>
<li>ctrl + w +  ←(h)/↑(j)/↓(k)/→(l)：控制调整的方向。</li>
<li>ctrl + w+ w：跳转下一个窗口</li>
<li>ctrl + w +c 关闭窗口</li>
</ul>
</li>
</ol>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2021/07/20/%E4%B8%AD%E6%96%87%E6%96%87%E6%9C%AC%E7%BA%A0%E9%94%99%E8%B0%83%E7%A0%94/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="sunshine">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="浮生物语的博客">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2021/07/20/%E4%B8%AD%E6%96%87%E6%96%87%E6%9C%AC%E7%BA%A0%E9%94%99%E8%B0%83%E7%A0%94/" class="post-title-link" itemprop="url">中文文本纠错调研</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2021-07-20 00:00:00" itemprop="dateCreated datePublished" datetime="2021-07-20T00:00:00+08:00">2021-07-20</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2021-08-20 11:24:42" itemprop="dateModified" datetime="2021-08-20T11:24:42+08:00">2021-08-20</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/NLP/" itemprop="url" rel="index"><span itemprop="name">NLP</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h4 id="1-常见的中文错误类型"><a href="#1-常见的中文错误类型" class="headerlink" title="1. 常见的中文错误类型"></a>1. 常见的中文错误类型</h4><ul>
<li><p>发音错误， 特点：音近，发音不标准， 原因：地方发音，语言转化。 - 灰机</p>
</li>
<li><p>拼写错误：特点： 正确词语错误使用， 原因： 输入法导致-拼音、五笔、手写 - 眼睛蛇</p>
</li>
<li><p>语法，知识错误： 特点：逻辑错误，多字、少字，乱序 - 女性患病前列腺炎</p>
</li>
</ul>
<h4 id="2-研究现状"><a href="#2-研究现状" class="headerlink" title="2. 研究现状"></a>2. 研究现状</h4><h5 id="2-1-通用纠错项目"><a href="#2-1-通用纠错项目" class="headerlink" title="2.1 通用纠错项目"></a>2.1 通用纠错项目</h5><blockquote>
<p><a target="_blank" rel="noopener" href="https://github.com/shibing624/pycorrector">https://github.com/shibing624/pycorrector</a></p>
</blockquote>
<ul>
<li><p>错误检测</p>
<ul>
<li>常用字典匹配： 切词后不再常用字典中认为有错</li>
<li>统计语言模型：某个字的似然概率低于句子的平均值</li>
<li>混淆字典匹配：example - 国藉 -&gt; 国籍</li>
</ul>
</li>
<li><p>候选召回</p>
<ul>
<li>近音字替换（拼音）： 藉\ji -&gt; 籍， 集， 寄。。。</li>
<li>近形字替换（五笔）： 藉 -&gt; 籍，藕，箱</li>
</ul>
</li>
<li><p>候选排序</p>
<ul>
<li><p>语言模型计算句子概率，取概率超过原句子切最大的</p>
<blockquote>
<p>P(患者1天前体检发现脾动脉瘤)</p>
<p>P(患者1天前体检发现皮动脉瘤)</p>
<p>P(患者1天前体检发现劈动脉瘤)</p>
</blockquote>
<h5 id="2-2-学术界进展"><a href="#2-2-学术界进展" class="headerlink" title="2.2 学术界进展"></a>2.2 学术界进展</h5></li>
<li><p>基于序列标注的纠错</p>
<blockquote>
<p>《 Alibaba at IJCNLP-2017 Task 1: Embedding Grammatical Features<br>into LSTMs for Chinese Grammatical Error Diagnosis Task 》</p>
</blockquote>
<p>利用序列标注模型 + 人工提取特征进行错误位置的标注</p>
<p><img src="https://gitee.com/fushengwuyu1993/images/raw/master/imgs/1577068913235.png" alt="1577068913235"></p>
<pre><code>                 2017年IJCNLP举办的CGED比赛中阿里团队提出的Top1方案
</code></pre>
<p>成绩： P：0.36， R： 0.21， F1：0.27</p>
</li>
<li><p>基于NMT的纠错</p>
<blockquote>
<p>《 Youdao’s Winning Solution to the NLPCC-2018 Task 2 Challenge: A Neural<br>Machine Translation Approach to Chinese Grammatical Error Correction 》</p>
</blockquote>
<p>利用模型将错误语句翻译成正确语句，利用transformer模型完成端到端的纠错过程</p>
<p><img src="https://gitee.com/fushengwuyu1993/images/raw/master/imgs/1577069217626.png" alt="1577069217626"></p>
<p>成绩： P： 0.34， R：0.18， F0.5： 0.29</p>
</li>
</ul>
</li>
</ul>
<h5 id="2-3-评价指标"><a href="#2-3-评价指标" class="headerlink" title="2.3 评价指标"></a>2.3 评价指标</h5><ul>
<li><p>过纠率 / 误报率</p>
<p>$FAR = \frac{正确句子被纠错的个数}{正确句子的个数}$</p>
</li>
<li><p>召回率</p>
<p>$$R = \frac{错误句子被改正的句子数}{错误的句子总数}$$</p>
</li>
<li><p>纠错目标</p>
<p>被改正的句子数 &gt;&gt; 被改错的句子数</p>
<p>​                       $$K * R &gt;&gt; (1 - K) * FAR$$</p>
<p>目标在于尽可能的提高召回率R。</p>
</li>
</ul>
<h5 id="2-4-存在的问题"><a href="#2-4-存在的问题" class="headerlink" title="2.4 存在的问题"></a>2.4 存在的问题</h5><p>​    公司目前纠错现状，还存在一下问题。</p>
<ul>
<li>缺乏标注语料，难以展开基于深度学习的监督学习</li>
<li>纠错强调实时性，对内存和实效性要求很高，线上纠错不得超过10ms/句，导致大规模字典和复杂模型无法线上使用</li>
<li>纠错要求高准确性，宁愿牺牲召回也必须保证高准确度，防止过纠（把正确的词改错），过纠率不得高于0.2%</li>
<li>结合电子病历，绝大部分错误都是替换错误，同音字，同行字等。</li>
</ul>
<h4 id="3-平安文本纠错方案"><a href="#3-平安文本纠错方案" class="headerlink" title="3. 平安文本纠错方案"></a>3. 平安文本纠错方案</h4><p>​    平安人寿问答纠错模块结构如下图所示。其基本流程包括错误检测、候选召回、候选排序、候选筛选。</p>
<p><img src="https://gitee.com/fushengwuyu1993/images/raw/master/imgs/1577070846118.png" alt="1577070846118"></p>
<h5 id="3-1-错误检测"><a href="#3-1-错误检测" class="headerlink" title="3.1 错误检测"></a>3.1 错误检测</h5><ul>
<li><p>基于规则的错误检测</p>
<ul>
<li><p>拼音匹配： 适合实体错误检测，比如疾病，药品等实体，需要维护拼音-实体隐射字典</p>
<img src="https://gitee.com/fushengwuyu1993/images/raw/master/imgs/1577071517262.png" alt="1577071517262" style="zoom:80%;" /></li>
<li><p>拼音编辑距离：1.  检测所有编辑距离小于阈值的路径 2. 最优路径选取（最小拼音编辑距离， 最长字符匹配）3. 语言模型 + 规则联合筛选</p>
</li>
</ul>
</li>
<li><p>单双向2gram检测</p>
<p>当前词与上下文组成的2gram词频很低，认为有错</p>
<p>基于假设： 正确表述发生的频次要远远大于错误表述发生的次数</p>
<p><img src="https://gitee.com/fushengwuyu1993/images/raw/master/imgs/1577072025140.png" alt="yu1577072025140"></p>
</li>
<li><p>基于神经网络语言模型的错误检测 </p>
<p>核心思想：</p>
<ul>
<li>通过完形填空的方式预测候选字的概率分布</li>
<li>如果原字的概率不在topK或者top1比值操作阈值则认为有错</li>
</ul>
<p>改进措施：</p>
<ul>
<li><p>传统的语言模型从左到右，单向，只利用上文，改为双向模型，利用上下文信息。</p>
</li>
<li><p>传统的语言模型把预测字MASK，没有预测字的信息，可以改为引入当前字的混淆字信息（如：相似的字音和字形字）。</p>
</li>
<li><p>传统语言模型会直接预测字表，比如字表大小是3800，预测结果会直接得到3800个字的概率分布，其中大多是无用信息，且容易引发维度灾问题。可以通过将预测字约束在近音、近形和混淆字表里，提高效率和正确字与错误中字的区分度。</p>
<p><img src="https://gitee.com/fushengwuyu1993/images/raw/master/imgs/1581907503895.png" alt="1581907503895"></p>
<p><img src="https://gitee.com/fushengwuyu1993/images/raw/master/imgs/1581907667130.png" alt="1581907667130"></p>
</li>
</ul>
</li>
<li><p>基于word2vec-cbow改造的音字混合受限字表示语言模型检测算法</p>
<p>基于CSLM的中文拼写检测：《Chinese Spelling Errors Detection Based on  CSLM,2015》</p>
<p>主要特征：</p>
<ul>
<li>带入预测字及上下文拼音、五笔特征</li>
<li>去掉前后鼻音和翘舌音,并利用混淆音集映射的方式来提高模型对谐音错误的识别性能。</li>
<li>预测字表受限于近音字、近形字和混淆字表中。</li>
</ul>
<p><img src="https://gitee.com/fushengwuyu1993/images/raw/master/imgs/1581908381943.png" alt="1581908381943"></p>
</li>
</ul>
<h5 id="3-2-候选召回"><a href="#3-2-候选召回" class="headerlink" title="3.2 候选召回"></a>3.2 候选召回</h5><ul>
<li><p>近音字候选召回</p>
<p>选择近音字作为候选字，构造一个近音字字典。大规模的基础字典，使得在存储和读取速度方面收到了极大的调整。</p>
<p>字典存储构架如下：</p>
<p><img src="https://gitee.com/fushengwuyu1993/images/raw/master/imgs/1581911102435.png" alt="1581911102435"></p>
<p>关键技术：</p>
<ul>
<li>减低存储空间：<ol>
<li>利用Trie树降低信息冗余</li>
<li>利用经典结合CSR压缩稀疏矩阵</li>
<li>使用词典间的关联信息回复2gram同音字典</li>
</ol>
</li>
<li>提高读取速度：Trie树、CSR技术的高效索引。</li>
</ul>
</li>
<li><p>字、音编辑距离召回</p>
<p>使用编辑距离作为是否召回的依据。</p>
</li>
<li><p>混淆词集</p>
</li>
<li><p>疾病口语词</p>
</li>
</ul>
<h5 id="3-3-候选排序"><a href="#3-3-候选排序" class="headerlink" title="3.3 候选排序"></a>3.3 候选排序</h5><p>​    针对候选词的排序主要由二级排序来实现。</p>
<ul>
<li><p>一级排序</p>
<p>模型：逻辑回归LR</p>
<p>作用：二级排序比较耗时，通过一级排序初筛出TopK进入下一级</p>
<p>要求：正类召回率高，运行速度快</p>
<p>特征：</p>
<ul>
<li>频次比值：候选频次越高分数越高</li>
<li>编辑距离：编辑距离越小分数越高</li>
<li>拼音jaccard距离：拼音相近分数越高</li>
<li>4gram-LM概率差值：候选替换后橘子越通顺分数越高</li>
</ul>
<p>一级排序大致流程如下：</p>
<p><img src="https://gitee.com/fushengwuyu1993/images/raw/master/imgs/1581916837380.png" alt="1581916837380"></p>
<p>例如：甲状腺==姐姐==该怎么治疗？ -&gt;==结节  0.99==</p>
<ul>
<li>频次： 55 -&gt; 94</li>
<li>编辑距离：2</li>
<li>拼音jaccard距离：0</li>
<li>语言模型概率：-21.9 -&gt; -8.6</li>
</ul>
</li>
<li><p>二级排序</p>
<p>模型：xgboost</p>
<p>作用：分数超过设定阈值且是Top1作为最终候选</p>
<p>要求：正类准确率高</p>
<p>特征：</p>
<ol>
<li>局部特征<ul>
<li>切词变化：短语个数、含错别字片段长度等</li>
<li>PMI变化：最小值、最值</li>
<li>频次变化：频次变化、2gram频次变化</li>
<li>4gram语言模型变化</li>
<li>形音变化：拼音韵母变化、jccard距离、五笔变化</li>
<li>其他：停用词\错别字位置、候选来源等等</li>
</ul>
</li>
<li>全局特征<ul>
<li>Cbow-LM</li>
<li>LSTM-Attention-LM</li>
<li>BERT-LM</li>
</ul>
</li>
</ol>
<p><img src="https://gitee.com/fushengwuyu1993/images/raw/master/imgs/1581918099275.png" alt="1581918099275"></p>
<p>例子：==红癍狼仓==常见症状有哪些?   ==红斑狼疮==</p>
<ul>
<li>频次 ：20 -&gt; 1688</li>
<li>切词：红\癍\狼疮 (1\1\2) -&gt; 红斑狼疮 (4)</li>
<li>nn语言模型:癍 (&lt;0.001) -&gt; 斑 (0.979)</li>
<li>4gram语言模型:-19.2 -&gt; -10.6</li>
<li>PMI:红癍(0.33) -&gt;红斑(9.7)</li>
</ul>
</li>
</ul>
<h5 id="3-4-整体架构"><a href="#3-4-整体架构" class="headerlink" title="3.4 整体架构"></a>3.4 整体架构</h5><p><img src="https://gitee.com/fushengwuyu1993/images/raw/master/imgs/1581918508852.png" alt="1581918508852"></p>
<p>​    特性：</p>
<ul>
<li><p>pipline串联，热插拔</p>
</li>
<li><p>子模块均遵循检测-召回-排序流程</p>
</li>
<li><p>规则+模型混用</p>
</li>
<li><p>离线+在线</p>
</li>
</ul>
<p>在线方案：</p>
<ul>
<li>低延迟、低复杂度</li>
<li>高速1ms-3ms/句</li>
<li>用于线上实时预测</li>
</ul>
<p>离线方案：</p>
<ul>
<li>大规模、复杂模型</li>
<li>低速200ms-500ms/句</li>
<li>用于构造在线模型，训练数据</li>
</ul>
<h5 id="3-5-总结与改进"><a href="#3-5-总结与改进" class="headerlink" title="3.5 总结与改进"></a>3.5 总结与改进</h5><ol>
<li>优点：<ul>
<li>无监督，方便将该方法迁移到其他垂直领域，只需要重新无监督挖掘数据</li>
<li>系统架构方便插拔特殊编写纠错子模块</li>
</ul>
</li>
<li>缺点：<ul>
<li>很难迁移到通用领域</li>
<li>Pipline导致错误逐级传递</li>
<li>Pipline链越长，耗时越长</li>
</ul>
</li>
<li>改进思路<ul>
<li>强化上下文/全局的语义理解</li>
<li>训练预料去噪处理</li>
<li>端到端算法，如NMT（神经机器翻译）</li>
<li>语法错误（多字少字乱序）</li>
</ul>
</li>
</ol>
<h4 id="4-爱奇艺文本纠错方案"><a href="#4-爱奇艺文本纠错方案" class="headerlink" title="4. 爱奇艺文本纠错方案"></a>4. 爱奇艺文本纠错方案</h4><p>《FASPell: A Fast, Adaptable, Simple, Powerful Chinese Spell Checker Based On DAE-Decoder Paradigm》</p>
<h5 id="4-1-背景"><a href="#4-1-背景" class="headerlink" title="4.1 背景"></a>4.1 背景</h5><p>​    大部分的中文拼写检查模型都使用用一个范式，即讲每个汉字的固定相似字符集（混淆集或困惑集）作为候选项，然后使用过滤器选择最佳候选项作为错字的替换字符。这种设计面临着两个主要瓶颈：</p>
<ul>
<li><p>稀疏的中文拼写检查数据上的过拟合问题。</p>
<p>​    由于中文拼写检查数据需要乏味繁冗的专业人力工作，因为一直资源不足。为了防止模型的过拟合，        Wang等人（2018）提出了一种自动方法来生成伪拼写检查数据。 但是，当生成的数据达到40k句子时，其拼写检查模型的精度不再提高。 Zhao等人（2017）使用了大量的语言学规则来过滤候选项，但结果却比我们的表现差，尽管我们的模型没有利用任何语言学知识。</p>
</li>
<li><p>困惑集的使用带来的汉字字符相似度利用上的不灵活性和不充分性问题。</p>
<p>​    困惑集因为是固定的，因此并非在任何语境、场景下都能包含正确候选项（一个比较极端的例子是，如果困惑集按照繁体中文制定，那么繁体中文的 “體”和“休”肯定不在困惑集的同一组相似字符中，但是在简体中文中对应的“体”和“休”缺是相似字符，如果错误文本中是把“休”写成了“体”，那么繁体中文困惑集下就无法检出，必须专门再制定一个简体困惑集才可以），这会极大降低检测的召回率（不灵活性问题）；另外，困惑集中的字符的相似性的信息有损失，没有得到充分利用，因为一个字符在困惑集中相似字符是无差别对待的，然而事实上每两个字符间的相似度明显是有差别的，因此会影响检测的精确率（不充分性）。</p>
</li>
</ul>
<h5 id="4-2-设计"><a href="#4-2-设计" class="headerlink" title="4.2 设计"></a>4.2 设计</h5><p>​    FASPell提出通过设计中文拼写检查范式来避免传统模型的两个瓶颈。FASPell利用seq2seq的思想，包括去噪自编码器（DAE）和解码器。</p>
<ul>
<li><p>编码器DAE</p>
<p>DAE通过利用无监督预训练方法（BERT），减少了监督学习中所需的中文拼写检查数据量（&lt;10000个句子）。DAE可以将错误文本修改为正确文本的可能候选矩阵，解码器只需要在这个矩阵中寻求最佳候选项作为输出。DAE因为可以在大规模正常预料数据上无监督训练，而仅在中文拼写检测数据上做fine-tune，避免了过拟合问题。此外，只要DAE足够强大，所有语境上可能的候选字符都可以出现，且候选字符是根据上下文即时生成的，避免了困惑集带来的不灵活性。</p>
</li>
<li><p>解码器CSD</p>
<p>CSD巧妙的将预训练模型的置信度和字相似度结合起来，作为候选集的评价标准，消除困惑集的使用。CSD根据量化的字符相似度和DAE给出的符合语境的置信度来过滤出正确的替换字符，如此，字符相似性上的细微差别信息都可以得到充分利用。</p>
</li>
</ul>
<p>模型架构如图1所示：</p>
<p><img src="https://gitee.com/fushengwuyu1993/images/raw/master/imgs/1581923079272.png" alt="1581923079272"></p>
<p>​    可以看到，在FASPell中，DAE由BERT中的掩码语言模型（MLM）来充当，而解码器使用了置信度-相似度解码器(CSD)。</p>
<h5 id="4-3-CSD解码器"><a href="#4-3-CSD解码器" class="headerlink" title="4.3 CSD解码器"></a>4.3 CSD解码器</h5><p>​    CSD主要结合DAE的置信度和字符相似度，置信度直接由DAE给出，暂且不谈，这里详细说明字符相似度。</p>
<ol>
<li><p>字符相似度</p>
<ul>
<li><p>字音</p>
<p>采用中日韩统一表意文字（CJK）语言中的汉语发音，尽管目前只是对中文文本检错纠错，但是实验证明考虑诸如粤语、日语音读、韩语、越南语的汉字发音对提高拼写检查的性能是有帮助的，而过去的方法均只考虑了普通话拼音。</p>
</li>
<li><p>字形</p>
<p>采用Unicode标准的IDS表征，它可以准确的扫描汉字中各个笔画和他们的布局方式，这使得即使相同笔画和笔画顺序的汉字之间也拥有不为1的相似度。</p>
</li>
</ul>
<p>以午和牛，田和由为例：</p>
<p><img src="https://gitee.com/fushengwuyu1993/images/raw/master/imgs/1581929776094.png" alt="1581929776094"></p>
</li>
<li><p>训练CSD</p>
<p>CSD的训练阶段，利用训练集文本通过MLM输出的矩阵，逐行绘制置信度-字符相似度散点图，确定能将FP和 TP分开的最佳分界曲线。</p>
<p><img src="https://gitee.com/fushengwuyu1993/images/raw/master/imgs/1581930742369.png" alt="1581930742369"></p>
<p>​    如上图所示，红点代表正确检测并正确纠正的样本，蓝色圆圈代表正确检测但纠正错误的样本，叉叉代表错误检测的样本。图一并没有过滤候选集；图二倾向于错误检测性能，大部分正确检测的候选集保留了下来；图三更加倾向于错误纠正，FASPell采用此种曲线；图四采用加权确定阈值的方式来确定曲线$（0.8×confidence+0.2×similarity&lt;0.8）$。</p>
<p>​    在训练阶段，我们的目标在于确定一条合适的曲线，供于推理阶段使用。</p>
</li>
<li><p>推理</p>
<p>在推理阶段，逐行根据分界线过滤掉FP得到TP结果，然后将每行的结果取并集得到最终替换结果。以上面架构图为例片，句子首先通过fine-tune训练好的MLM模型，得到的候选字符矩阵通过CSD进行解码过滤，第一行候选项中只有“主”字没有被CSD过滤掉，第二行只有“著”字未被过滤掉，其它行候选项均被分界线过滤清除，得到最终输出结果，即“苦”字被替换为为“著”，“丰”被替换为“主”。</p>
</li>
</ol>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2021/07/20/%E4%BF%A1%E6%81%AF%E7%86%B5/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="sunshine">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="浮生物语的博客">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2021/07/20/%E4%BF%A1%E6%81%AF%E7%86%B5/" class="post-title-link" itemprop="url">信息熵</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2021-07-20 00:00:00" itemprop="dateCreated datePublished" datetime="2021-07-20T00:00:00+08:00">2021-07-20</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2021-08-20 11:17:58" itemprop="dateModified" datetime="2021-08-20T11:17:58+08:00">2021-08-20</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E7%AC%94%E8%AE%B0/" itemprop="url" rel="index"><span itemprop="name">笔记</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h4 id="一-熵"><a href="#一-熵" class="headerlink" title="一. 熵"></a>一. 熵</h4><ol>
<li><p>解释</p>
<ul>
<li>熵是不确定的度量</li>
<li>熵是信息的度量</li>
</ul>
</li>
<li><p>计算公式<br>$$<br>S = - \sum _{x} p(x)\log p(x) \tag{1}<br>$$</p>
<p>log可以取自然对数，也可以是以底为2的对数，任意大于1的底都是成立的。换底只不过换了信息的单位而已。</p>
</li>
</ol>
<p>对于连续的概率分布，熵的定义为：<br>$$<br>S=- \int p(x) \log p (x)dx \tag{2}<br>$$</p>
<ol start="3">
<li><p>联合熵<br>$$<br>S[p(x,y)]=-\sum_{x} \sum_{y}p(x,y)\ln p(x,y) \tag{3}<br>$$</p>
</li>
<li><p>条件熵<br>$$<br>S(Y|X)=S[p(x,y)] - S[p(x)] \tag{4}<br>$$<br>等价于：<br>$$<br>S(Y|X)=-\sum_{x} \sum_{y}p(x,y) \log p(y:x) \tag{5}<br>$$<br>通俗的说，本来的信息量有$$S[p(x,y)]$$ ，然后$$p(x)$$ 能带来$$S[p(x)]$$ 的信息，减去其不确定性，剩下的就是条件熵。</p>
</li>
<li><p>互信息</p>
<p>互信息可以度量两个随机事件“相关性”的量化<br>$$<br>S(X;Y)=\sum_{x}\sum_{y}p(x,y)\log \frac{p(x,y)}{p(x)p(y)} \tag{6}<br>$$</p>
<p>互信息就是随机事件X，以及知道随机事件Y条件下的不确定性，或者条件熵之间的差异。即。<br>$$<br>S(X;Y)=S(X) -S(X|Y) \tag{7}<br>$$</p>
</li>
<li><p>相对熵</p>
<p>相对熵也是来衡量相关性，但和互信息不同，它用来衡量两个取值为正数的函数的相似性。<br>$$<br>KL(f(x)||g(x))=\sum_{x \in X}f(x)\cdot \log \frac {f(x)}{g(x)} \tag{8}<br>$$</p>
<ul>
<li>对于两个完全相同的函数，他们的相对数为0</li>
<li>相对熵越大，两个函数差异越大；反之，相对熵越小，两函数差异越小</li>
<li>对于概率分布和概率密度分布，如果取值均大于0，相对熵可以度量两个随机分布的差异性</li>
</ul>
<p>相对熵是不对称的。<br>$$<br>KL(f(x)||g(x)) \ne KL(g(x)||f(x)) \tag{9}<br>$$<br>詹森和香农提出了一种相对熵的计算方法，将上面的不等式变为等式。<br>$$<br>JS(f(x)||g(x))=\frac{1}{2}[KL(f(x)||g(x))+KL(g(x)||f(x))] \tag{10}<br>$$</p>
</li>
</ol>
<h4 id="二-最大熵"><a href="#二-最大熵" class="headerlink" title="二. 最大熵"></a>二. 最大熵</h4><p>当我们想要得到一个随机事件的概率分布时，如果没有足够的信息能够确定这个概率分布（可能是不能确定分布，也可能是知道分布的类型，但是还有若干个参数没有确定），那么最“保险”的方案就是选择使得熵最大的分布。</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2021/07/20/%E6%83%85%E6%84%9F%E5%88%86%E6%9E%90/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="sunshine">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="浮生物语的博客">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2021/07/20/%E6%83%85%E6%84%9F%E5%88%86%E6%9E%90/" class="post-title-link" itemprop="url">情感分析总结</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2021-07-20 00:00:00" itemprop="dateCreated datePublished" datetime="2021-07-20T00:00:00+08:00">2021-07-20</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2021-08-20 11:25:17" itemprop="dateModified" datetime="2021-08-20T11:25:17+08:00">2021-08-20</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/NLP/" itemprop="url" rel="index"><span itemprop="name">NLP</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h4 id="1-last3embedding"><a href="#1-last3embedding" class="headerlink" title="1. last3embedding"></a>1. last3embedding</h4><p>参考：<a target="_blank" rel="noopener" href="https://blog.csdn.net/weixin_45839693/article/details/109378849">https://blog.csdn.net/weixin_45839693/article/details/109378849</a></p>
<p><img src="https://gitee.com/fushengwuyu1993/images/raw/master/imgs/20210805103133-image-20210805103132616.png" alt="image-20210805103132616"></p>
<p>模型比较简单，就是将最后3层的cls取出来拼接在一起，接dense即可。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, inputs</span>):</span></span><br><span class="line">    x = self.bert_layer(inputs, output_hidden_states=<span class="literal">True</span>)</span><br><span class="line">    hiden_states = x.hidden_states</span><br><span class="line">    pooled_output = x.pooled_output</span><br><span class="line">    tensor = torch.cat([hidden_states[-<span class="number">1</span>][:,<span class="number">0</span>],hidden_states[-<span class="number">2</span>][:,<span class="number">0</span>],hidden_states[-<span class="number">3</span>][:,<span class="number">0</span>],pooled_output, dim=<span class="number">1</span>)</span><br><span class="line">    drop_out_l = self.drop_out(tensor)</span><br><span class="line">    Dense_l = self.liner_layer(drop_out_l)</span><br><span class="line">    outputs = self.soft_max(Dense_l)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>改进：</p>
<ul>
<li><p>接lstm</p>
</li>
<li><p>接textcnn</p>
</li>
</ul>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2021/07/20/%E5%B8%B8%E8%A7%81%E5%AE%89%E8%A3%85%E8%84%9A%E6%9C%AC/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="sunshine">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="浮生物语的博客">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2021/07/20/%E5%B8%B8%E8%A7%81%E5%AE%89%E8%A3%85%E8%84%9A%E6%9C%AC/" class="post-title-link" itemprop="url">常见安装脚本</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2021-07-20 00:00:00" itemprop="dateCreated datePublished" datetime="2021-07-20T00:00:00+08:00">2021-07-20</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2021-08-20 11:24:58" itemprop="dateModified" datetime="2021-08-20T11:24:58+08:00">2021-08-20</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E8%BF%90%E7%BB%B4/" itemprop="url" rel="index"><span itemprop="name">运维</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="1-安装python3-6-5"><a href="#1-安装python3-6-5" class="headerlink" title="1. 安装python3.6.5"></a>1. 安装python3.6.5</h2><ol>
<li><p>安装依赖包</p>
<ul>
<li><p>centos</p>
<blockquote>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum -y install zlib-devel bzip2-devel openssl-devel ncurses-devel sqlite-devel readline-devel tk-devel gdbm-devel db4-devel libpcap-devel xz-devel libffi-devel</span><br></pre></td></tr></table></figure></blockquote>
</li>
<li><p>ubuntu</p>
<blockquote>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get install zlib1g-dev libbz2-dev libssl-dev libncurses5-dev libsqlite3-dev libreadline-dev tk-dev libgdbm-dev libdb-dev libpcap-dev xz-utils libexpat1-dev liblzma-dev libffi-dev libc6-dev</span><br></pre></td></tr></table></figure></blockquote>
</li>
</ul>
</li>
<li><p>解压</p>
</li>
<li><p>安装</p>
<blockquote>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">./configure</span><br><span class="line">make &amp;&amp; make install</span><br></pre></td></tr></table></figure></blockquote>
</li>
<li><p>添加软连接</p>
<blockquote>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ln -s /usr/local/python3/bin/python3.6.7 /usr/bin/python3</span><br><span class="line">ln -s /usr/local/python3/bin/pip3.6.5 /usr/bin/pip3</span><br></pre></td></tr></table></figure></blockquote>
</li>
</ol>
<h2 id="2-安装neo4j"><a href="#2-安装neo4j" class="headerlink" title="2. 安装neo4j"></a>2. 安装neo4j</h2><ol>
<li><p>neo4j底层依赖java，请自行安装jdk</p>
</li>
<li><p>下载neo4j</p>
<p><a target="_blank" rel="noopener" href="https://neo4j.com/download/other-releases/#releases">https://neo4j.com/download/other-releases/#releases</a></p>
</li>
<li><p>解压</p>
</li>
<li><p>配置neo4j.conf文件，修改相应配置(配置行数针对3.4.5版本，其他版本自行寻找相应配置)</p>
<blockquote>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 修改第22行load csv时l路径，在前面加个<span class="comment">#，可从任意路径读取文件</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash">dbms.directories.import=import</span></span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 修改35行和36行，设置JVM初始堆内存和JVM最大堆内存</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 生产环境给的JVM最大堆内存越大越好，但是要小于机器的物理内存</span></span><br><span class="line">dbms.memory.heap.initial_size=5g</span><br><span class="line">dbms.memory.heap.max_size=10g</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 修改46行，可以认为这个是缓存，如果机器配置高，这个越大越好</span></span><br><span class="line">dbms.memory.pagecache.size=10g</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 修改54行，去掉改行的<span class="comment">#，可以远程通过ip访问neo4j数据库</span></span></span><br><span class="line">dbms.connectors.default_listen_address=0.0.0.0</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 默认 bolt端口是7687，http端口是7474，https关口是7473，不修改下面3项也可以</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 修改71行，去掉<span class="comment">#，设置http端口为7687，端口可以自定义，只要不和其他端口冲突就行</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash">dbms.connector.bolt.listen_address=:7687</span></span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 修改75行，去掉<span class="comment">#，设置http端口为7474，端口可以自定义，只要不和其他端口冲突就行</span></span></span><br><span class="line">dbms.connector.http.listen_address=:7474</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 修改79行，去掉<span class="comment">#，设置http端口为7473，端口可以自定义，只要不和其他端口冲突就行</span></span></span><br><span class="line">dbms.connector.https.listen_address=:7473</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 修改227行，去掉<span class="comment">#，允许从远程url来load csv</span></span></span><br><span class="line">dbms.security.allow_csv_import_from_file_urls=true</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 修改246行，允许使用neo4j-shell，类似于mysql 命令行之类的</span></span><br><span class="line">dbms.shell.enabled=true</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 修改235行，去掉<span class="comment">#，设置连接neo4j-shell的端口，一般都是localhost或者127.0.0.1，这样安全，其他地址的话，一般使用https就行</span></span></span><br><span class="line">dbms.shell.host=127.0.0.1</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 修改250行，去掉<span class="comment">#，设置neo4j-shell端口，端口可以自定义，只要不和其他端口冲突就行</span></span></span><br><span class="line">dbms.shell.port=1337</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 修改254行，设置neo4j可读可写</span></span><br><span class="line">dbms.read_only=false</span><br></pre></td></tr></table></figure></blockquote>
</li>
<li><p>启动，进入neo4j目录。</p>
<blockquote>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./bin/neo4j start</span><br></pre></td></tr></table></figure>
</blockquote>
<blockquote>
<p>Active database: graph.db<br>Directories in use:<br>  home:         /root/neo4j-community-3.4.5<br>  config:       /root/neo4j-community-3.4.5/conf<br>  logs:         /root/neo4j-community-3.4.5/logs<br>  plugins:      /root/neo4j-community-3.4.5/plugins<br>  import:       NOT SET<br>  data:         /root/neo4j-community-3.4.5/data<br>  certificates: /root/neo4j-community-3.4.5/certificates<br>  run:          /root/neo4j-community-3.4.5/run<br>Starting Neo4j.<br>Started neo4j (pid 19029). It is available at <a target="_blank" rel="noopener" href="http://0.0.0.0:7474/">http://0.0.0.0:7474/</a><br>There may be a short delay until the server is ready.<br>See /root/neo4j-community-3.4.5/logs/neo4j.log for current status.</p>
</blockquote>
</li>
<li><p>停止</p>
<blockquote>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/neo4j stop</span><br></pre></td></tr></table></figure>
</blockquote>
<blockquote>
<p>Stopping Neo4j.. stopped</p>
</blockquote>
</li>
</ol>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2021/07/20/%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B%E6%A2%B3%E7%90%86/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="sunshine">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="浮生物语的博客">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2021/07/20/%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B%E6%A2%B3%E7%90%86/" class="post-title-link" itemprop="url">预训练模型梳理</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2021-07-20 00:00:00" itemprop="dateCreated datePublished" datetime="2021-07-20T00:00:00+08:00">2021-07-20</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2021-08-20 11:26:32" itemprop="dateModified" datetime="2021-08-20T11:26:32+08:00">2021-08-20</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/NLP/" itemprop="url" rel="index"><span itemprop="name">NLP</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>summary Table</p>
<table>
<thead>
<tr>
<th>模型</th>
<th>语言模型</th>
<th>特征抽取</th>
<th>上下文表征</th>
<th>亮点</th>
</tr>
</thead>
<tbody><tr>
<td>ELMO</td>
<td>BiLM</td>
<td>Bi-LSTM</td>
<td>单向</td>
<td>2个单向语言模型拼接</td>
</tr>
<tr>
<td>ULMFiT</td>
<td>LM</td>
<td>AWD-LSTM</td>
<td>单向</td>
<td>引入逐层解冻fine-tune中的灾难性问题</td>
</tr>
<tr>
<td>SiATL</td>
<td>LM</td>
<td>LSTM</td>
<td>单向</td>
<td>引入逐层解冻+辅助LM解决fine-tune中的灾难性问题</td>
</tr>
<tr>
<td>GPT1.0</td>
<td>LM</td>
<td>Transformer</td>
<td>单向</td>
<td>统一下游任务框架，验证Transformer在LM中的强大</td>
</tr>
<tr>
<td>GPT2.0</td>
<td>LM</td>
<td>Transformer</td>
<td>单向</td>
<td>没有特定的fine-tune流程，生成任务取得好的结果</td>
</tr>
<tr>
<td>BERT</td>
<td>MLM</td>
<td>Transformer</td>
<td>双向</td>
<td>MLM获取上下文相关的双向特征表示</td>
</tr>
<tr>
<td>MASS</td>
<td>LM+MLM</td>
<td>Transformer</td>
<td>单向/双向</td>
<td>改进BERT生成任务：统一为类seq2seq的预训练模型</td>
</tr>
<tr>
<td>UNILM</td>
<td>LM+MLM+S2SLM</td>
<td>Transformer</td>
<td>单向/双向</td>
<td>改进BERT生成任务，直接从mask矩阵的角度出发</td>
</tr>
<tr>
<td>ENRIE1.0</td>
<td>MLM（BPE）</td>
<td>Transformer</td>
<td>双向</td>
<td>引入知识：3种MASK策略（BPE）预测短语和实体</td>
</tr>
<tr>
<td>ENRIE</td>
<td>MLM+DEA</td>
<td>Transformer</td>
<td>双向</td>
<td>引入知识：讲实体向量和文本表示相融合</td>
</tr>
<tr>
<td>MTDNN</td>
<td>MLM</td>
<td>Transformer</td>
<td>双向</td>
<td>引入多任务学习：在下游阶段</td>
</tr>
<tr>
<td>ENRIE2.0</td>
<td>MLM+Multi-Task</td>
<td>Transformer</td>
<td>双向</td>
<td>引入多任务学习：在预训练阶段，连续增量学习</td>
</tr>
<tr>
<td>SpanBERT</td>
<td>MLM+SPO</td>
<td>Transformer</td>
<td>双向</td>
<td>不需要按照边界信息进行mask</td>
</tr>
<tr>
<td>RoBERTa</td>
<td>MLM</td>
<td>Transformer</td>
<td>双向</td>
<td>精细调参，舍弃NSP</td>
</tr>
<tr>
<td>XLNet</td>
<td>PLM</td>
<td>Transformer-XL</td>
<td>双向</td>
<td>排列语言模型+双注意力机制+Transformer</td>
</tr>
</tbody></table>
<h5 id="1-word2vec"><a href="#1-word2vec" class="headerlink" title="1. word2vec"></a>1. word2vec</h5><h5 id="2-ELMo"><a href="#2-ELMo" class="headerlink" title="2. ELMo"></a>2. ELMo</h5><p><img src="https://gitee.com/fushengwuyu1993/images/raw/master/imgs/1583220450290.png" alt="1583220450290"></p>
<ul>
<li><p>要点</p>
<ul>
<li>引入双向语言模型，2个单向的语言模型（向前和向后）的集成。</li>
<li>通过保存预训练好的2层BiLSTM，通过特征集成或finetune应用于下游任务。</li>
</ul>
</li>
<li><p>缺陷</p>
<ul>
<li>本质上是自回归语言模型，只能获取单向特征表示，不能同时获取上下文。</li>
<li>LSTM不能解决长距离依赖问题。</li>
</ul>
</li>
<li><p>为什么不能用BiLSTM构建双向语言模型</p>
<p>如果采用BiLSTM构建双向语言模型，会造成标签泄露的问题。因此ELMo前向和后向的LSTM参数独立，共享词向量，拼接构造语言模型。</p>
<p><img src="https://gitee.com/fushengwuyu1993/images/raw/master/imgs/1583461295578.png" alt="1583461295578"></p>
</li>
</ul>
<h5 id="3-GPT1-0-GPT2-0-OpenAI"><a href="#3-GPT1-0-GPT2-0-OpenAI" class="headerlink" title="3. GPT1.0/GPT2.0(OpenAI)"></a>3. GPT1.0/GPT2.0(OpenAI)</h5><ul>
<li><p>GPT1.0要点</p>
<ul>
<li><p>相比ELMo，将LSTM替换成了transformer，首次将Transformer应用与预训练模型。</p>
</li>
<li><p>finetune阶段引入语言模型辅助目标，解决finetune过程中的灾难性遗忘问题。</p>
</li>
</ul>
</li>
<li><p>GPT2.0要点</p>
<ul>
<li>不针对特定模型的精调过程：GPT2.0认为预训练中已经包含了许多特定任务所需的信息。</li>
<li>生成式任务效果比较好，使用了覆盖更广、质量更好的数据。</li>
</ul>
</li>
<li><p>缺点</p>
<ul>
<li>依然为单向的自回归语言模型，没有编码上下文的特征表示。</li>
</ul>
</li>
</ul>
<h5 id="4-BERT（重点介绍）"><a href="#4-BERT（重点介绍）" class="headerlink" title="4. BERT（重点介绍）"></a>4. BERT（重点介绍）</h5><ul>
<li><p>Transformer</p>
<p><img src="https://gitee.com/fushengwuyu1993/images/raw/master/imgs/1583486843525.png" alt="1583486843525"></p>
<p>$ Attention(Q,K,V) = softmax(\frac{QK^{T}}{\sqrt{d_{k}}})V$</p>
<ol>
<li><p>Multi-Head Attention和Scaled Dot-Product Attention</p>
<p>本质上是self attention通过attention mask动态编码变长序列，解决长依赖、无位置偏差、可并行计算。</p>
<ul>
<li><p>为什么是缩放点积，而不是点积模型？</p>
<p>当输入信息的维度较高时，点积模型的值通常有较大方差，从而导致softmax函数的梯度较小，因此缩放点积模型可以较好的解决这一问题。</p>
</li>
<li><p>为什么是双线性点积模型（经过线性变换$Q \ne K$）?</p>
<p>双线性点积模型，引入非对称性，根据健壮性（Attention mask对角线元素不一定是最大的，也就是说当前位置对自身的注意力得分不一定最高）。</p>
</li>
<li><p>相较与加性模型，点积模型具备哪些优势？</p>
<p>常用的attention机制有加性模型和点积模型，理论上两者的复杂度差不多，但是点积模型在实现上可以更好的利用矩阵乘积，从而效率更高。</p>
</li>
<li><p>多头机制为什么有效？</p>
<ul>
<li>类似于CNN中的通过多通道机制进行特征选择</li>
<li>Transformer中先通过切头（split），再分别进行Scale-Product Attention，可以使进行点积计算的维度d不会太大，同时缩小attention mask矩阵。</li>
</ul>
</li>
</ul>
</li>
<li><p>Position-wise Feed-Forward Networks</p>
<ul>
<li>FFN将每个位置的Multi-Head Attention结果隐射到一个更大的特征空间，然后使用ReLU引入非线性进行筛选，最后恢复原始维度。</li>
<li>Transformer放弃LSTM之后，FFN中的ReLU成为了一个主要的提供非线性变换的单元。</li>
</ul>
</li>
<li><p>Positional Encoding</p>
<p>Position Encoding是可学习的，编码范围不受限制。</p>
<p>$$PE_{(pos,2i)}=sin(pos/10000^{2i/d_{model}})$$</p>
<p>$$PE_{(pos,2i+1)}=cos(pos/10000^{2i/d_{model}})$$</p>
<ul>
<li>为什么引入$sin$和$cos$建模Position Encoding？<ol>
<li>为了使得模型实现相对位置的学习，两个位置pos和pos+k的位置编码是固定间距k的线性变化。</li>
<li>可以证明，间隔为k的任意两个位置编码的欧式距离是恒等的，只与k有关。</li>
</ol>
</li>
</ul>
</li>
</ol>
</li>
<li><p>BERT为什么如此有效？</p>
<ol>
<li>引入Masked Language Model（MLM）预训练目标，能够获取上下文相关的双向特征表示</li>
<li>引入Next Sentence Prediction（NSP）预训练目标，擅长处理句子或段落的匹配任务。</li>
<li>引入强大的特征抽取机制。<ul>
<li>Muti-Head self attention：多头机制类似于多通道特征抽取</li>
<li>self attention通过attention mask动态编码变长序列，解决长距离依赖、可并行计算</li>
<li>Feed-forward ：非线性层级特征</li>
<li>Layer Norm &amp; Residuals：加速训练，使深度网络更加健壮。</li>
</ul>
</li>
</ol>
<ul>
<li>BERT 通过不同的迁移学习应用与下游任务，BERT擅长处理NLU任务。</li>
<li>BERT通过MLM解决了深层BiLSTM构建双向模型中存在的‘标签泄露’问题，也就是‘see itself’。</li>
</ul>
</li>
<li><p>BERT的优缺点？</p>
<ul>
<li>优点：能够获取上下文相关的双向特征表示</li>
<li>缺点：<ul>
<li>生成任务表现不佳</li>
<li>采取独立性假设：没有考虑预测[MASK]之间的相关性，是对语言模型联合概率的有偏估计（不是密度估计）。</li>
<li>输入噪声[MASJ]，造成预训练-finetune两阶段之间的差异。</li>
<li>无法处理文档级别的NLP任务，只适合句子和段落级别的任务。</li>
</ul>
</li>
</ul>
</li>
<li><p>BERT基于‘字输入’还是‘词输入’好?(中文)</p>
<ol>
<li>如果基于’词输入‘，可能会出现’OOV‘问题，增大标签空间，需要利用更多预料去学习标签分布来拟合模型</li>
<li>随着Transformer特征抽取能力加强，分词不再成为必要，词级别的特征学习可以纳入内部特征进行表示学习。</li>
</ol>
</li>
</ul>
<h5 id="5-BERT改进系列模型"><a href="#5-BERT改进系列模型" class="headerlink" title="5. BERT改进系列模型"></a>5. BERT改进系列模型</h5><h6 id="5-1-改进生成任务"><a href="#5-1-改进生成任务" class="headerlink" title="5.1 改进生成任务"></a>5.1 改进生成任务</h6><ol>
<li><p>MASS</p>
<p><img src="https://gitee.com/fushengwuyu1993/images/raw/master/imgs/1583723052606.png" alt="1583723052606"></p>
<ul>
<li><p>统一预训练框架：通过类似于Seq2Seq的框架，在预训练阶段统一了BERT和LM模型</p>
</li>
<li><p>Encoder中理解unmasked tokens；Decoder中需要预测连续的[mask]tokens，获取更多的语言信息；Decoder从Encoder中抽取更多信息</p>
</li>
<li><p>当k=1或者n时，MASS的概率形式分别和BERT中的MLM以及GPT中标准的LM一致（k为mask的连续片段长度）</p>
</li>
</ul>
</li>
<li><p>UNILM</p>
<ul>
<li>统一预训练模型框架：直接从mask矩阵角度统一BERT和LM</li>
<li>3个Attention Mask矩阵：LM、MLM、Seq2Seq LM</li>
<li>UNILM中的LM并不是传统的LM模型，任需通过引入[MASK]实现。</li>
</ul>
</li>
</ol>
<h6 id="5-2-引入知识"><a href="#5-2-引入知识" class="headerlink" title="5.2 引入知识"></a>5.2 引入知识</h6><ol>
<li><p>ERNIE1.0(百度)</p>
<p>在预训练阶段引入知识（预先识别出的实体），引入三种[MASK]策略</p>
<ul>
<li>Basci-Level Masking：和BERT一样，对subword进行mask，无法获取高层次的语义。</li>
<li>Phrase-Level Masking：mask连续短语。</li>
<li>Entity-Level Masking：mask实体。</li>
</ul>
</li>
<li><p>ERNIE（THU）</p>
<p><img src="https://gitee.com/fushengwuyu1993/images/raw/master/imgs/1583731675001.png" alt="1583731675001"></p>
<ul>
<li>基于BERT预训练原生模型，讲文本中的实体对齐到外部的知识图谱，并通过知识嵌入得到实体向量作为ERNIR的输入。</li>
<li>由于语言表征的预训练过程和知识表征过程有很大的不同，会产生两个独立的向量空间，为解决这个问题，在有实体输入的位置，将实体向量和文本表示通过非线性变换进行融合，以融合词汇、句法和知识信息。</li>
<li>引入改进的预训练目标Denoising entity auto-encoder(DEA)：要求模型能够根据给定的实体序列和文本序列来预测对应的实体。</li>
</ul>
</li>
</ol>
<h6 id="5-3-引入多任务机制"><a href="#5-3-引入多任务机制" class="headerlink" title="5.3 引入多任务机制"></a>5.3 引入多任务机制</h6><p>​    多任务学习是指同时学习多个相关任务，让这些任务在学习过程中共享知识，利用多个任务之间的相关性来改善模型在每个任务的性能和泛华能力。</p>
<ol>
<li><p>MTDNN（微软）：在下游任务中引入多任务学习机制</p>
<p><img src="https://gitee.com/fushengwuyu1993/images/raw/master/imgs/1583732461374.png" alt="1583732461374"></p>
</li>
<li><p>ERNIE 2.0（百度）</p>
<p><img src="https://gitee.com/fushengwuyu1993/images/raw/master/imgs/1583735200104.png" alt="1583735200104"></p>
<ul>
<li>MTDNN是在下游任务引入多任务机制的，而ERNIE2.0是在预训练引入多任务学习（与先验知识库进行交互），使模型能够从不同的任务中学到更多的语言知识。</li>
<li>构建多个层次的任务全面捕捉训练预料中的词法、结构、语义的潜在知识。主要包含3个方面的任务：<ul>
<li>词法层面，word-aware任务：捕捉词汇层面的信息，如英文大小写预测。</li>
<li>结构层面，structure-aware任务：捕捉句法层次的信息，如句子顺序问题、句子距离问题。</li>
<li>语义层面，semantic-aware任务：捕捉语义方面的问题，如语义逻辑关系预测（因果，假设，递进，转折）。</li>
</ul>
</li>
<li>主要的方式是构建增量学习模型，通过多任务学习持续更新预训练模型，这种连续交替的学习范式不会使模型忘记之前学到的语言知识。</li>
</ul>
</li>
</ol>
<h6 id="5-4-改进mask策略"><a href="#5-4-改进mask策略" class="headerlink" title="5.4 改进mask策略"></a>5.4 改进mask策略</h6><p>​    原生BERT模型：按照subword维度进行mask，然后预测，局部的语言模型，缺乏全局建模的能力。</p>
<ul>
<li>BERT WWM(google)：进行whole word维度进行mask。</li>
<li>ERNIE系列：建模词、短语、实体的完整语义：通过先验知识将知识（短语、词、实体）进行整体mask；引入外部知识，按照entity维度进行mask，然后进行预测。</li>
<li>Span Bert：不需要按照先验的词、实体、短语等边界信息进行mask，而是采取随机mask<ul>
<li><strong>采用Span Masking</strong>：根据几何分布，随机选择一段空间长度，之后再根据均匀分布随机选择起始位置，最后按照长度mask，通过采样，平均被遮盖长度是3.8个词的长度。</li>
<li><strong>引入Span Boundary Objective</strong>：新的预训练目标旨在使被mask的Span 边界的词向量能学习到 Span中被mask的部分；新的预训练目标和MLM一起使用；</li>
</ul>
</li>
</ul>
<h6 id="5-5-精调"><a href="#5-5-精调" class="headerlink" title="5.5 精调"></a>5.5 精调</h6><ol>
<li>RoBERTa(FaceBook)<ul>
<li>丢弃NSP，效果更好</li>
<li>动态改变mask策略，把数据复制10份，然后统一进行随机mask</li>
<li>对学习率的峰值和warm-up跟新步数做出调整</li>
<li>在更长序列上训练，不对序列进行截断，使用全长度序列</li>
</ul>
</li>
</ol>
<h5 id="6-XLNet"><a href="#6-XLNet" class="headerlink" title="6. XLNet"></a>6. XLNet</h5><h6 id="6-1-提出的背景"><a href="#6-1-提出的背景" class="headerlink" title="6.1 提出的背景"></a>6.1 提出的背景</h6><ul>
<li>对于ELMO、GPT等预训练模型都是基于传统的语言模型（自回归语言模型AR），自回归语言模型天然适合处理生成任务，但是无法对双向上下文进行表征。</li>
<li>自编码语言模型（AE）虽然可以实现双向上下文表征，但是：<ul>
<li>BERT系列模型引入独立性假设，没有考虑预测[mask]之间的相关性。</li>
<li>MLM预训练目标的设置造成预训练过程和生成过程不一致。</li>
<li>预训练时的[mask]噪声在finetune阶段不会出现，造成两阶段不匹配问题。</li>
</ul>
</li>
</ul>
<h6 id="6-2-核心机制分析"><a href="#6-2-核心机制分析" class="headerlink" title="6.2 核心机制分析"></a>6.2 核心机制分析</h6><ul>
<li>使用自回归语言模型，为解决双向上下文问题，引入了排列语言模型PLM</li>
<li>PLM在预测时需要target的位置信息，此为引入了Two-Stream：Content流编码到当前时刻的所有内容，而Query流只能参考之前的历史信息以及当前要预测的位置信息。</li>
<li>为解决计算量过大的问题，采取随机采样语言排列+只预测1个句子后面的1/k的词。</li>
<li>融合Transformer-XL的优点处理长文本。</li>
</ul>
<ol>
<li><p>排列语言模型（Permutation LM，PLM）</p>
</li>
<li><p>Two-Stream Self-Attention</p>
</li>
<li><p>融入Transformer-XL</p>
</li>
</ol>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2021/07/20/tensorflow%20serving/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="sunshine">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="浮生物语的博客">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2021/07/20/tensorflow%20serving/" class="post-title-link" itemprop="url">tensorflow serving 总结文档</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2021-07-20 00:00:00" itemprop="dateCreated datePublished" datetime="2021-07-20T00:00:00+08:00">2021-07-20</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2021-08-20 11:35:02" itemprop="dateModified" datetime="2021-08-20T11:35:02+08:00">2021-08-20</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E8%BF%90%E7%BB%B4/" itemprop="url" rel="index"><span itemprop="name">运维</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h5 id="1-准备模型"><a href="#1-准备模型" class="headerlink" title="1. 准备模型"></a>1. 准备模型</h5><p>使用tf.keras训练一个简单的线性回归模型，保存为protobuf文件。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras <span class="keyword">import</span> models,layers,optimizers</span><br><span class="line"></span><br><span class="line"><span class="comment">## 样本数量</span></span><br><span class="line">n = <span class="number">800</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## 生成测试用数据集</span></span><br><span class="line">X = tf.random.uniform([n,<span class="number">2</span>],minval=-<span class="number">10</span>,maxval=<span class="number">10</span>) </span><br><span class="line">w0 = tf.constant([[<span class="number">2.0</span>],[-<span class="number">1.0</span>]])</span><br><span class="line">b0 = tf.constant(<span class="number">3.0</span>)</span><br><span class="line"></span><br><span class="line">Y = X@w0 + b0 + tf.random.normal([n,<span class="number">1</span>],</span><br><span class="line">    mean = <span class="number">0.0</span>,stddev= <span class="number">2.0</span>) <span class="comment"># @表示矩阵乘法,增加正态扰动</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## 建立模型</span></span><br><span class="line">tf.keras.backend.clear_session()</span><br><span class="line">inputs = layers.Input(shape = (<span class="number">2</span>,),name =<span class="string">&quot;inputs&quot;</span>) <span class="comment">#设置输入名字为inputs</span></span><br><span class="line">outputs = layers.Dense(<span class="number">1</span>, name = <span class="string">&quot;outputs&quot;</span>)(inputs) <span class="comment">#设置输出名字为outputs</span></span><br><span class="line">linear = models.Model(inputs = inputs,outputs = outputs)</span><br><span class="line">linear.summary()</span><br><span class="line"></span><br><span class="line"><span class="comment">## 使用fit方法进行训练</span></span><br><span class="line">linear.<span class="built_in">compile</span>(optimizer=<span class="string">&quot;rmsprop&quot;</span>,loss=<span class="string">&quot;mse&quot;</span>,metrics=[<span class="string">&quot;mae&quot;</span>])</span><br><span class="line">linear.fit(X,Y,batch_size = <span class="number">8</span>,epochs = <span class="number">100</span>)  </span><br><span class="line"></span><br><span class="line">tf.<span class="built_in">print</span>(<span class="string">&quot;w = &quot;</span>,linear.layers[<span class="number">1</span>].kernel)</span><br><span class="line">tf.<span class="built_in">print</span>(<span class="string">&quot;b = &quot;</span>,linear.layers[<span class="number">1</span>].bias)</span><br><span class="line"></span><br><span class="line"><span class="comment">## 将模型保存成pb格式文件</span></span><br><span class="line">export_path = <span class="string">&quot;linear_model/&quot;</span></span><br><span class="line">version = <span class="string">&quot;1&quot;</span>       <span class="comment">#后续可以通过版本号进行模型版本迭代与管理</span></span><br><span class="line">linear.save(export_path+version, save_format=<span class="string">&quot;tf&quot;</span>) </span><br></pre></td></tr></table></figure>

<p>查看模型</p>
<blockquote>
<p>saved_model_cli show –dir=’linear_model/1’ –all</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br></pre></td><td class="code"><pre><span class="line">MetaGraphDef <span class="keyword">with</span> tag-<span class="built_in">set</span>: <span class="string">&#x27;serve&#x27;</span> contains the following SignatureDefs:</span><br><span class="line"></span><br><span class="line">signature_def[<span class="string">&#x27;__saved_model_init_op&#x27;</span>]:</span><br><span class="line">  The given SavedModel SignatureDef contains the following <span class="built_in">input</span>(s):</span><br><span class="line">  The given SavedModel SignatureDef contains the following output(s):</span><br><span class="line">    outputs[<span class="string">&#x27;__saved_model_init_op&#x27;</span>] tensor_info:</span><br><span class="line">        dtype: DT_INVALID</span><br><span class="line">        shape: unknown_rank</span><br><span class="line">        name: NoOp</span><br><span class="line">  Method name <span class="keyword">is</span>: </span><br><span class="line"></span><br><span class="line">signature_def[<span class="string">&#x27;serving_default&#x27;</span>]:   <span class="comment"># 注意signature_def</span></span><br><span class="line">  The given SavedModel SignatureDef contains the following <span class="built_in">input</span>(s):</span><br><span class="line">    inputs[<span class="string">&#x27;inputs&#x27;</span>] tensor_info:   <span class="comment"># 注意inputs</span></span><br><span class="line">        dtype: DT_FLOAT</span><br><span class="line">        shape: (-<span class="number">1</span>, <span class="number">2</span>)</span><br><span class="line">        name: serving_default_inputs:<span class="number">0</span></span><br><span class="line">  The given SavedModel SignatureDef contains the following output(s):</span><br><span class="line">    outputs[<span class="string">&#x27;outputs&#x27;</span>] tensor_info:</span><br><span class="line">        dtype: DT_FLOAT</span><br><span class="line">        shape: (-<span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">        name: StatefulPartitionedCall:<span class="number">0</span></span><br><span class="line">  Method name <span class="keyword">is</span>: tensorflow/serving/predict</span><br><span class="line">WARNING:tensorflow:From /usr/local/lib/python3<span class="number">.6</span>/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:<span class="number">1786</span>: calling BaseResourceVariable.__init__ (<span class="keyword">from</span> tensorflow.python.ops.resource_variable_ops) <span class="keyword">with</span> constraint <span class="keyword">is</span> deprecated <span class="keyword">and</span> will be removed <span class="keyword">in</span> a future version.</span><br><span class="line">Instructions <span class="keyword">for</span> updating:</span><br><span class="line">If using Keras <span class="keyword">pass</span> *_constraint arguments to layers.</span><br><span class="line"></span><br><span class="line">Defined Functions:</span><br><span class="line">  Function Name: <span class="string">&#x27;__call__&#x27;</span></span><br><span class="line">    Option <span class="comment">#1</span></span><br><span class="line">      <span class="type">Callable</span> <span class="keyword">with</span>:</span><br><span class="line">        Argument <span class="comment">#1</span></span><br><span class="line">          inputs: TensorSpec(shape=(<span class="literal">None</span>, <span class="number">2</span>), dtype=tf.float32, name=<span class="string">&#x27;inputs&#x27;</span>)</span><br><span class="line">        Argument <span class="comment">#2</span></span><br><span class="line">          DType: <span class="built_in">bool</span></span><br><span class="line">          Value: <span class="literal">True</span></span><br><span class="line">        Argument <span class="comment">#3</span></span><br><span class="line">          DType: NoneType</span><br><span class="line">          Value: <span class="literal">None</span></span><br><span class="line">    Option <span class="comment">#2</span></span><br><span class="line">      <span class="type">Callable</span> <span class="keyword">with</span>:</span><br><span class="line">        Argument <span class="comment">#1</span></span><br><span class="line">          inputs: TensorSpec(shape=(<span class="literal">None</span>, <span class="number">2</span>), dtype=tf.float32, name=<span class="string">&#x27;inputs&#x27;</span>)</span><br><span class="line">        Argument <span class="comment">#2</span></span><br><span class="line">          DType: <span class="built_in">bool</span></span><br><span class="line">          Value: <span class="literal">False</span></span><br><span class="line">        Argument <span class="comment">#3</span></span><br><span class="line">          DType: NoneType</span><br><span class="line">          Value: <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">  Function Name: <span class="string">&#x27;_default_save_signature&#x27;</span></span><br><span class="line">    Option <span class="comment">#1</span></span><br><span class="line">      <span class="type">Callable</span> <span class="keyword">with</span>:</span><br><span class="line">        Argument <span class="comment">#1</span></span><br><span class="line">          inputs: TensorSpec(shape=(<span class="literal">None</span>, <span class="number">2</span>), dtype=tf.float32, name=<span class="string">&#x27;inputs&#x27;</span>)</span><br><span class="line"></span><br><span class="line">  Function Name: <span class="string">&#x27;call_and_return_all_conditional_losses&#x27;</span></span><br><span class="line">    Option <span class="comment">#1</span></span><br><span class="line">      <span class="type">Callable</span> <span class="keyword">with</span>:</span><br><span class="line">        Argument <span class="comment">#1</span></span><br><span class="line">          inputs: TensorSpec(shape=(<span class="literal">None</span>, <span class="number">2</span>), dtype=tf.float32, name=<span class="string">&#x27;inputs&#x27;</span>)</span><br><span class="line">        Argument <span class="comment">#2</span></span><br><span class="line">          DType: <span class="built_in">bool</span></span><br><span class="line">          Value: <span class="literal">False</span></span><br><span class="line">        Argument <span class="comment">#3</span></span><br><span class="line">          DType: NoneType</span><br><span class="line">          Value: <span class="literal">None</span></span><br><span class="line">    Option <span class="comment">#2</span></span><br><span class="line">      <span class="type">Callable</span> <span class="keyword">with</span>:</span><br><span class="line">        Argument <span class="comment">#1</span></span><br><span class="line">          inputs: TensorSpec(shape=(<span class="literal">None</span>, <span class="number">2</span>), dtype=tf.float32, name=<span class="string">&#x27;inputs&#x27;</span>)</span><br><span class="line">        Argument <span class="comment">#2</span></span><br><span class="line">          DType: <span class="built_in">bool</span></span><br><span class="line">          Value: <span class="literal">True</span></span><br><span class="line">        Argument <span class="comment">#3</span></span><br><span class="line">          DType: NoneType</span><br><span class="line">          Value: <span class="literal">None</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>注意：请牢记上面的signature_def值和inputs值及其shape，在grpc调用的时候需要用到。</p>
<h5 id="2-tensorflow-serving-docker方式安装"><a href="#2-tensorflow-serving-docker方式安装" class="headerlink" title="2. tensorflow/serving docker方式安装"></a>2. tensorflow/serving docker方式安装</h5><ol>
<li><p>拉取镜像</p>
<blockquote>
<p> docker pull tensorflow/serving:latest</p>
</blockquote>
<p>在docker hub中有四中镜像。</p>
<ul>
<li>:latest</li>
<li>:lasest-gpu</li>
<li>:lasest-devel</li>
<li>:lasest-devel-gpu</li>
</ul>
<p>两种划分共有4种镜像。CPU、GPU、稳定版、开发版。稳定版在dockerfile中启动tensorflow_model_server服务，创建容器即启动服务。开发版需要在创建容器之后，进入容器，手动启动tensorflow_model_server服务。</p>
<p>以下都已稳定版为例。</p>
</li>
<li><p>启动容器</p>
<blockquote>
<p>docker run -t -p 8501:8501 -p 8500:8500 -v /root/mutimodel/linear_model:/models/linear_model -e MODEL_NAME=linear_model tensorflow/serving</p>
</blockquote>
<p> ==备注：路径只需到模型这一级，不能精确到版本级别，比如：/root/mutimodel/linear_model而不是/root/mutimodel/linear_model/1，服务会默认加载最大版本号的模型。==</p>
<p> 参数解释：</p>
<ul>
<li><p>-p : 端口映射，tensorflow serving提供了两种调用方式：gRPC和REST，<br>gRPC的默认端口是8500，REST的默认端口是8501.</p>
</li>
<li><p>-v：目录映射，需要注意的是，在新版的docker中，已经移除了–mount type=bind,source=%source_path,target=$target_path的挂载目录方式。</p>
</li>
<li><p>-e：设置变量。</p>
<ul>
<li>可选参数: MODLE_NAME（默认值：model）</li>
<li>可选参数：MODEL_BASE_PATH（默认值/models）</li>
</ul>
<p>启动容器之后，相当于在容器中启动服务：</p>
<blockquote>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tensorflow_model_server --port=8500 --rest_api_port=8501 --model_name=$&#123;MODEL_NAME&#125; --model_base_path=$&#123;MODEL_BASE_PATH&#125;/$&#123;MODEL_NAME&#125;</span><br></pre></td></tr></table></figure></blockquote>
</li>
</ul>
<p> 如果需要修改相关参数配置，可以通过如下命令：</p>
<blockquote>
<p>docker run -p 8501:8501 -v /root/mutimodel/linear_model:/models/linear_model -t –entrypoint=tensorflow_model_server tensorflow/serving  –port=8500 –model_name=linear_model –model_base_path=/models/linear_model –rest_api_port=8501</p>
</blockquote>
<p> 参数解释：</p>
<ul>
<li>-t –entrypoint=tensorflow_model_server tensorflow/serving：如果使用稳定版的docker，启动docker之后是不能进入容器内部bash环境的，–entrypoint的作用是允许你“间接”进入容器内部，然后调用tensorflow_model_server命令来启动TensorFlow Serving，这样才能输入后面的参数。</li>
</ul>
<p> tensorflow serving的详细参数如下：</p>
 <figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">Flags:</span><br><span class="line">    --port=8500                         int32   Port to listen on for gRPC API</span><br><span class="line">    --grpc_socket_path=&quot;&quot;               string  If non-empty, listen to a UNIX socket for gRPC API on the given path. Can be either relative or absolute path.</span><br><span class="line">    --rest_api_port=0                   int32   Port to listen on for HTTP/REST API. If set to zero HTTP/REST API will not be exported. This port must be different than the one specified in --port.</span><br><span class="line">    --rest_api_num_threads=16           int32   Number of threads for HTTP/REST API processing. If not set, will be auto set based on number of CPUs.</span><br><span class="line">    --rest_api_timeout_in_ms=30000      int32   Timeout for HTTP/REST API calls.</span><br><span class="line">    --enable_batching=false             bool    enable batching</span><br><span class="line">    --batching_parameters_file=&quot;&quot;       string  If non-empty, read an ascii BatchingParameters protobuf from the supplied file name and use the contained values instead of the defaults.</span><br><span class="line">    --model_config_file=&quot;&quot;              string  If non-empty, read an ascii ModelServerConfig protobuf from the supplied file name, and serve the models in that file. This config file can be used to specify multiple models to serve and other advanced parameters including non-default version policy. (If used, --model_name, --model_base_path are ignored.)</span><br><span class="line">    --model_name=&quot;default&quot;              string  name of model (ignored if --model_config_file flag is set)</span><br><span class="line">    --model_base_path=&quot;&quot;                string  path to export (ignored if --model_config_file flag is set, otherwise required)</span><br><span class="line">    --max_num_load_retries=5            int32   maximum number of times it retries loading a model after the first failure, before giving up. If set to 0, a load is attempted only once. Default: 5</span><br><span class="line">    --load_retry_interval_micros=60000000   int64   The interval, in microseconds, between each servable load retry. If set negative, it doesn&#x27;t wait. Default: 1 minute</span><br><span class="line">    --file_system_poll_wait_seconds=1   int32   Interval in seconds between each poll of the filesystem for new model version. If set to zero poll will be exactly done once and not periodically. Setting this to negative value will disable polling entirely causing ModelServer to indefinitely wait for a new model at startup. Negative values are reserved for testing purposes only.</span><br><span class="line">    --flush_filesystem_caches=true      bool    If true (the default), filesystem caches will be flushed after the initial load of all servables, and after each subsequent individual servable reload (if the number of load threads is 1). This reduces memory consumption of the model server, at the potential cost of cache misses if model files are accessed after servables are loaded.</span><br><span class="line">    --tensorflow_session_parallelism=0  int64   Number of threads to use for running a Tensorflow session. Auto-configured by default.Note that this option is ignored if --platform_config_file is non-empty.</span><br><span class="line">    --tensorflow_intra_op_parallelism=0 int64   Number of threads to use to parallelize the executionof an individual op. Auto-configured by default.Note that this option is ignored if --platform_config_file is non-empty.</span><br><span class="line">    --tensorflow_inter_op_parallelism=0 int64   Controls the number of operators that can be executed simultaneously. Auto-configured by default.Note that this option is ignored if --platform_config_file is non-empty.</span><br><span class="line">    --ssl_config_file=&quot;&quot;                string  If non-empty, read an ascii SSLConfig protobuf from the supplied file name and set up a secure gRPC channel</span><br><span class="line">    --platform_config_file=&quot;&quot;           string  If non-empty, read an ascii PlatformConfigMap protobuf from the supplied file name, and use that platform config instead of the Tensorflow platform. (If used, --enable_batching is ignored.)</span><br><span class="line">    --per_process_gpu_memory_fraction=0.000000  float   Fraction that each process occupies of the GPU memory space the value is between 0.0 and 1.0 (with 0.0 as the default) If 1.0, the server will allocate all the memory when the server starts, If 0.0, Tensorflow will automatically select a value.</span><br><span class="line">    --saved_model_tags=&quot;serve&quot;          string  Comma-separated set of tags corresponding to the meta graph def to load from SavedModel.</span><br><span class="line">    --grpc_channel_arguments=&quot;&quot;         string  A comma separated list of arguments to be passed to the grpc server. (e.g. grpc.max_connection_age_ms=2000)</span><br><span class="line">    --enable_model_warmup=true          bool    Enables model warmup, which triggers lazy initializations (such as TF optimizations) at load time, to reduce first request latency.</span><br><span class="line">    --version=false                     bool    Display version</span><br></pre></td></tr></table></figure>

<p> 容器启动成功。</p>
<blockquote>
<p>…<br>tensorflow_serving/servables/tensorflow/saved_model_warmup.cc:105] No warmup data file found at /models/linear_model/1/assets.extra/tf_serving_warmup_requests<br>2020-03-19 01:25:24.979107: I tensorflow_serving/core/loader_harness.cc:87] Successfully loaded servable version {name: linear_model version: 1}<br>2020-03-19 01:25:24.982357: I tensorflow_serving/model_servers/server.cc:358] Running gRPC ModelServer at 0.0.0.0:8500 …<br>2020-03-19 01:25:24.982960: I tensorflow_serving/model_servers/server.cc:378] Exporting HTTP/REST API at:localhost:8501 …<br>[evhttp_server.cc : 238] NET_LOG: Entering the event loop …</p>
</blockquote>
<p> 可以看到，启动了grpc的8500端口和RESR的8501端口。</p>
</li>
</ol>
<h5 id="2-REST调用"><a href="#2-REST调用" class="headerlink" title="2. REST调用"></a>2. REST调用</h5><ul>
<li></li>
</ul>
<p>​    REST api方式调用很简单，可以通过curl或者postman发送一个post请求，也可以用python的requests模拟一个post请求。这里我们使用postman工具。</p>
<p><img src="/home/sunshine/Documents/%E5%8D%9A%E5%AE%A2/assets/1584583823994.png" alt="1584583823994"></p>
<p>​    可以看到正确返回结果。</p>
<p>​    注意事项：</p>
<ul>
<li>请求参数：“inputs”，这里对应于模型中的signature_def下面的inputs值。</li>
<li>参数形状：参见tensor_info的shape：（-1, 2）。</li>
<li>参数类型：参见tensor_info的dtype：DT_FLOAT（对应于np.float32）</li>
</ul>
<h5 id="3-grpc调用"><a href="#3-grpc调用" class="headerlink" title="3. grpc调用"></a>3. grpc调用</h5><ol>
<li><p>安装相应的包</p>
<blockquote>
<p> pip install tensorflow-serving-api</p>
</blockquote>
</li>
<li><p>编写代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> grpc</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> tensorflow_serving.apis <span class="keyword">import</span> predict_pb2</span><br><span class="line"><span class="keyword">from</span> tensorflow_serving.apis <span class="keyword">import</span> prediction_service_pb2_grpc</span><br><span class="line"></span><br><span class="line">options = [(<span class="string">&#x27;grpc.max_send_message_length&#x27;</span>, <span class="number">1000</span> * <span class="number">1024</span> * <span class="number">1024</span>),</span><br><span class="line">           (<span class="string">&#x27;grpc.max_receive_message_length&#x27;</span>, <span class="number">1000</span> * <span class="number">1024</span> * <span class="number">1024</span>)]</span><br><span class="line"></span><br><span class="line">channel = grpc.insecure_channel(<span class="string">&#x27;ip:8500&#x27;</span>, options=options)</span><br><span class="line">stub = prediction_service_pb2_grpc.PredictionServiceStub(channel)</span><br><span class="line"></span><br><span class="line">x = [[<span class="number">1.0</span>, <span class="number">2.0</span>]]</span><br><span class="line"></span><br><span class="line">request = predict_pb2.PredictRequest()</span><br><span class="line">request.model_spec.name = <span class="string">&quot;linear_model&quot;</span></span><br><span class="line">request.model_spec.signature_name = <span class="string">&#x27;serving_default&#x27;</span></span><br><span class="line">request.inputs[<span class="string">&#x27;inputs&#x27;</span>].CopyFrom(tf.make_tensor_proto(x, shape=(<span class="number">1</span>, <span class="number">2</span>)))</span><br><span class="line">response = stub.Predict(request, <span class="number">10.0</span>)</span><br><span class="line">output = tf.make_ndarray(response.outputs[<span class="string">&quot;outputs&quot;</span>])[<span class="number">0</span>][<span class="number">0</span>]</span><br><span class="line"><span class="built_in">print</span>(output)</span><br></pre></td></tr></table></figure>

<p>注意事项：</p>
<ul>
<li>request.model_spec.name：模型名</li>
<li>request.model_spec.signature_name：必须与模型中定义的一致，参照signature_def值（参见第一节查看模型）</li>
<li>request.inputs[‘inputs’]：inputs的key参见tensor_info的inputs值（第一节查看模型）</li>
</ul>
</li>
</ol>
<h5 id="4-多模型部署"><a href="#4-多模型部署" class="headerlink" title="4. 多模型部署"></a>4. 多模型部署</h5><p>​    单一模型部署，上面的方式即可完成。对于多个模型统一部署，基本流程与单模型一致，不同之处在于需要借助模型的配置文件来完成。</p>
<ol>
<li>model.config</li>
</ol>
<p>新建mutimodel文件夹，放置多个模型，并建一配置文件model.config.</p>
<blockquote>
<p>mutimodel</p>
<p>├── linear_model<br>│   └── 1<br>│       ├── assets<br>│       ├── saved_model.pb<br>│       └── variables<br>│           ├── variables.data-00000-of-00001<br>│           └── variables.index<br>├── model.config<br>├── router_model<br>│   └── 1<br>│       ├── assets<br>│       ├── saved_model.pb<br>│       └── variables<br>│           ├── variables.data-00000-of-00001<br>│           └── variables.index<br>└── textcnn_model<br>    └── 1<br>        ├── assets<br>        ├── saved_model.pb<br>        └── variables<br>            ├── variables.data-00000-of-00001<br>            └── variables.index</p>
<p>12 directories, 10 files</p>
</blockquote>
<p>​    model.conf配置如下：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">model_config_list &#123;</span><br><span class="line">  config &#123;</span><br><span class="line">    name: &#x27;linear&#x27;,</span><br><span class="line">    model_platform: &quot;tensorflow&quot;,</span><br><span class="line">    base_path: &#x27;/models/mutimodel/linear_model&#x27;</span><br><span class="line">  &#125;,</span><br><span class="line">  config &#123;</span><br><span class="line">    name: &#x27;textcnn&#x27;,</span><br><span class="line">    model_platform: &quot;tensorflow&quot;,</span><br><span class="line">    base_path: &#x27;/models/mutimodel/textcnn_model&#x27;</span><br><span class="line">  &#125;,</span><br><span class="line">  config &#123;</span><br><span class="line">    name: &#x27;router&#x27;,</span><br><span class="line">    model_platform: &quot;tensorflow&quot;,</span><br><span class="line">    base_path: &#x27;/models/mutimodel/router_model&#x27;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<ol start="2">
<li>启动容器</li>
</ol>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker run -p 8501:8501 -p 8500:8500 -v /root/mutimodel/:/models/mutimodel  -t tensorflow/serving --model_config_file=/models/mutimodel/model.config</span><br></pre></td></tr></table></figure>

<blockquote>
<p>…<br>2020-03-19 0/models/mutimodel/router_model/1/assets.extra/tf_serving_warmup_requests<br>2020-03-19 02:42:58.197083: I tensorflow_serving/core/loader_harness.cc:87] Successfully loaded servable version {name: router version: 1}<br>2020-03-19 02:42:58.199987: I tensorflow_serving/model_servers/server.cc:358] Running gRPC ModelServer at 0.0.0.0:8500 …<br>2020-03-19 02:42:58.200632: I tensorflow_serving/model_servers/server.cc:378] Exporting HTTP/REST API at:localhost:8501 …<br>[evhttp_server.cc : 238] NET_LOG: Entering the event loop …</p>
</blockquote>
<p>REST api 测试。</p>
<p><img src="/home/sunshine/Documents/%E5%8D%9A%E5%AE%A2/assets/1584585981550.png" alt="1584585981550"></p>
<p>正常访问。</p>
<h5 id="5-版本控制"><a href="#5-版本控制" class="headerlink" title="5. 版本控制"></a>5. 版本控制</h5><ol>
<li><p>服务端配置</p>
<p>tensorflow serving服务默认只会读取最大版本号的版本（按数字来标记版本号），实际上，我们可以通过提供不同的版本的模型，比如提供稳定版、测试版，来实现版本控制，只需要在在配置文件中配置model_version_policy。</p>
<figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">model_config_list &#123;</span><br><span class="line">  config &#123;</span><br><span class="line">    name: &#x27;linear&#x27;,</span><br><span class="line">    model_platform: &quot;tensorflow&quot;,</span><br><span class="line">    base_path: &#x27;/models/mutimodel/linear_model&#x27;</span><br><span class="line">    model_version_policy&#123;</span><br><span class="line">      specific&#123;</span><br><span class="line">            version: 1,</span><br><span class="line">            version: 2</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    version_labels&#123;</span><br><span class="line">        key: &quot;stable&quot;,</span><br><span class="line">        value: 1    </span><br><span class="line">    &#125;</span><br><span class="line">    version_labels&#123;</span><br><span class="line">        key: &quot;test&quot;,</span><br><span class="line">        value: 2    </span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>这里我们同时提供版本号为1和版本号为2的版本，并分别为其取别名stable和test。这样做的好处在于，用户只需要定向到stable或者test版本，而不必关心具体的某个版本号，同时，在不通知用户的情况下，可以调整版本号，比如版本2稳定后，可以升级为稳定版，只需要将stable对应的value改为2即可。同样，若需要版本回滚，将value修改为之前的1即可。</p>
<p>启动服务</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker run -p 8501:8501 -p 8500:8500 -v /root/mutimodel/:/models/mutimodel  -t tensorflow/serving --model_config_file=/models/mutimodel/model.config --allow_version_labels_for_unavailable_models=true</span><br></pre></td></tr></table></figure>

<p>说明：根据官方说明，添加别名只能针对已经加载的模型（先启动服务，再更新配置文件），若想在启动服务的时候设置别名，需要设置allow_version_labels_for_unavailable_models=true。</p>
<p>官方说明如下：</p>
<blockquote>
<p>Please note that labels can only be assigned to model versions that are <em>already</em> loaded and available for serving. Once a model version is available, one may reload the model config on the fly to assign a label to it. This can be achieved using a<a target="_blank" rel="noopener" href="https://github.com/tensorflow/serving/blob/master/tensorflow_serving/apis/model_service.proto#L22">HandleReloadConfigRequest</a> RPC or if the server is set up to periodically poll the filesystem for the config file, as described <a target="_blank" rel="noopener" href="https://www.tensorflow.org/tfx/serving/serving_config#reloading_model_server_configuration">above</a>.</p>
<p>If you would like to assign a label to a version that is not yet loaded (for ex. by supplying both the model version and the label at startup time) then you must set the <code>--allow_version_labels_for_unavailable_models</code> flag to true, which allows new labels to be assigned to model versions that are not loaded yet.</p>
</blockquote>
</li>
<li><p>客户端调用</p>
<p>特别说明：version_label设置别名的方式只适用于grpc调用方式，而不适用与REST调用。</p>
<ul>
<li><p>REST 调用，直接制定版本号。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">curl -d &#x27;&#123;&quot;inputs&quot;:[[1.0, 2.0]]&#125;&#x27; -X POST http://localhost:8501/v1/models/linear/versions/1:predict</span><br><span class="line">&#123;</span><br><span class="line">    &quot;outputs&quot;: [</span><br><span class="line">        [</span><br><span class="line">            2.18523026</span><br><span class="line">        ]</span><br><span class="line">    ]</span><br></pre></td></tr></table></figure></li>
<li><p>gRPC方式</p>
<p>使用别名：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">channel = grpc.insecure_channel(<span class="string">&#x27;49.233.155.170:8500&#x27;</span>)</span><br><span class="line">stub = prediction_service_pb2_grpc.PredictionServiceStub(channel)</span><br><span class="line">x = [[<span class="number">1.0</span>, <span class="number">2.0</span>]]</span><br><span class="line">request = predict_pb2.PredictRequest()</span><br><span class="line">request.model_spec.name = <span class="string">&quot;linear&quot;</span></span><br><span class="line">request.model_spec.version_label = <span class="string">&quot;stable&quot;</span></span><br><span class="line">request.model_spec.signature_name = <span class="string">&#x27;serving_default&#x27;</span></span><br><span class="line">request.inputs[<span class="string">&#x27;inputs&#x27;</span>].CopyFrom(tf.make_tensor_proto(x, shape=(<span class="number">1</span>, <span class="number">2</span>)))</span><br><span class="line">response = stub.Predict(request, <span class="number">10.0</span>)</span><br><span class="line">output = tf.make_ndarray(response.outputs[<span class="string">&quot;outputs&quot;</span>])[<span class="number">0</span>][<span class="number">0</span>]</span><br><span class="line"><span class="built_in">print</span>(output)</span><br></pre></td></tr></table></figure>

<p>使用版本号：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">channel = grpc.insecure_channel(<span class="string">&#x27;49.233.155.170:8500&#x27;</span>)</span><br><span class="line">stub = prediction_service_pb2_grpc.PredictionServiceStub(channel)</span><br><span class="line">x = [[<span class="number">1.0</span>, <span class="number">2.0</span>]]</span><br><span class="line">request = predict_pb2.PredictRequest()</span><br><span class="line">request.model_spec.name = <span class="string">&quot;linear&quot;</span></span><br><span class="line">request.model_spec.version.value = <span class="number">1</span></span><br><span class="line">request.model_spec.signature_name = <span class="string">&#x27;serving_default&#x27;</span></span><br><span class="line">request.inputs[<span class="string">&#x27;inputs&#x27;</span>].CopyFrom(tf.make_tensor_proto(x, shape=(<span class="number">1</span>, <span class="number">2</span>)))</span><br><span class="line">response = stub.Predict(request, <span class="number">10.0</span>)</span><br><span class="line">output = tf.make_ndarray(response.outputs[<span class="string">&quot;outputs&quot;</span>])[<span class="number">0</span>][<span class="number">0</span>]</span><br><span class="line"><span class="built_in">print</span>(output)</span><br></pre></td></tr></table></figure>

<p>==区别：model_spec.version_label与model_spec.version.value。==</p>
</li>
</ul>
</li>
</ol>
<h5 id="6-热更新"><a href="#6-热更新" class="headerlink" title="6. 热更新"></a>6. 热更新</h5><p>服务启动后，可以通过重新加载配置文件的方式来实现模型的热更新。可以通过一下两种方式来实现。</p>
<ol>
<li><p><a target="_blank" rel="noopener" href="https://github.com/tensorflow/serving/blob/master/tensorflow_serving/apis/model_service.proto#L22">HandleReloadConfigRequest</a> （grpc）</p>
<p>比如我们想新增模型textcnn和router。先更新其配置文件model.config为：</p>
<figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">model_config_list &#123;</span><br><span class="line">  config &#123;</span><br><span class="line">    name: &quot;linear&quot;</span><br><span class="line">    base_path: &quot;/models/mutimodel/linear_model&quot;</span><br><span class="line">    model_platform: &quot;tensorflow&quot;</span><br><span class="line">    model_version_policy &#123;</span><br><span class="line">      specific &#123;</span><br><span class="line">        versions: 1</span><br><span class="line">        versions: 2</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    version_labels &#123;</span><br><span class="line">      key: &quot;stable&quot;</span><br><span class="line">      value: 1</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  config &#123;</span><br><span class="line">    name: &quot;textcnn&quot;</span><br><span class="line">    base_path: &quot;/models/mutimodel/textcnn_model&quot;</span><br><span class="line">    model_platform: &quot;tensorflow&quot;</span><br><span class="line">  &#125;</span><br><span class="line">  config &#123;</span><br><span class="line">    name: &quot;router&quot;</span><br><span class="line">    base_path: &quot;/models/mutimodel/router_model&quot;</span><br><span class="line">    model_platform: &quot;tensorflow&quot;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>gRPC代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> google.protobuf <span class="keyword">import</span> text_format</span><br><span class="line"><span class="keyword">from</span> tensorflow_serving.apis <span class="keyword">import</span> model_management_pb2</span><br><span class="line"><span class="keyword">from</span> tensorflow_serving.apis <span class="keyword">import</span> model_service_pb2_grpc</span><br><span class="line"><span class="keyword">from</span> tensorflow_serving.config <span class="keyword">import</span> model_server_config_pb2</span><br><span class="line"></span><br><span class="line">config_file = <span class="string">&quot;model.config&quot;</span></span><br><span class="line">stub = model_service_pb2_grpc.ModelServiceStub(channel)</span><br><span class="line">request = model_management_pb2.ReloadConfigRequest()</span><br><span class="line"></span><br><span class="line"><span class="comment"># # read config file</span></span><br><span class="line">config_content = <span class="built_in">open</span>(config_file, <span class="string">&quot;r&quot;</span>).read()</span><br><span class="line">model_server_config = model_server_config_pb2.ModelServerConfig()</span><br><span class="line">model_server_config = text_format.Parse(text=config_content, message=model_server_config)</span><br><span class="line">request.config.CopyFrom(model_server_config)</span><br><span class="line">request_response = stub.HandleReloadConfigRequest(request, <span class="number">10</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> request_response.status.error_code == <span class="number">0</span>:</span><br><span class="line">    <span class="built_in">open</span>(config_file, <span class="string">&quot;w&quot;</span>).write(<span class="built_in">str</span>(request.config))</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;TF Serving config file updated.&quot;</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;Failed to update config file.&quot;</span>)</span><br><span class="line">        <span class="built_in">print</span>(request_response.status.error_code)</span><br><span class="line">        <span class="built_in">print</span>(request_response.status.error_message)</span><br></pre></td></tr></table></figure>

<p>测试textcnn模型。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">   </span><br><span class="line">(train_data, train_labels), (test_data, test_labels) = datasets.imdb.load_data(num_words=<span class="number">10000</span>)</span><br><span class="line">test_data = pad_sequences(test_data, maxlen=<span class="number">200</span>)</span><br><span class="line">test_data = test_data.astype(np.float32)</span><br><span class="line">request = predict_pb2.PredictRequest()</span><br><span class="line">request.model_spec.name = <span class="string">&#x27;textcnn&#x27;</span></span><br><span class="line">request.model_spec.signature_name = <span class="string">&#x27;serving_default&#x27;</span></span><br><span class="line">request.inputs[<span class="string">&#x27;input_1&#x27;</span>].CopyFrom(tf.make_tensor_proto(np.array(test_data[<span class="number">0</span>]), shape=(<span class="number">1</span>, <span class="number">200</span>)))</span><br><span class="line">   </span><br><span class="line">start = time.time()</span><br><span class="line">response = stub.Predict(request, <span class="number">10.0</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;cost time = &quot;</span>, time.time() - start)</span><br><span class="line">res_from_server_np = tf.make_ndarray(response.outputs[<span class="string">&quot;dense&quot;</span>])[<span class="number">0</span>][<span class="number">0</span>]</span><br><span class="line">label = <span class="number">1</span> <span class="keyword">if</span> res_from_server_np &gt; <span class="number">0.5</span> <span class="keyword">else</span> <span class="number">0</span></span><br><span class="line"><span class="built_in">print</span>(label)</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cost time =  0.1668863296508789</span><br><span class="line">0</span><br></pre></td></tr></table></figure>

<p>模型新增成功。</p>
</li>
<li><p>–model_config_file_poll_wait_seconds</p>
</li>
</ol>
<p>在启动服务的时候，指定重新加载配置文件的时间间隔60s。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker run -p 8501:8501 -p 8500:8500 -v /root/mutimodel/:/models/mutimodel  -t tensorflow/serving --model_config_file=/models/mutimodel/model.config --allow_version_labels_for_unavailable_models=true --model_config_file_poll_wait_seconds=60</span><br></pre></td></tr></table></figure>

<p>立即调用textcnn，可以看到报如下错误。很明显，此时服务并没有加载textcnn模型。</p>
<blockquote>
<p>grpc._channel._Rendezvous: &lt;_Rendezvous of RPC that terminated with:<br>    status = StatusCode.NOT_FOUND<br>    details = “Servable not found for request: Latest(textcnn)”<br>    debug_error_string = “{“created”:”@1584608241.949779831”,”description”:”Error received from peer ipv4:49.233.155.170:8500”,”file”:”src/core/lib/surface/call.cc”,”file_line”:1055,”grpc_message”:”Servable not found for request: Latest(textcnn)”,”grpc_status”:5}”</p>
<blockquote>
</blockquote>
</blockquote>
<p>60s之后，观察到服务出现变化，显示已经加载模型textcnn和router。</p>
<p><img src="https://gitee.com/fushengwuyu1993/images/raw/master/imgs/1584608837466.png" alt="1584608837466"></p>
<p>此时，再次调用textcnn模型</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cost time =  0.1185760498046875</span><br><span class="line">0</span><br></pre></td></tr></table></figure>

<p>正确返回，模型更新成功。</p>
<p>引用：</p>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/zong596568821xp/article/details/102953720">https://blog.csdn.net/zong596568821xp/article/details/102953720</a></p>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/weixin_44899143/article/details/90715186?depth_1-utm_source=distribute.pc_relevant.none-task&amp;utm_source=distribute.pc_relevant.none-task#model_config_file_43">https://blog.csdn.net/weixin_44899143/article/details/90715186?depth_1-utm_source=distribute.pc_relevant.none-task&amp;utm_source=distribute.pc_relevant.none-task#model_config_file_43</a></p>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/JerryZhang__/article/details/86516428">https://blog.csdn.net/JerryZhang__/article/details/86516428</a></p>
<p><a target="_blank" rel="noopener" href="https://stackoverflow.com/questions/54440762/tensorflow-serving-update-model-config-add-additional-models-at-runtime">https://stackoverflow.com/questions/54440762/tensorflow-serving-update-model-config-add-additional-models-at-runtime</a></p>
<p><a target="_blank" rel="noopener" href="https://www.tensorflow.org/tfx/serving/serving_config">https://www.tensorflow.org/tfx/serving/serving_config</a></p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2021/07/20/%E4%BE%9D%E5%AD%98%E5%8F%A5%E6%B3%95%E5%88%86%E6%9E%90%E6%80%BB%E7%BB%93/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="sunshine">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="浮生物语的博客">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2021/07/20/%E4%BE%9D%E5%AD%98%E5%8F%A5%E6%B3%95%E5%88%86%E6%9E%90%E6%80%BB%E7%BB%93/" class="post-title-link" itemprop="url">依存句法分析</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2021-07-20 00:00:00" itemprop="dateCreated datePublished" datetime="2021-07-20T00:00:00+08:00">2021-07-20</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2021-08-20 10:40:20" itemprop="dateModified" datetime="2021-08-20T10:40:20+08:00">2021-08-20</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/NLP/" itemprop="url" rel="index"><span itemprop="name">NLP</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h4 id="1-基本概念"><a href="#1-基本概念" class="headerlink" title="1. 基本概念"></a>1. 基本概念</h4><p>依存句法分析（Dependency Parsing，DP）通过分析语言单位内成分之间的依存关系，揭示其句法结构。直观来讲，就是分析句子中的“主谓宾”、“定状补”这些语法成分，并分析各成分的关系。对句法结构进行分析，一方面是语言理解的自身需求，句法分析是语言理解的基础，另外一方面，句法分析也为其他自然语言处理任务提供支持。比如：句法驱动的统计机器翻译需要对源语言或目标语言进行句法分析。</p>
<h5 id="1-1-谓词"><a href="#1-1-谓词" class="headerlink" title="1.1 谓词"></a>1.1 谓词</h5><p>依存句法认为“谓词”中的动词是一个句子的核心，其他成分与动词直接或者间接的产生联系。</p>
<h5 id="1-2-依存理论"><a href="#1-2-依存理论" class="headerlink" title="1.2 依存理论"></a>1.2 依存理论</h5><p>依存理论中，“依存”指的是词与词之间处于支配与被支配的关系，这种关系具有方向性。处于支配地位的词称之为支配者（head），处于被支配地位的成分称之为从属者（dependency）。</p>
<p>依存语法存在一个基本假设，句法分析核心是词与词的依存关系，一个依存关系连接两个词：head和dependency。依存关系可以细分为不同类型，表示具体的两个词的依存关系。</p>
<h5 id="1-3-依存关系"><a href="#1-3-依存关系" class="headerlink" title="1.3 依存关系"></a>1.3 依存关系</h5><table>
<thead>
<tr>
<th>关系类型</th>
<th>Tag</th>
<th>Description</th>
<th>Example</th>
</tr>
</thead>
<tbody><tr>
<td>主谓关系</td>
<td>SBV</td>
<td>subject-verb</td>
<td>我送她一束花 (我 &lt;– 送)</td>
</tr>
<tr>
<td>动宾关系</td>
<td>VOB</td>
<td>直接宾语，verb-object</td>
<td>我送她一束花 (送 –&gt; 花)</td>
</tr>
<tr>
<td>间宾关系</td>
<td>IOB</td>
<td>间接宾语，indirect-object</td>
<td>我送她一束花 (送 –&gt; 她)</td>
</tr>
<tr>
<td>前置宾语</td>
<td>FOB</td>
<td>前置宾语，fronting-object</td>
<td>他什么书都读 (书 &lt;– 读)</td>
</tr>
<tr>
<td>兼语</td>
<td>DBL</td>
<td>double</td>
<td>他请我吃饭 (请 –&gt; 我)</td>
</tr>
<tr>
<td>定中关系</td>
<td>ATT</td>
<td>attribute</td>
<td>红苹果 (红 &lt;– 苹果)</td>
</tr>
<tr>
<td>状中结构</td>
<td>ADV</td>
<td>adverbial</td>
<td>非常美丽 (非常 &lt;– 美丽)</td>
</tr>
<tr>
<td>动补结构</td>
<td>CMP</td>
<td>complement</td>
<td>做完了作业 (做 –&gt; 完)</td>
</tr>
<tr>
<td>并列关系</td>
<td>COO</td>
<td>coordinate</td>
<td>大山和大海 (大山 –&gt; 大海)</td>
</tr>
<tr>
<td>介宾关系</td>
<td>POB</td>
<td>preposition-object</td>
<td>在贸易区内 (在 –&gt; 内)</td>
</tr>
<tr>
<td>左附加关系</td>
<td>LAD</td>
<td>left adjunct</td>
<td>大山和大海 (和 &lt;– 大海)</td>
</tr>
<tr>
<td>右附加关系</td>
<td>RAD</td>
<td>right adjunct</td>
<td>孩子们 (孩子 –&gt; 们)</td>
</tr>
<tr>
<td>独立结构</td>
<td>IS</td>
<td>independent structure</td>
<td>两个单句在结构上彼此独立</td>
</tr>
<tr>
<td>核心关系</td>
<td>HED</td>
<td>head</td>
<td>指整个句子的核心</td>
</tr>
</tbody></table>
<h4 id="2-基本方法"><a href="#2-基本方法" class="headerlink" title="2. 基本方法"></a>2. 基本方法</h4><ul>
<li><p>基于转移的方法</p>
<p>基于转移的方法通过shift-reduce两个基本动作，将序列转为树结构。首先用一个 buffer 来存储所有未处理的输入句子，并用一个栈来存储当前的分析状态。动作可以分为：</p>
<ol>
<li>shift，即将 buffer 中的一个词移到栈中；</li>
<li>$left_arc(x)$，即栈顶两个词 a,b 为 a&lt;-b 的依赖关系，关系种类为 x；</li>
<li>$right_arc(x)$，即栈顶两个词 a,b 为 a-&gt;b 的依赖关系，关系种类为 x。后两种动作为 reduce 动作。</li>
</ol>
<p>目前，基于转移的方法最好模型是stack lstm。 通过三个 LSTM 来分别建模栈状态、待输入序列和动作序列。 其中因为栈需要入栈和出栈，因此作者提出了一个 Stack LSTM 来建模栈状态。</p>
<p><img src="https://gitee.com/fushengwuyu1993/images/raw/master/imgs/1587606360367.png" alt="1587606360367"></p>
<p>论文地址： <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1505.08075.pdf">https://arxiv.org/pdf/1505.08075.pdf</a></p>
</li>
<li><p>基于图的方法</p>
<p>目前的依存句法分析中，<strong>最流行的方法是基于图的方法经典的方法是 Biaffine 模型</strong>。直接用神经网络来预测每两个词之间存在依存关系的概率，这样我们就得到一个全连接图，图上每个边代表了节点 a 指向节点 b 的概率。然后使用MST等方法来来将图转换为一棵树。</p>
<p>Biaffine 模型其实和我们目前全连接自注意力模型非常类似。Biaffine 模型十分简单，并且容易理解，并且在很多数据集上都取得了目前最好的结果。</p>
<p><img src="https://gitee.com/fushengwuyu1993/images/raw/master/imgs/1587606231909.png" alt="1587606231909"></p>
<p>论文地址：<a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1611.01734.pdf">https://arxiv.org/pdf/1611.01734.pdf</a></p>
</li>
<li><p>联合模型(深度学习)</p>
<ol>
<li><p>词性标注&amp;句法分析</p>
<p>联合词性标注和句法分析的模型有很多，可以是基于转移的方法，也可以是基于图的方法，这里介绍一个简单思路。首先利用lstm来预测词性，然后联合词性信息和词信息一起用另外一个lstm来建模，并用Biaffine模型来做句法分析。</p>
<p><img src="https://gitee.com/fushengwuyu1993/images/raw/master/imgs/1587606449299.png" alt="1587606449299"></p>
<p>论文地址：<a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1807.03955.pdf">https://arxiv.org/pdf/1807.03955.pdf</a></p>
</li>
<li><p>中文分词&amp;句法分析</p>
<p>中文的句法分析是基于词级别的，所以在句法分析之前，会做分词。为了避免流水线模式的错误积累，很容易想到的就是分词和词法分析联合建模。</p>
<p>这里主要介绍一下邱希鹏教授实验室提出的模型：joint CWS。</p>
<p><img src="https://gitee.com/fushengwuyu1993/images/raw/master/imgs/1587606912240.png" alt="1587606912240"></p>
<p>其中两个关键点：</p>
<ul>
<li>biaffine parsing</li>
<li>‘app’ 作为特殊的依赖关系</li>
</ul>
<p>其实方法很简单，只需要将词内部的字之间加上一个特殊的依赖关系“app”，然后将词级别的依存关系转换为字级别的依存关系。并且用 biaffine 模型来进行同时预测。</p>
<p>论文地址：<a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1904.04697.pdf">https://arxiv.org/pdf/1904.04697.pdf</a></p>
</li>
</ol>
</li>
</ul>
<h4 id="3-常用工具"><a href="#3-常用工具" class="headerlink" title="3. 常用工具"></a>3. 常用工具</h4><p><a target="_blank" rel="noopener" href="https://www.jianshu.com/p/867bd48cd9ad">https://www.jianshu.com/p/867bd48cd9ad</a></p>
<h5 id="3-1-LTP"><a href="#3-1-LTP" class="headerlink" title="3.1 LTP"></a>3.1 LTP</h5><ol>
<li><p>安装</p>
<blockquote>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install pyltp</span><br></pre></td></tr></table></figure></blockquote>
</li>
<li><p>下载数据包</p>
<p>ltp_data_v3.4.0： 链接: <a target="_blank" rel="noopener" href="https://pan.baidu.com/s/1aDrb95ylZHoTPKJY6K1Slw">https://pan.baidu.com/s/1aDrb95ylZHoTPKJY6K1Slw</a>  密码: ehe2</p>
</li>
<li><p>测试代码</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyltp <span class="keyword">import</span> Parser, Postagger, Segmentor</span><br><span class="line"></span><br><span class="line">text = <span class="string">&#x27;HanLP是一系列模型与算法组成的自然语言处理工具包，目标是普及自然语言处理在生产环境中的应用。&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 分词</span></span><br><span class="line">segmentor = Segmentor()</span><br><span class="line">segmentor.load(<span class="string">&quot;/home/sunshine/datasets/other/ltp_data_v3.4.0/cws.model&quot;</span>)</span><br><span class="line">tokens = segmentor.segment(text)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 词性</span></span><br><span class="line">postagger = Postagger()</span><br><span class="line">postagger.load(<span class="string">&#x27;/home/sunshine/datasets/other/ltp_data_v3.4.0/pos.model&#x27;</span>)</span><br><span class="line">postags = postagger.postag(tokens)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 依存句法分析</span></span><br><span class="line">parser = Parser()</span><br><span class="line">parser.load(<span class="string">&#x27;/home/sunshine/datasets/other/ltp_data_v3.4.0/parser.model&#x27;</span>)</span><br><span class="line">arcs = parser.parse(tokens, postags)</span><br><span class="line"></span><br><span class="line">i = <span class="number">1</span></span><br><span class="line">result = <span class="built_in">zip</span>(tokens, postags, arcs)</span><br><span class="line"><span class="keyword">for</span> item <span class="keyword">in</span> result:</span><br><span class="line">    <span class="built_in">print</span>(i, item[<span class="number">0</span>], item[<span class="number">1</span>], item[<span class="number">2</span>].head, item[<span class="number">2</span>].relation)</span><br><span class="line">    i += <span class="number">1</span></span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">1 HanLP ws 2 SBV</span><br><span class="line">2 是 v 0 HED</span><br><span class="line">3 一 m 4 ATT</span><br><span class="line">4 系列 q 5 ATT</span><br><span class="line">5 模型 n 8 SBV</span><br><span class="line">6 与 c 7 LAD</span><br><span class="line">7 算法 n 5 COO</span><br><span class="line">8 组成 v 12 ATT</span><br><span class="line">9 的 u 8 RAD</span><br><span class="line">10 自然 n 11 ATT</span><br><span class="line">11 语言 n 12 SBV</span><br><span class="line">12 处理 v 2 VOB</span><br><span class="line">13 工具包 n 12 VOB</span><br><span class="line">14 ， wp 2 WP</span><br><span class="line">15 目标 n 16 SBV</span><br><span class="line">16 是 v 2 COO</span><br><span class="line">17 普及 v 16 VOB</span><br><span class="line">18 自然 n 19 ATT</span><br><span class="line">19 语言 n 20 ATT</span><br><span class="line">20 处理 v 17 VOB</span><br><span class="line">21 在 p 26 ATT</span><br><span class="line">22 生产 v 23 ATT</span><br><span class="line">23 环境 n 24 ATT</span><br><span class="line">24 中 nd 21 POB</span><br><span class="line">25 的 u 21 RAD</span><br><span class="line">26 应用 v 20 VOB</span><br><span class="line">27 。 wp 2 WP</span><br></pre></td></tr></table></figure></li>
</ol>
<h5 id="3-2-stanfordNLP"><a href="#3-2-stanfordNLP" class="headerlink" title="3.2 stanfordNLP"></a>3.2 stanfordNLP</h5><h6 id="3-2-1-StanordCoreNLP"><a href="#3-2-1-StanordCoreNLP" class="headerlink" title="3.2.1 StanordCoreNLP"></a>3.2.1 StanordCoreNLP</h6><p>Github地址：<a target="_blank" rel="noopener" href="https://github.com/Lynten/stanford-corenlp">https://github.com/Lynten/stanford-corenlp</a></p>
<p>官网：<a target="_blank" rel="noopener" href="https://stanfordnlp.github.io/CoreNLP/">https://stanfordnlp.github.io/CoreNLP/</a></p>
<ol>
<li><p>安装</p>
<blockquote>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install stanfordcorenlp</span><br></pre></td></tr></table></figure></blockquote>
</li>
<li><p>安装java环境（略）</p>
</li>
<li><p>下载数据包</p>
<p>链接: <a target="_blank" rel="noopener" href="https://pan.baidu.com/s/1kD3gaxVwvxZGaEN3EDedvA">https://pan.baidu.com/s/1kD3gaxVwvxZGaEN3EDedvA</a> 提取码: m72n</p>
<p>数据包下载之后，解压stanford-corenlp-full-2018-02-27.zip，将stanford-chinese-corenlp-2018-02-27-models.jar拷贝至stanford-corenlp-full-2018-02-27.zip解压目录。</p>
</li>
<li><p>测试代码</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> stanfordcorenlp <span class="keyword">import</span> StanfordCoreNLP</span><br><span class="line">text = <span class="string">&#x27;HanLP是一系列模型与算法组成的自然语言处理工具包，目标是普及自然语言处理在生产环境中的应用。&#x27;</span></span><br><span class="line">nlp = StanfordCoreNLP(<span class="string">&quot;/home/sunshine/datasets/other/standfordCoreNLP/stanford-corenlp-full-2018-02-27&quot;</span>, lang=<span class="string">&#x27;zh&#x27;</span>)</span><br><span class="line">tokens = nlp.word_tokenize(text)</span><br><span class="line">postags = nlp.pos_tag(text)</span><br><span class="line">result = nlp.dependency_parse(text)</span><br><span class="line">i = <span class="number">1</span></span><br><span class="line"><span class="keyword">for</span> item <span class="keyword">in</span> <span class="built_in">zip</span>(tokens, postags, result):</span><br><span class="line">    <span class="built_in">print</span>(i, item[<span class="number">0</span>], item[<span class="number">1</span>][<span class="number">1</span>], item[<span class="number">2</span>][<span class="number">1</span>], item[<span class="number">2</span>][<span class="number">2</span>])</span><br><span class="line">    i += <span class="number">1</span></span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">1 HanLP NR 0 12</span><br><span class="line">2 是 VC 12 1</span><br><span class="line">3 一 CD 12 2</span><br><span class="line">4 系列 M 11 3</span><br><span class="line">5 模型 NN 3 4</span><br><span class="line">6 与 CC 7 5</span><br><span class="line">7 算法 NN 7 6</span><br><span class="line">8 组成 VV 8 7</span><br><span class="line">9 的 DEC 11 8</span><br><span class="line">10 自然 NN 8 9</span><br><span class="line">11 语言 NN 11 10</span><br><span class="line">12 处理 VV 12 11</span><br><span class="line">13 工具包 NN 12 13</span><br><span class="line">14 ， PU 12 14</span><br><span class="line">15 目标 NN 17 15</span><br><span class="line">16 是 VC 17 16</span><br><span class="line">17 普及 VV 12 17</span><br><span class="line">18 自然 NN 19 18</span><br><span class="line">19 语言 NN 17 19</span><br><span class="line">20 处理 VV 17 20</span><br><span class="line">21 在 P 23 21</span><br><span class="line">22 生产 NN 23 22</span><br><span class="line">23 环境 NN 26 23</span><br><span class="line">24 中 LC 23 24</span><br><span class="line">25 的 DEG 23 25</span><br><span class="line">26 应用 NN 20 26</span><br><span class="line">27 。 PU 12 27</span><br></pre></td></tr></table></figure></li>
<li><p>依存句法解释</p>
<blockquote>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br></pre></td><td class="code"><pre><span class="line">&gt; &gt; ROOT：要处理文本的语句</span><br><span class="line">&gt; &gt; IP：简单从句</span><br><span class="line">&gt; &gt; NP：名词短语</span><br><span class="line">&gt; &gt; VP：动词短语</span><br><span class="line">&gt; &gt; PU：断句符，通常是句号、问号、感叹号等标点符号</span><br><span class="line">&gt; &gt; LCP：方位词短语</span><br><span class="line">&gt; &gt; PP：介词短语</span><br><span class="line">&gt; &gt; CP：由‘的’构成的表示修饰性关系的短语</span><br><span class="line">&gt; &gt; DNP：由‘的’构成的表示所属关系的短语</span><br><span class="line">&gt; &gt; ADVP：副词短语</span><br><span class="line">&gt; &gt; ADJP：形容词短语</span><br><span class="line">&gt; &gt; DP：限定词短语</span><br><span class="line">&gt; &gt; QP：量词短语</span><br><span class="line">&gt; &gt; NN：常用名词</span><br><span class="line">&gt; &gt; NR：固有名词</span><br><span class="line">&gt; &gt; NT：时间名词</span><br><span class="line">&gt; &gt; PN：代词</span><br><span class="line">&gt; &gt; VV：动词</span><br><span class="line">&gt; &gt; VC：是</span><br><span class="line">&gt; &gt; CC：表示连词</span><br><span class="line">&gt; &gt; VE：有</span><br><span class="line">&gt; &gt; VA：表语形容词</span><br><span class="line">&gt; &gt; AS：内容标记（如：了）</span><br><span class="line">&gt; &gt; VRD：动补复合词</span><br><span class="line">&gt; &gt; CD: 表示基数词</span><br><span class="line">&gt; &gt; DT: determiner 表示限定词</span><br><span class="line">&gt; &gt; EX: existential there 存在句</span><br><span class="line">&gt; &gt; FW: foreign word 外来词</span><br><span class="line">&gt; &gt; IN: preposition or conjunction, subordinating 介词或从属连词</span><br><span class="line">&gt; &gt; JJ: adjective or numeral, ordinal 形容词或序数词</span><br><span class="line">&gt; &gt; JJR: adjective, comparative 形容词比较级</span><br><span class="line">&gt; &gt; JJS: adjective, superlative 形容词最高级</span><br><span class="line">&gt; &gt; LS: list item marker 列表标识</span><br><span class="line">&gt; &gt; MD: modal auxiliary 情态助动词</span><br><span class="line">&gt; &gt; PDT: pre-determiner 前位限定词</span><br><span class="line">&gt; &gt; POS: genitive marker 所有格标记</span><br><span class="line">&gt; &gt; PRP: pronoun, personal 人称代词</span><br><span class="line">&gt; &gt; RB: adverb 副词</span><br><span class="line">&gt; &gt; RBR: adverb, comparative 副词比较级</span><br><span class="line">&gt; &gt; RBS: adverb, superlative 副词最高级</span><br><span class="line">&gt; &gt; RP: particle 小品词</span><br><span class="line">&gt; &gt; SYM: symbol 符号</span><br><span class="line">&gt; &gt; TO:”to” as preposition or infinitive marker 作为介词或不定式标记</span><br><span class="line">&gt; &gt; WDT: WH-determiner WH限定词</span><br><span class="line">&gt; &gt; WP: WH-pronoun WH代词</span><br><span class="line">&gt; &gt; WP$: WH-pronoun, possessive WH所有格代词</span><br><span class="line">&gt; &gt; WRB:Wh-adverb WH副词</span><br><span class="line">&gt; &gt; </span><br><span class="line">&gt; &gt; 关系表示</span><br><span class="line">&gt; &gt; abbrev: abbreviation modifier，缩写</span><br><span class="line">&gt; &gt; acomp: adjectival complement，形容词的补充；</span><br><span class="line">&gt; &gt; advcl : adverbial clause modifier，状语从句修饰词</span><br><span class="line">&gt; &gt; advmod: adverbial modifier状语</span><br><span class="line">&gt; &gt; agent: agent，代理，一般有by的时候会出现这个</span><br><span class="line">&gt; &gt; amod: adjectival modifier形容词</span><br><span class="line">&gt; &gt; appos: appositional modifier,同位词</span><br><span class="line">&gt; &gt; attr: attributive，属性</span><br><span class="line">&gt; &gt; aux: auxiliary，非主要动词和助词，如BE,HAVE SHOULD/COULD等到</span><br><span class="line">&gt; &gt; auxpass: passive auxiliary 被动词</span><br><span class="line">&gt; &gt; cc: coordination，并列关系，一般取第一个词</span><br><span class="line">&gt; &gt; ccomp: clausal complement从句补充</span><br><span class="line">&gt; &gt; complm: complementizer，引导从句的词好重聚中的主要动词</span><br><span class="line">&gt; &gt; conj : conjunct，连接两个并列的词。</span><br><span class="line">&gt; &gt; cop: copula。系动词（如be,seem,appear等），（命题主词与谓词间的）连系</span><br><span class="line">&gt; &gt; csubj : clausal subject，从主关系</span><br><span class="line">&gt; &gt; csubjpass: clausal passive subject 主从被动关系</span><br><span class="line">&gt; &gt; dep: dependent依赖关系</span><br><span class="line">&gt; &gt; det: determiner决定词，如冠词等</span><br><span class="line">&gt; &gt; dobj : direct object直接宾语</span><br><span class="line">&gt; &gt; expl: expletive，主要是抓取there</span><br><span class="line">&gt; &gt; infmod: infinitival modifier，动词不定式</span><br><span class="line">&gt; &gt; iobj : indirect object，非直接宾语，也就是所以的间接宾语；</span><br><span class="line">&gt; &gt; mark: marker，主要出现在有“that” or “whether”“because”, “when”,</span><br><span class="line">&gt; &gt; mwe: multi-word expression，多个词的表示</span><br><span class="line">&gt; &gt; neg: negation modifier否定词</span><br><span class="line">&gt; &gt; nn: noun compound modifier名词组合形式</span><br><span class="line">&gt; &gt; npadvmod: noun phrase as adverbial modifier名词作状语</span><br><span class="line">&gt; &gt; nsubj : nominal subject，名词主语</span><br><span class="line">&gt; &gt; nsubjpass: passive nominal subject，被动的名词主语</span><br><span class="line">&gt; &gt; num: numeric modifier，数值修饰</span><br><span class="line">&gt; &gt; number: element of compound number，组合数字</span><br><span class="line">&gt; &gt; parataxis: parataxis: parataxis，并列关系</span><br><span class="line">&gt; &gt; partmod: participial modifier动词形式的修饰</span><br><span class="line">&gt; &gt; pcomp: prepositional complement，介词补充</span><br><span class="line">&gt; &gt; pobj : object of a preposition，介词的宾语</span><br><span class="line">&gt; &gt; poss: possession modifier，所有形式，所有格，所属</span><br><span class="line">&gt; &gt; possessive: possessive modifier，这个表示所有者和那个’S的关系</span><br><span class="line">&gt; &gt; preconj : preconjunct，常常是出现在 “either”, “both”, “neither”的情况下</span><br><span class="line">&gt; &gt; predet: predeterminer，前缀决定，常常是表示所有</span><br><span class="line">&gt; &gt; prep: prepositional modifier</span><br><span class="line">&gt; &gt; prepc: prepositional clausal modifier</span><br><span class="line">&gt; &gt; prt: phrasal verb particle，动词短语</span><br><span class="line">&gt; &gt; punct: punctuation，这个很少见，但是保留下来了，结果当中不会出现这个</span><br><span class="line">&gt; &gt; purpcl : purpose clause modifier，目的从句</span><br><span class="line">&gt; &gt; quantmod: quantifier phrase modifier，数量短语</span><br><span class="line">&gt; &gt; rcmod: relative clause modifier相关关系</span><br><span class="line">&gt; &gt; ref : referent，指示物，指代</span><br><span class="line">&gt; &gt; rel : relative</span><br><span class="line">&gt; &gt; root: root，最重要的词，从它开始，根节点</span><br><span class="line">&gt; &gt; tmod: temporal modifier</span><br><span class="line">&gt; &gt; xcomp: open clausal complement</span><br><span class="line">&gt; &gt; xsubj : controlling subject 掌控者</span><br><span class="line">&gt; &gt; 中心语为谓词</span><br><span class="line">&gt; &gt; subj — 主语</span><br><span class="line">&gt; &gt; nsubj — 名词性主语（nominal subject） （同步，建设）</span><br><span class="line">&gt; &gt; top — 主题（topic） （是，建筑）</span><br><span class="line">&gt; &gt; npsubj — 被动型主语（nominal passive subject），专指由“被”引导的被动句中的主语，一般是谓词语义上的受事 （称作，镍）</span><br><span class="line">&gt; &gt; csubj — 从句主语（clausal subject），中文不存在</span><br><span class="line">&gt; &gt; xsubj — x主语，一般是一个主语下面含多个从句 （完善，有些）</span><br><span class="line">&gt; &gt; 中心语为谓词或介词</span><br><span class="line">&gt; &gt; obj — 宾语</span><br><span class="line">&gt; &gt; dobj — 直接宾语 （颁布，文件）</span><br><span class="line">&gt; &gt; iobj — 间接宾语（indirect object），基本不存在</span><br><span class="line">&gt; &gt; range — 间接宾语为数量词，又称为与格 （成交，元）</span><br><span class="line">&gt; &gt; pobj — 介词宾语 （根据，要求）</span><br><span class="line">&gt; &gt; lobj — 时间介词 （来，近年）</span><br><span class="line">&gt; &gt; 中心语为谓词</span><br><span class="line">&gt; &gt; comp — 补语</span><br><span class="line">&gt; &gt; ccomp — 从句补语，一般由两个动词构成，中心语引导后一个动词所在的从句(IP) （出现，纳入）</span><br><span class="line">&gt; &gt; xcomp — x从句补语（xclausal complement），不存在</span><br><span class="line">&gt; &gt; acomp — 形容词补语（adjectival complement）</span><br><span class="line">&gt; &gt; tcomp — 时间补语（temporal complement） （遇到，以前）</span><br><span class="line">&gt; &gt; lccomp — 位置补语（localizer complement） （占，以上）</span><br><span class="line">&gt; &gt; — 结果补语（resultative complement）</span><br><span class="line">&gt; &gt; 中心语为名词</span><br><span class="line">&gt; &gt; mod — 修饰语（modifier）</span><br><span class="line">&gt; &gt; pass — 被动修饰（passive）</span><br><span class="line">&gt; &gt; tmod — 时间修饰（temporal modifier）</span><br><span class="line">&gt; &gt; rcmod — 关系从句修饰（relative clause modifier） （问题，遇到）</span><br><span class="line">&gt; &gt; numod — 数量修饰（numeric modifier） （规定，若干）</span><br><span class="line">&gt; &gt; ornmod — 序数修饰（numeric modifier）</span><br><span class="line">&gt; &gt; clf — 类别修饰（classifier modifier） （文件，件）</span><br><span class="line">&gt; &gt; nmod — 复合名词修饰（noun compound modifier） （浦东，上海）</span><br><span class="line">&gt; &gt; amod — 形容词修饰（adjetive modifier） （情况，新）</span><br><span class="line">&gt; &gt; advmod — 副词修饰（adverbial modifier） （做到，基本）</span><br><span class="line">&gt; &gt; vmod — 动词修饰（verb modifier，participle modifier）</span><br><span class="line">&gt; &gt; prnmod — 插入词修饰（parenthetical modifier）</span><br><span class="line">&gt; &gt; neg — 不定修饰（negative modifier） (遇到，不)</span><br><span class="line">&gt; &gt; det — 限定词修饰（determiner modifier） （活动，这些）</span><br><span class="line">&gt; &gt; possm — 所属标记（possessive marker），NP</span><br><span class="line">&gt; &gt; poss — 所属修饰（possessive modifier），NP</span><br><span class="line">&gt; &gt; dvpm — DVP标记（dvp marker），DVP （简单，的）</span><br><span class="line">&gt; &gt; dvpmod — DVP修饰（dvp modifier），DVP （采取，简单）</span><br><span class="line">&gt; &gt; assm — 关联标记（associative marker），DNP （开发，的）</span><br><span class="line">&gt; &gt; assmod — 关联修饰（associative modifier），NP|QP （教训，特区）</span><br><span class="line">&gt; &gt; prep — 介词修饰（prepositional modifier） NP|VP|IP（采取，对）</span><br><span class="line">&gt; &gt; clmod — 从句修饰（clause modifier） （因为，开始）</span><br><span class="line">&gt; &gt; plmod — 介词性地点修饰（prepositional localizer modifier） （在，上）</span><br><span class="line">&gt; &gt; asp — 时态标词（aspect marker） （做到，了）</span><br><span class="line">&gt; &gt; partmod– 分词修饰（participial modifier） 不存在</span><br><span class="line">&gt; &gt; etc — 等关系（etc） （办法，等）</span><br><span class="line">&gt; &gt; 中心语为实词</span><br><span class="line">&gt; &gt; conj — 联合(conjunct)</span><br><span class="line">&gt; &gt; cop — 系动(copula) 双指助动词？？？？</span><br><span class="line">&gt; &gt; cc — 连接(coordination)，指中心词与连词 （开发，与）</span><br><span class="line">&gt; &gt; 其它</span><br><span class="line">&gt; &gt; attr — 属性关系 （是，工程）</span><br><span class="line">&gt; &gt; cordmod– 并列联合动词（coordinated verb compound） （颁布，实行）</span><br><span class="line">&gt; &gt; mmod — 情态动词（modal verb） （得到，能）</span><br><span class="line">&gt; &gt; ba — 把字关系</span><br><span class="line">&gt; &gt; tclaus — 时间从句 （以后，积累）</span><br><span class="line">&gt; &gt; — semantic dependent</span><br><span class="line">&gt; &gt; cpm — 补语化成分（complementizer），一般指“的”引导的CP （振兴，的）</span><br></pre></td></tr></table></figure>
<blockquote>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">```</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">###### 3.2.2 stanza</span><br><span class="line"></span><br><span class="line">github: &lt;https://github.com/stanfordnlp/stanza&gt;</span><br><span class="line"></span><br><span class="line">stanza同样是stanford发布的版本。</span><br><span class="line"></span><br><span class="line">1. 安装</span><br><span class="line"></span><br><span class="line">```shell</span><br><span class="line">pip install stanza</span><br></pre></td></tr></table></figure></blockquote>
</blockquote>
</li>
<li><p>下载模型</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> stanza</span><br><span class="line">stanza.download(<span class="string">&#x27;zh&#x27;</span>) </span><br></pre></td></tr></table></figure>

<p>我这里提供一份中文的模型包供大家下载。</p>
<p>链接: <a target="_blank" rel="noopener" href="https://pan.baidu.com/s/1hb9ATqpOGC9sHBHZ2hNdeg">https://pan.baidu.com/s/1hb9ATqpOGC9sHBHZ2hNdeg</a> 提取码: fqdm</p>
</li>
<li><p>测试代码</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> stanza</span><br><span class="line">nlp = stanza.Pipeline(<span class="string">&#x27;zh&#x27;</span>) <span class="comment"># This sets up a default neural pipeline in English</span></span><br><span class="line">doc = nlp(<span class="string">&quot;HanLP是一系列模型与算法组成的自然语言处理工具包，目标是普及自然语言处理在生产环境中的应用。&quot;</span>)</span><br><span class="line">doc.sentences[<span class="number">0</span>].print_dependencies()</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">(&#x27;HanLP&#x27;, &#x27;14&#x27;, &#x27;nsubj&#x27;)</span><br><span class="line">(&#x27;是&#x27;, &#x27;14&#x27;, &#x27;cop&#x27;)</span><br><span class="line">(&#x27;一&#x27;, &#x27;4&#x27;, &#x27;nummod&#x27;)</span><br><span class="line">(&#x27;系列&#x27;, &#x27;5&#x27;, &#x27;clf&#x27;)</span><br><span class="line">(&#x27;模型&#x27;, &#x27;8&#x27;, &#x27;nsubj&#x27;)</span><br><span class="line">(&#x27;与&#x27;, &#x27;7&#x27;, &#x27;cc&#x27;)</span><br><span class="line">(&#x27;算法&#x27;, &#x27;5&#x27;, &#x27;conj&#x27;)</span><br><span class="line">(&#x27;组成&#x27;, &#x27;14&#x27;, &#x27;acl:relcl&#x27;)</span><br><span class="line">(&#x27;的&#x27;, &#x27;8&#x27;, &#x27;mark:relcl&#x27;)</span><br><span class="line">(&#x27;自然&#x27;, &#x27;12&#x27;, &#x27;nmod&#x27;)</span><br><span class="line">(&#x27;语言&#x27;, &#x27;12&#x27;, &#x27;compound&#x27;)</span><br><span class="line">(&#x27;处&#x27;, &#x27;13&#x27;, &#x27;nmod&#x27;)</span><br><span class="line">(&#x27;理工&#x27;, &#x27;14&#x27;, &#x27;nsubj&#x27;)</span><br><span class="line">(&#x27;具包&#x27;, &#x27;0&#x27;, &#x27;root&#x27;)</span><br><span class="line">(&#x27;，&#x27;, &#x27;14&#x27;, &#x27;punct&#x27;)</span><br><span class="line">(&#x27;目标&#x27;, &#x27;17&#x27;, &#x27;nsubj&#x27;)</span><br><span class="line">(&#x27;是&#x27;, &#x27;14&#x27;, &#x27;parataxis&#x27;)</span><br><span class="line">(&#x27;普及&#x27;, &#x27;17&#x27;, &#x27;xcomp&#x27;)</span><br><span class="line">(&#x27;自然&#x27;, &#x27;20&#x27;, &#x27;nmod&#x27;)</span><br><span class="line">(&#x27;语言&#x27;, &#x27;21&#x27;, &#x27;nsubj&#x27;)</span><br><span class="line">(&#x27;处理&#x27;, &#x27;18&#x27;, &#x27;ccomp&#x27;)</span><br><span class="line">(&#x27;在&#x27;, &#x27;27&#x27;, &#x27;det&#x27;)</span><br><span class="line">(&#x27;生产&#x27;, &#x27;24&#x27;, &#x27;nmod&#x27;)</span><br><span class="line">(&#x27;环境&#x27;, &#x27;22&#x27;, &#x27;nmod&#x27;)</span><br><span class="line">(&#x27;中&#x27;, &#x27;24&#x27;, &#x27;acl&#x27;)</span><br><span class="line">(&#x27;的&#x27;, &#x27;22&#x27;, &#x27;case:dec&#x27;)</span><br><span class="line">(&#x27;应用&#x27;, &#x27;18&#x27;, &#x27;obj&#x27;)</span><br><span class="line">(&#x27;。&#x27;, &#x27;14&#x27;, &#x27;punct&#x27;)</span><br></pre></td></tr></table></figure></li>
</ol>
<h5 id="3-3-HaNLP"><a href="#3-3-HaNLP" class="headerlink" title="3.3 HaNLP"></a>3.3 HaNLP</h5><p>官网：<a target="_blank" rel="noopener" href="http://hanlp.linrunsoft.com/">http://hanlp.linrunsoft.com/</a></p>
<p>在线演示：<a target="_blank" rel="noopener" href="http://hanlp.com/">http://hanlp.com/</a></p>
<h6 id="3-3-1-pyhanlp-hanlp1-x"><a href="#3-3-1-pyhanlp-hanlp1-x" class="headerlink" title="3.3.1 pyhanlp(hanlp1.x)"></a>3.3.1 pyhanlp(hanlp1.x)</h6><p>Github地址：<a target="_blank" rel="noopener" href="https://github.com/hankcs/pyhanlp">https://github.com/hankcs/pyhanlp</a></p>
<ol>
<li><p>安装</p>
<blockquote>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install pyhanlp</span><br></pre></td></tr></table></figure></blockquote>
</li>
<li><p>下载数据包</p>
<p>data：链接: <a target="_blank" rel="noopener" href="https://pan.baidu.com/s/169Fgb6vhfsx10O2xEomY1Q">https://pan.baidu.com/s/169Fgb6vhfsx10O2xEomY1Q</a> 提取码: r4zv</p>
<p>将下载的数据包解压至%python_lib%/site-packages/pyhanlp/static文件夹。我这里提供的是1.7.5版本，同样支持1.7.7版本的pyhanlp。</p>
<p>默认会自动下载相关的jar包。</p>
</li>
<li><p>测试代码</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyhanlp <span class="keyword">import</span> HanLP</span><br><span class="line">    <span class="built_in">print</span>(HanLP.parseDependency(<span class="string">&quot;HanLP是一系列模型与算法组成的自然语言处理工具包，目标是普及自然语言处理在生产环境中的应用&quot;</span>))</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">1	HanLP	HanLP	ws	nx	_	2	主谓关系	_	_</span><br><span class="line">2	是	是	v	v	_	0	核心关系	_	_</span><br><span class="line">3	一系列	一系列	n	n	_	4	定中关系	_	_</span><br><span class="line">4	模型	模型	n	n	_	7	主谓关系	_	_</span><br><span class="line">5	与	与	p	p	_	7	状中结构	_	_</span><br><span class="line">6	算法	算法	n	n	_	5	介宾关系	_	_</span><br><span class="line">7	组成	组成	v	v	_	10	定中关系	_	_</span><br><span class="line">8	的	的	u	u	_	7	右附加关系	_	_</span><br><span class="line">9	自然语言处理	自然语言处理	nz	nz	_	10	定中关系	_	_</span><br><span class="line">10	工具包	工具包	n	n	_	2	动宾关系	_	_</span><br><span class="line">11	，	，	wp	w	_	2	标点符号	_	_</span><br><span class="line">12	目标	目标	n	n	_	13	主谓关系	_	_</span><br><span class="line">13	是	是	v	v	_	2	并列关系	_	_</span><br><span class="line">14	普及	普及	v	v	_	13	动宾关系	_	_</span><br><span class="line">15	自然语言处理	自然语言处理	nz	nz	_	19	主谓关系	_	_</span><br><span class="line">16	在	在	p	p	_	19	状中结构	_	_</span><br><span class="line">17	生产环境	生产环境	n	n	_	16	介宾关系	_	_</span><br><span class="line">18	中的	中的	v	v	_	19	状中结构	_	_</span><br><span class="line">19	应用	应用	v	vn	_	14	动宾关系	_	_</span><br></pre></td></tr></table></figure></li>
</ol>
<h6 id="3-3-2-hanlp2-0"><a href="#3-3-2-hanlp2-0" class="headerlink" title="3.3.2 hanlp2.0"></a>3.3.2 hanlp2.0</h6><ol>
<li><p>安装</p>
<blockquote>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install hanlp</span><br></pre></td></tr></table></figure>
</blockquote>
<p>hanlp2.0是基于tensorflow2.1训练的网络模型，线上提供了很多训练好的预训练模型，问题在于基本上不可能自动下载成功，需要手动下载模型并存放到相应的位置。</p>
</li>
<li><p>查看已经提供的模型</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> hanlp</span><br><span class="line"><span class="keyword">for</span> k,v <span class="keyword">in</span> hanlp.pretrained.ALL.items():</span><br><span class="line">    <span class="built_in">print</span>(k, v)</span><br></pre></td></tr></table></figure></li>
<li><p>测试代码</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">tokenizer = hanlp.load(<span class="string">&#x27;CTB6_CONVSEG&#x27;</span>)</span><br><span class="line">tagger = hanlp.load(<span class="string">&#x27;CTB5_POS_RNN&#x27;</span>)</span><br><span class="line">syntactic_parser = hanlp.load(<span class="string">&#x27;CTB7_BIAFFINE_DEP_ZH&#x27;</span>)</span><br><span class="line"></span><br><span class="line">pipeline = hanlp.pipeline() \</span><br><span class="line">.append(hanlp.utils.rules.split_sentence, output_key=<span class="string">&#x27;sentences&#x27;</span>) \</span><br><span class="line">.append(tokenizer, output_key=<span class="string">&#x27;tokens&#x27;</span>) \</span><br><span class="line">.append(tagger, output_key=<span class="string">&#x27;part_of_speech_tags&#x27;</span>) \</span><br><span class="line">.append(syntactic_parser, input_key=(<span class="string">&#x27;tokens&#x27;</span>, <span class="string">&#x27;part_of_speech_tags&#x27;</span>), output_key=<span class="string">&#x27;syntactic_dependencies&#x27;</span>,</span><br><span class="line">        conll=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">text = <span class="string">&#x27;HanLP是一系列模型与算法组成的自然语言处理工具包，目标是普及自然语言处理在生产环境中的应用&#x27;</span></span><br><span class="line"></span><br><span class="line">doc = pipeline(text)</span><br><span class="line">tokens = doc.tokens[<span class="number">0</span>]</span><br><span class="line">pos = doc.part_of_speech_tags[<span class="number">0</span>]</span><br><span class="line">dependencies = doc.syntactic_dependencies[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(tokens)):</span><br><span class="line">    <span class="built_in">print</span>(i, tokens[i], pos[i], dependencies[i][<span class="number">0</span>], dependencies[i][<span class="number">1</span>])</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">0 HanLP NN 2 top</span><br><span class="line">1 是 VC 0 root</span><br><span class="line">2 一系列 NN 6 nn</span><br><span class="line">3 模型 NN 6 conj</span><br><span class="line">4 与 CC 6 cc</span><br><span class="line">5 算法 NN 7 nsubj</span><br><span class="line">6 组成 VV 10 rcmod</span><br><span class="line">7 的 DEC 7 cpm</span><br><span class="line">8 自然 NN 10 nn</span><br><span class="line">9 语言 NN 11 nsubj</span><br><span class="line">10 处理 VV 2 ccomp</span><br><span class="line">11 工具包 PU 11 punct</span><br><span class="line">12 ， PU 2 punct</span><br><span class="line">13 目标 NN 15 top</span><br><span class="line">14 是 VC 2 conj</span><br><span class="line">15 普及 VV 15 ccomp</span><br><span class="line">16 自然 NN 18 nn</span><br><span class="line">17 语言 NN 16 dobj</span><br><span class="line">18 处理 VV 16 conj</span><br><span class="line">19 在 P 25 assmod</span><br><span class="line">20 生产 NN 22 nn</span><br><span class="line">21 环境 NN 23 lobj</span><br><span class="line">22 中 LC 20 plmod</span><br><span class="line">23 的 DEG 20 assm</span><br><span class="line">24 应用 NN 19 dobj</span><br></pre></td></tr></table></figure></li>
</ol>
<h4 id="4-数据集"><a href="#4-数据集" class="headerlink" title="4. 数据集"></a>4. 数据集</h4><ul>
<li><p>Penn Treebank</p>
<p>Penn Treebank是一个项目的名称，项目目的是对语料进行标注，标注内容包括词性标注以及句法分析。</p>
</li>
<li><p>SemEval-2016 Task 9</p>
<p>中文语义依存图数据：<a target="_blank" rel="noopener" href="http://ir.hit.edu.cn/2461.html">http://ir.hit.edu.cn/2461.html</a></p>
<p>下载地址：<a target="_blank" rel="noopener" href="https://github.com/HIT-SCIR/SemEval-2016">https://github.com/HIT-SCIR/SemEval-2016</a></p>
</li>
<li><p>evsam05</p>
<p>链接: <a target="_blank" rel="noopener" href="https://pan.baidu.com/s/1cFQBNcd-HnuTPUlGT7h9wg">https://pan.baidu.com/s/1cFQBNcd-HnuTPUlGT7h9wg</a> 提取码: tjdx </p>
</li>
<li><p>CoNLL任务</p>
<ul>
<li><a target="_blank" rel="noopener" href="http://universaldependencies.org/conll18/">http://universaldependencies.org/conll18/</a></li>
<li><a target="_blank" rel="noopener" href="http://ufal.mff.cuni.cz/conll2009-st/">http://ufal.mff.cuni.cz/conll2009-st/</a></li>
<li><a target="_blank" rel="noopener" href="https://www.clips.uantwerpen.be/conll2008/">https://www.clips.uantwerpen.be/conll2008/</a></li>
<li><a target="_blank" rel="noopener" href="https://www.clips.uantwerpen.be/conll2007/">https://www.clips.uantwerpen.be/conll2007/</a></li>
</ul>
</li>
</ul>
<h4 id="5-可视化工具"><a href="#5-可视化工具" class="headerlink" title="5. 可视化工具"></a>5. 可视化工具</h4><ol>
<li><p>conllu.js</p>
<p><a target="_blank" rel="noopener" href="https://github.com/spyysalo/conllu.js">https://github.com/spyysalo/conllu.js</a></p>
</li>
<li><p>DependencyViewer.exe </p>
<p><a target="_blank" rel="noopener" href="http://nlp.nju.edu.cn/tanggc/tools/DependencyViewer.html">http://nlp.nju.edu.cn/tanggc/tools/DependencyViewer.html</a></p>
</li>
</ol>
<p>参考：</p>
<p><a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s/AP4TCnRfIccqAxDu4FlBew">https://mp.weixin.qq.com/s/AP4TCnRfIccqAxDu4FlBew</a></p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  


  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/"><i class="fa fa-angle-left" aria-label="上一页"></i></a><a class="page-number" href="/">1</a><span class="page-number current">2</span><a class="page-number" href="/page/3/">3</a><a class="extend next" rel="next" href="/page/3/"><i class="fa fa-angle-right" aria-label="下一页"></i></a>
  </nav>



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">sunshine</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">22</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">6</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">36</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/fushengwuyu" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;fushengwuyu" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="/2303153523@qq.com" title="E-Mail → 2303153523@qq.com"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
  </div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2021</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">sunshine</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Gemini</a> 强力驱动
  </div>

        
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <span class="post-meta-item" id="busuanzi_container_site_uv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="总访客量">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item" id="busuanzi_container_site_pv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="总访问量">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="//cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js"></script>
  <script src="//cdn.jsdelivr.net/gh/fancyapps/fancybox@3/dist/jquery.fancybox.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  















  

  
      

<script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      loader: {
          load: ['[tex]/mhchem'],
        source: {
          '[tex]/amsCd': '[tex]/amscd',
          '[tex]/AMScd': '[tex]/amscd'
        }
      },
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
          packages: {'[+]': ['mhchem']},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              let target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    (function () {
      var script = document.createElement('script');
      script.src = '//cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js';
      script.defer = true;
      document.head.appendChild(script);
    })();
  } else {
    MathJax.startup.document.state(0);
    MathJax.texReset();
    MathJax.typeset();
  }
</script>

    

  

</body>
</html>
