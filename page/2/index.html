<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.4.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">
  <link rel="stylesheet" href="//cdn.jsdelivr.net/gh/fancyapps/fancybox@3/dist/jquery.fancybox.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"example.com","root":"/","scheme":"Muse","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":true,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta property="og:type" content="website">
<meta property="og:title" content="浮生物语的博客">
<meta property="og:url" content="http://example.com/page/2/index.html">
<meta property="og:site_name" content="浮生物语的博客">
<meta property="og:locale" content="zh_CN">
<meta property="article:author" content="sunshine">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="http://example.com/page/2/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : true,
    isPost : false,
    lang   : 'zh-CN'
  };
</script>

  <title>浮生物语的博客</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">浮生物语的博客</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">记录学习</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/%E5%BD%92%E6%A1%A3/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a>

  </li>
  </ul>
</nav>




</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content index posts-expand">
            
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2021/07/20/rasa%E6%96%87%E6%A1%A3/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="sunshine">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="浮生物语的博客">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2021/07/20/rasa%E6%96%87%E6%A1%A3/" class="post-title-link" itemprop="url">rasa总结文档</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>
              

              <time title="创建时间：2021-07-20 00:00:00 / 修改时间：10:18:58" itemprop="dateCreated datePublished" datetime="2021-07-20T00:00:00+08:00">2021-07-20</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h3 id="1-基本命令"><a href="#1-基本命令" class="headerlink" title="1. 基本命令"></a>1. 基本命令</h3><h4 id="1-1-训练模型"><a href="#1-1-训练模型" class="headerlink" title="1.1 训练模型"></a>1.1 训练模型</h4><p>无论是单独训练，还是2个模型一起训练，均可以使用rasa train命令实现（rasa nlu和rasa core合并为RASA），不同之处在于，提供的训练数据，若同时提供两份数据，则会同时训练nlu和core。</p>
<ul>
<li><p>训练nlu模型</p>
<blockquote>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python -m rasa train --config configs/zh_jieba_supervised_embeddings_config.yml --domain configs/domain.yml --data data/nlu/number_nlu.md data/stories/number_story.md</span><br></pre></td></tr></table></figure></blockquote>
</li>
<li><p>训练core模型</p>
<blockquote>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python -m rasa train --config configs/zh_jieba_supervised_embeddings_config.yml --domain configs/domain.yml --data data/stories/number_story.md</span><br></pre></td></tr></table></figure></blockquote>
</li>
<li><p>一起训练两个模型</p>
<blockquote>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python -m rasa train --config configs/zh_jieba_supervised_embeddings_config.yml --domain configs/domain.yml --data data/nlu/number_nlu.md data/stories/number_story.md</span><br></pre></td></tr></table></figure></blockquote>
</li>
</ul>
<h4 id="1-2-启动rasa"><a href="#1-2-启动rasa" class="headerlink" title="1.2 启动rasa"></a>1.2 启动rasa</h4><ul>
<li><p>不额外独立nlu服务</p>
<blockquote>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python -m rasa run --port 5005 --endpoints configs/endpoints.yml --credentials configs/credentials.yml </span><br></pre></td></tr></table></figure></blockquote>
</li>
<li><p>启动额外nlu服务</p>
<blockquote>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python -m rasa run --port 5005 --endpoints configs/endpoints.yml --credentials configs/credentials.yml --enable-api -m models/nlu-20190515-144445.tar.gz </span><br></pre></td></tr></table></figure></blockquote>
</li>
<li><p>单独启动nlu服务</p>
<blockquote>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rasa run --enable-api -m models/nlu-20190515-144445.tar.gz</span><br></pre></td></tr></table></figure></blockquote>
</li>
<li><p>调用第三方模型服务</p>
<blockquote>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rasa run --enable-api --log-file out.log --endpoints my_endpoints.yml</span><br></pre></td></tr></table></figure>

<p>在my_endpoints.yml中配置rasa模型的url</p>
<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">models:</span><br><span class="line">  url: http:<span class="comment">//my-server.com/models/2019-1222.tar.gz</span></span><br><span class="line">  wait_time_between_pulls: <span class="number">10</span>   # [optional](default: <span class="number">100</span>)</span><br></pre></td></tr></table></figure>

<p>rasa模型还可以存放在<a target="_blank" rel="noopener" href="https://aws.amazon.com/s3/">S3</a> , <a target="_blank" rel="noopener" href="https://cloud.google.com/storage/">GCS</a> and <a target="_blank" rel="noopener" href="https://azure.microsoft.com/services/storage/">Azure Storage</a> 云盘中，同样远程调用，这里不多赘述。</p>
<p><a target="_blank" rel="noopener" href="https://rasa.com/docs/rasa/user-guide/configuring-http-api/">https://rasa.com/docs/rasa/user-guide/configuring-http-api/</a></p>
</blockquote>
</li>
</ul>
<p>nlu服务开启后，post方式调用</p>
<p>post <a target="_blank" rel="noopener" href="http://localhost:5005/model/parse">http://localhost:5005/model/parse</a></p>
<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br></pre></td><td class="code"><pre><span class="line">input:</span><br><span class="line">&#123;<span class="attr">&quot;text&quot;</span>: <span class="string">&quot;明天成都的天气如何&quot;</span>&#125;</span><br><span class="line">output:</span><br><span class="line">&#123;</span><br><span class="line">    <span class="attr">&quot;intent&quot;</span>: &#123;</span><br><span class="line">        <span class="attr">&quot;name&quot;</span>: <span class="string">&quot;request_weather&quot;</span>,</span><br><span class="line">        <span class="attr">&quot;confidence&quot;</span>: <span class="number">0.5547698674</span></span><br><span class="line">    &#125;,</span><br><span class="line">    <span class="attr">&quot;entities&quot;</span>: [</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="attr">&quot;entity&quot;</span>: <span class="string">&quot;date_time&quot;</span>,</span><br><span class="line">            <span class="attr">&quot;value&quot;</span>: <span class="string">&quot;明天&quot;</span>,</span><br><span class="line">            <span class="attr">&quot;start&quot;</span>: <span class="number">0</span>,</span><br><span class="line">            <span class="attr">&quot;end&quot;</span>: <span class="number">2</span>,</span><br><span class="line">            <span class="attr">&quot;confidence&quot;</span>: <span class="literal">null</span>,</span><br><span class="line">            <span class="attr">&quot;extractor&quot;</span>: <span class="string">&quot;MitieEntityExtractor&quot;</span></span><br><span class="line">        &#125;,</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="attr">&quot;entity&quot;</span>: <span class="string">&quot;address&quot;</span>,</span><br><span class="line">            <span class="attr">&quot;value&quot;</span>: <span class="string">&quot;成都&quot;</span>,</span><br><span class="line">            <span class="attr">&quot;start&quot;</span>: <span class="number">2</span>,</span><br><span class="line">            <span class="attr">&quot;end&quot;</span>: <span class="number">4</span>,</span><br><span class="line">            <span class="attr">&quot;confidence&quot;</span>: <span class="literal">null</span>,</span><br><span class="line">            <span class="attr">&quot;extractor&quot;</span>: <span class="string">&quot;MitieEntityExtractor&quot;</span></span><br><span class="line">        &#125;</span><br><span class="line">    ],</span><br><span class="line">    <span class="attr">&quot;intent_ranking&quot;</span>: [</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="attr">&quot;name&quot;</span>: <span class="string">&quot;request_weather&quot;</span>,</span><br><span class="line">            <span class="attr">&quot;confidence&quot;</span>: <span class="number">0.5547698674</span></span><br><span class="line">        &#125;,</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="attr">&quot;name&quot;</span>: <span class="string">&quot;affirm&quot;</span>,</span><br><span class="line">            <span class="attr">&quot;confidence&quot;</span>: <span class="number">0.0898880708</span></span><br><span class="line">        &#125;,</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="attr">&quot;name&quot;</span>: <span class="string">&quot;deny&quot;</span>,</span><br><span class="line">            <span class="attr">&quot;confidence&quot;</span>: <span class="number">0.078563989</span></span><br><span class="line">        &#125;,</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="attr">&quot;name&quot;</span>: <span class="string">&quot;thanks&quot;</span>,</span><br><span class="line">            <span class="attr">&quot;confidence&quot;</span>: <span class="number">0.072717722</span></span><br><span class="line">        &#125;,</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="attr">&quot;name&quot;</span>: <span class="string">&quot;goodbye&quot;</span>,</span><br><span class="line">            <span class="attr">&quot;confidence&quot;</span>: <span class="number">0.0726876305</span></span><br><span class="line">        &#125;,</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="attr">&quot;name&quot;</span>: <span class="string">&quot;greet&quot;</span>,</span><br><span class="line">            <span class="attr">&quot;confidence&quot;</span>: <span class="number">0.0697155938</span></span><br><span class="line">        &#125;,</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="attr">&quot;name&quot;</span>: <span class="string">&quot;whattodo&quot;</span>,</span><br><span class="line">            <span class="attr">&quot;confidence&quot;</span>: <span class="number">0.0443638481</span></span><br><span class="line">        &#125;,</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="attr">&quot;name&quot;</span>: <span class="string">&quot;whoareyou&quot;</span>,</span><br><span class="line">            <span class="attr">&quot;confidence&quot;</span>: <span class="number">0.0172932785</span></span><br><span class="line">        &#125;</span><br><span class="line">    ],</span><br><span class="line">    <span class="attr">&quot;text&quot;</span>: <span class="string">&quot;明天成都的天气如何&quot;</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<h4 id="1-3-启动action"><a href="#1-3-启动action" class="headerlink" title="1.3 启动action"></a>1.3 启动action</h4><blockquote>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python -m rasa run actions --port 5055 --actions actions --debug</span><br></pre></td></tr></table></figure>
</blockquote>
<h3 id="2-NLU"><a href="#2-NLU" class="headerlink" title="2. NLU"></a>2. NLU</h3><p><img src="https://gitee.com/fushengwuyu1993/images/raw/master/imgs/1590138247599.png" alt="1590138247599"></p>
<p><img src="https://gitee.com/fushengwuyu1993/images/raw/master/imgs/1590138270872.png" alt="1590138270872"></p>
<h4 id="2-1-数据格式"><a href="#2-1-数据格式" class="headerlink" title="2.1 数据格式"></a>2.1 数据格式</h4><p>rasa支持markdown和json两种数据格式，同时提供了相互转化的命令。</p>
<p>nlu训练数据包含四个部分：</p>
<ul>
<li><p>Common Example</p>
<p>唯一必须提供数据。由三部分组成：intent、text、entities。</p>
<blockquote>
<p>## intent: 你的意图名称</p>
<p>- text</p>
</blockquote>
<p>text中可以不包括实体，如果有实体使用<code>[entityText](entityName)</code>来标记。</p>
</li>
<li><p>synonyms</p>
</li>
<li><p>Regular Expression Features</p>
</li>
<li><p>lookup tables</p>
</li>
</ul>
<h4 id="2-2-数据转化"><a href="#2-2-数据转化" class="headerlink" title="2.2 数据转化"></a>2.2 数据转化</h4><p>rasa提供了json和markdown格式的转化命令</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">usage: rasa data convert nlu [-h] [-v] [-vv] [--quiet] --data DATA --out OUT</span><br><span class="line">                             [-l LANGUAGE] -f &#123;json,md&#125;</span><br><span class="line"></span><br><span class="line">optional arguments:</span><br><span class="line">  -h, --help            show this help message and exit</span><br><span class="line">  --data DATA           Path to the file or directory containing Rasa NLU</span><br><span class="line">                        data. (default: None)</span><br><span class="line">  --out OUT             File where to save training data in Rasa format.</span><br><span class="line">                        (default: None)</span><br><span class="line">  -l LANGUAGE, --language LANGUAGE</span><br><span class="line">                        Language of data. (default: en)</span><br><span class="line">  -f &#123;json,md&#125;, --format &#123;json,md&#125;</span><br><span class="line">                        Output format the training data should be converted</span><br><span class="line">                        into. (default: None)</span><br><span class="line"></span><br><span class="line">Python Logging Options:</span><br><span class="line">  -v, --verbose         Be verbose. Sets logging level to INFO. (default:</span><br><span class="line">                        None)</span><br><span class="line">  -vv, --debug          Print lots of debugging statements. Sets logging level</span><br><span class="line">                        to DEBUG. (default: None)</span><br><span class="line">  --quiet               Be quiet! Sets logging level to WARNING. (default:</span><br><span class="line">                        None)</span><br></pre></td></tr></table></figure>

<p>example：</p>
<blockquote>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rasa data convert nlu --data M3-training_dataset_1564317234.json --out M3-training_dataset_1564317234.md -f md</span><br></pre></td></tr></table></figure>
</blockquote>
<h3 id="3-core"><a href="#3-core" class="headerlink" title="3. core"></a>3. core</h3><p>备注1： core模型是一个分类分为，类别数为domain中定义的action数。action主要分为以下4类：</p>
<ul>
<li><p>custom action</p>
</li>
<li><p>utterance：response、template</p>
</li>
<li><p>default actions</p>
<blockquote>
<p>[‘action_listen’, ‘action_restart’, ‘action_session_start’, ‘action_default_fallback’, ‘action_deactivate_form’, ‘action_revert_fallback_events’, ‘action_default_ask_affirmation’, ‘action_default_ask_rephrase’, ‘action_back’]</p>
</blockquote>
</li>
<li><p>forms（表单）</p>
</li>
</ul>
<p>action类别为各类action取交集后的结果。</p>
<p>备注2：用户可以直接像core发送请求，不经过nlu模块。参数格式：/intent{“entityName”: “entityValue”, …}</p>
<blockquote>
<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">	<span class="attr">&quot;sender&quot;</span>: <span class="string">&quot;kkkkkkk&quot;</span>,</span><br><span class="line">	<span class="attr">&quot;message&quot;</span>: <span class="string">&quot;/search_treat&#123;\&quot;disease\&quot;:\&quot;丛集性头痛\&quot;, \&quot;sure\&quot;:\&quot;丛集性头痛\&quot;&#125;&quot;</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">[</span><br><span class="line">    &#123;</span><br><span class="line">        &quot;recipient_id&quot;: &quot;kkkkkkk&quot;,</span><br><span class="line">        &quot;text&quot;: &quot;丛集性头痛的简介：从集性头痛(clusterheadaches)亦称偏头痛性神经痛、组胺性头痛、岩神经痛、蝶腭神经痛、Horton头痛等，.病员在某个时期内突然出现一系列的剧烈头痛。一般无前兆，疼痛多见于一侧眼眶或(及)额颞部，可伴同侧眼结膜充血、流泪、眼睑水肿或鼻塞、流涕，有时出现瞳孔缩小、垂睑、脸红、颊肿等症状。头痛多为非搏动性剧痛。病人坐立不安或前俯后仰地摇动，部分病员用拳击头部以缓解疼痛。&quot;</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">        &quot;recipient_id&quot;: &quot;kkkkkkk&quot;,</span><br><span class="line">        &quot;text&quot;: &quot;丛集性头痛的治疗方式有：药物治疗、支持性治疗&quot;</span><br><span class="line">    &#125;</span><br><span class="line">]</span><br></pre></td></tr></table></figure>
</blockquote>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2021/07/20/vim%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="sunshine">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="浮生物语的博客">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2021/07/20/vim%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/" class="post-title-link" itemprop="url">vim常用命令总结</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>
              

              <time title="创建时间：2021-07-20 00:00:00 / 修改时间：10:20:12" itemprop="dateCreated datePublished" datetime="2021-07-20T00:00:00+08:00">2021-07-20</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>vim常用命令</p>
<ol>
<li>行内移动<ul>
<li>w： 向前移动（单词）</li>
<li>b：向后移动（单词）</li>
<li>$： 移动到行末</li>
<li>^ ：移动到行首</li>
</ul>
</li>
<li>跨行移动<ul>
<li>↑，↓</li>
<li>数字+方向键：5↓代表向下移动5行</li>
<li>ctrl+f：向前翻页</li>
<li>ctrl+b：向后翻页</li>
<li>G（shift+g）：移动到文件末尾</li>
<li>gg：移动到文件开头</li>
<li>N+%：移动到文件的N%处，50+%表示移动到文件的中间位置</li>
<li>N+g：移动到文件的N行处，10+g表示移动到第10行。</li>
</ul>
</li>
<li>定向移动（查找）<ul>
<li>/text：查找text，使用n/N 向下/向上跳转。vim查找支持正则，如：/^$查找空白行。</li>
</ul>
</li>
<li>文件格式与编码<ul>
<li>:set list ：显示制表符和行尾， ：set nolist：取消显示</li>
<li>:set nu(number) ：显示行号，:set nonumber 取消显示</li>
<li>:set fileencoding：查看当前文件编码，当vim无法识别编码的时候，默认实用latin-1读取。:e ++enc=gb18030 强制使用gb18030编码重新打开。</li>
</ul>
</li>
<li>分屏<ul>
<li>vim -o file1 file2： 打开两个文件（默认水平分屏）</li>
<li>已经打开vim的情况下，:vs file2： 打开file2，vs指vertical split。</li>
<li>ctrl + w +  ←(h)/↑(j)/↓(k)/→(l)：控制调整的方向。</li>
<li>ctrl + w+ w：跳转下一个窗口</li>
<li>ctrl + w +c 关闭窗口</li>
</ul>
</li>
</ol>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2021/07/20/%E4%B8%AD%E6%96%87%E6%96%87%E6%9C%AC%E7%BA%A0%E9%94%99%E8%B0%83%E7%A0%94/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="sunshine">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="浮生物语的博客">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2021/07/20/%E4%B8%AD%E6%96%87%E6%96%87%E6%9C%AC%E7%BA%A0%E9%94%99%E8%B0%83%E7%A0%94/" class="post-title-link" itemprop="url">中文文本纠错调研</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>
              

              <time title="创建时间：2021-07-20 00:00:00 / 修改时间：10:16:06" itemprop="dateCreated datePublished" datetime="2021-07-20T00:00:00+08:00">2021-07-20</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h4 id="1-常见的中文错误类型"><a href="#1-常见的中文错误类型" class="headerlink" title="1. 常见的中文错误类型"></a>1. 常见的中文错误类型</h4><ul>
<li><p>发音错误， 特点：音近，发音不标准， 原因：地方发音，语言转化。 - 灰机</p>
</li>
<li><p>拼写错误：特点： 正确词语错误使用， 原因： 输入法导致-拼音、五笔、手写 - 眼睛蛇</p>
</li>
<li><p>语法，知识错误： 特点：逻辑错误，多字、少字，乱序 - 女性患病前列腺炎</p>
</li>
</ul>
<h4 id="2-研究现状"><a href="#2-研究现状" class="headerlink" title="2. 研究现状"></a>2. 研究现状</h4><h5 id="2-1-通用纠错项目"><a href="#2-1-通用纠错项目" class="headerlink" title="2.1 通用纠错项目"></a>2.1 通用纠错项目</h5><blockquote>
<p><a target="_blank" rel="noopener" href="https://github.com/shibing624/pycorrector">https://github.com/shibing624/pycorrector</a></p>
</blockquote>
<ul>
<li><p>错误检测</p>
<ul>
<li>常用字典匹配： 切词后不再常用字典中认为有错</li>
<li>统计语言模型：某个字的似然概率低于句子的平均值</li>
<li>混淆字典匹配：example - 国藉 -&gt; 国籍</li>
</ul>
</li>
<li><p>候选召回</p>
<ul>
<li>近音字替换（拼音）： 藉\ji -&gt; 籍， 集， 寄。。。</li>
<li>近形字替换（五笔）： 藉 -&gt; 籍，藕，箱</li>
</ul>
</li>
<li><p>候选排序</p>
<ul>
<li><p>语言模型计算句子概率，取概率超过原句子切最大的</p>
<blockquote>
<p>P(患者1天前体检发现脾动脉瘤)</p>
<p>P(患者1天前体检发现皮动脉瘤)</p>
<p>P(患者1天前体检发现劈动脉瘤)</p>
</blockquote>
<h5 id="2-2-学术界进展"><a href="#2-2-学术界进展" class="headerlink" title="2.2 学术界进展"></a>2.2 学术界进展</h5></li>
<li><p>基于序列标注的纠错</p>
<blockquote>
<p>《 Alibaba at IJCNLP-2017 Task 1: Embedding Grammatical Features<br>into LSTMs for Chinese Grammatical Error Diagnosis Task 》</p>
</blockquote>
<p>利用序列标注模型 + 人工提取特征进行错误位置的标注</p>
<p><img src="https://gitee.com/fushengwuyu1993/images/raw/master/imgs/1577068913235.png" alt="1577068913235"></p>
<pre><code>                 2017年IJCNLP举办的CGED比赛中阿里团队提出的Top1方案
</code></pre>
<p>成绩： P：0.36， R： 0.21， F1：0.27</p>
</li>
<li><p>基于NMT的纠错</p>
<blockquote>
<p>《 Youdao’s Winning Solution to the NLPCC-2018 Task 2 Challenge: A Neural<br>Machine Translation Approach to Chinese Grammatical Error Correction 》</p>
</blockquote>
<p>利用模型将错误语句翻译成正确语句，利用transformer模型完成端到端的纠错过程</p>
<p><img src="https://gitee.com/fushengwuyu1993/images/raw/master/imgs/1577069217626.png" alt="1577069217626"></p>
<p>成绩： P： 0.34， R：0.18， F0.5： 0.29</p>
</li>
</ul>
</li>
</ul>
<h5 id="2-3-评价指标"><a href="#2-3-评价指标" class="headerlink" title="2.3 评价指标"></a>2.3 评价指标</h5><ul>
<li><p>过纠率 / 误报率</p>
<p>$FAR = \frac{正确句子被纠错的个数}{正确句子的个数}$</p>
</li>
<li><p>召回率</p>
<p>$$R = \frac{错误句子被改正的句子数}{错误的句子总数}$$</p>
</li>
<li><p>纠错目标</p>
<p>被改正的句子数 &gt;&gt; 被改错的句子数</p>
<p>​                       $$K * R &gt;&gt; (1 - K) * FAR$$</p>
<p>目标在于尽可能的提高召回率R。</p>
</li>
</ul>
<h5 id="2-4-存在的问题"><a href="#2-4-存在的问题" class="headerlink" title="2.4 存在的问题"></a>2.4 存在的问题</h5><p>​    公司目前纠错现状，还存在一下问题。</p>
<ul>
<li>缺乏标注语料，难以展开基于深度学习的监督学习</li>
<li>纠错强调实时性，对内存和实效性要求很高，线上纠错不得超过10ms/句，导致大规模字典和复杂模型无法线上使用</li>
<li>纠错要求高准确性，宁愿牺牲召回也必须保证高准确度，防止过纠（把正确的词改错），过纠率不得高于0.2%</li>
<li>结合电子病历，绝大部分错误都是替换错误，同音字，同行字等。</li>
</ul>
<h4 id="3-平安文本纠错方案"><a href="#3-平安文本纠错方案" class="headerlink" title="3. 平安文本纠错方案"></a>3. 平安文本纠错方案</h4><p>​    平安人寿问答纠错模块结构如下图所示。其基本流程包括错误检测、候选召回、候选排序、候选筛选。</p>
<p><img src="https://gitee.com/fushengwuyu1993/images/raw/master/imgs/1577070846118.png" alt="1577070846118"></p>
<h5 id="3-1-错误检测"><a href="#3-1-错误检测" class="headerlink" title="3.1 错误检测"></a>3.1 错误检测</h5><ul>
<li><p>基于规则的错误检测</p>
<ul>
<li><p>拼音匹配： 适合实体错误检测，比如疾病，药品等实体，需要维护拼音-实体隐射字典</p>
<img src="https://gitee.com/fushengwuyu1993/images/raw/master/imgs/1577071517262.png" alt="1577071517262" style="zoom:80%;" /></li>
<li><p>拼音编辑距离：1.  检测所有编辑距离小于阈值的路径 2. 最优路径选取（最小拼音编辑距离， 最长字符匹配）3. 语言模型 + 规则联合筛选</p>
</li>
</ul>
</li>
<li><p>单双向2gram检测</p>
<p>当前词与上下文组成的2gram词频很低，认为有错</p>
<p>基于假设： 正确表述发生的频次要远远大于错误表述发生的次数</p>
<p><img src="https://gitee.com/fushengwuyu1993/images/raw/master/imgs/1577072025140.png" alt="yu1577072025140"></p>
</li>
<li><p>基于神经网络语言模型的错误检测 </p>
<p>核心思想：</p>
<ul>
<li>通过完形填空的方式预测候选字的概率分布</li>
<li>如果原字的概率不在topK或者top1比值操作阈值则认为有错</li>
</ul>
<p>改进措施：</p>
<ul>
<li><p>传统的语言模型从左到右，单向，只利用上文，改为双向模型，利用上下文信息。</p>
</li>
<li><p>传统的语言模型把预测字MASK，没有预测字的信息，可以改为引入当前字的混淆字信息（如：相似的字音和字形字）。</p>
</li>
<li><p>传统语言模型会直接预测字表，比如字表大小是3800，预测结果会直接得到3800个字的概率分布，其中大多是无用信息，且容易引发维度灾问题。可以通过将预测字约束在近音、近形和混淆字表里，提高效率和正确字与错误中字的区分度。</p>
<p><img src="https://gitee.com/fushengwuyu1993/images/raw/master/imgs/1581907503895.png" alt="1581907503895"></p>
<p><img src="https://gitee.com/fushengwuyu1993/images/raw/master/imgs/1581907667130.png" alt="1581907667130"></p>
</li>
</ul>
</li>
<li><p>基于word2vec-cbow改造的音字混合受限字表示语言模型检测算法</p>
<p>基于CSLM的中文拼写检测：《Chinese Spelling Errors Detection Based on  CSLM,2015》</p>
<p>主要特征：</p>
<ul>
<li>带入预测字及上下文拼音、五笔特征</li>
<li>去掉前后鼻音和翘舌音,并利用混淆音集映射的方式来提高模型对谐音错误的识别性能。</li>
<li>预测字表受限于近音字、近形字和混淆字表中。</li>
</ul>
<p><img src="https://gitee.com/fushengwuyu1993/images/raw/master/imgs/1581908381943.png" alt="1581908381943"></p>
</li>
</ul>
<h5 id="3-2-候选召回"><a href="#3-2-候选召回" class="headerlink" title="3.2 候选召回"></a>3.2 候选召回</h5><ul>
<li><p>近音字候选召回</p>
<p>选择近音字作为候选字，构造一个近音字字典。大规模的基础字典，使得在存储和读取速度方面收到了极大的调整。</p>
<p>字典存储构架如下：</p>
<p><img src="https://gitee.com/fushengwuyu1993/images/raw/master/imgs/1581911102435.png" alt="1581911102435"></p>
<p>关键技术：</p>
<ul>
<li>减低存储空间：<ol>
<li>利用Trie树降低信息冗余</li>
<li>利用经典结合CSR压缩稀疏矩阵</li>
<li>使用词典间的关联信息回复2gram同音字典</li>
</ol>
</li>
<li>提高读取速度：Trie树、CSR技术的高效索引。</li>
</ul>
</li>
<li><p>字、音编辑距离召回</p>
<p>使用编辑距离作为是否召回的依据。</p>
</li>
<li><p>混淆词集</p>
</li>
<li><p>疾病口语词</p>
</li>
</ul>
<h5 id="3-3-候选排序"><a href="#3-3-候选排序" class="headerlink" title="3.3 候选排序"></a>3.3 候选排序</h5><p>​    针对候选词的排序主要由二级排序来实现。</p>
<ul>
<li><p>一级排序</p>
<p>模型：逻辑回归LR</p>
<p>作用：二级排序比较耗时，通过一级排序初筛出TopK进入下一级</p>
<p>要求：正类召回率高，运行速度快</p>
<p>特征：</p>
<ul>
<li>频次比值：候选频次越高分数越高</li>
<li>编辑距离：编辑距离越小分数越高</li>
<li>拼音jaccard距离：拼音相近分数越高</li>
<li>4gram-LM概率差值：候选替换后橘子越通顺分数越高</li>
</ul>
<p>一级排序大致流程如下：</p>
<p><img src="https://gitee.com/fushengwuyu1993/images/raw/master/imgs/1581916837380.png" alt="1581916837380"></p>
<p>例如：甲状腺==姐姐==该怎么治疗？ -&gt;==结节  0.99==</p>
<ul>
<li>频次： 55 -&gt; 94</li>
<li>编辑距离：2</li>
<li>拼音jaccard距离：0</li>
<li>语言模型概率：-21.9 -&gt; -8.6</li>
</ul>
</li>
<li><p>二级排序</p>
<p>模型：xgboost</p>
<p>作用：分数超过设定阈值且是Top1作为最终候选</p>
<p>要求：正类准确率高</p>
<p>特征：</p>
<ol>
<li>局部特征<ul>
<li>切词变化：短语个数、含错别字片段长度等</li>
<li>PMI变化：最小值、最值</li>
<li>频次变化：频次变化、2gram频次变化</li>
<li>4gram语言模型变化</li>
<li>形音变化：拼音韵母变化、jccard距离、五笔变化</li>
<li>其他：停用词\错别字位置、候选来源等等</li>
</ul>
</li>
<li>全局特征<ul>
<li>Cbow-LM</li>
<li>LSTM-Attention-LM</li>
<li>BERT-LM</li>
</ul>
</li>
</ol>
<p><img src="https://gitee.com/fushengwuyu1993/images/raw/master/imgs/1581918099275.png" alt="1581918099275"></p>
<p>例子：==红癍狼仓==常见症状有哪些?   ==红斑狼疮==</p>
<ul>
<li>频次 ：20 -&gt; 1688</li>
<li>切词：红\癍\狼疮 (1\1\2) -&gt; 红斑狼疮 (4)</li>
<li>nn语言模型:癍 (&lt;0.001) -&gt; 斑 (0.979)</li>
<li>4gram语言模型:-19.2 -&gt; -10.6</li>
<li>PMI:红癍(0.33) -&gt;红斑(9.7)</li>
</ul>
</li>
</ul>
<h5 id="3-4-整体架构"><a href="#3-4-整体架构" class="headerlink" title="3.4 整体架构"></a>3.4 整体架构</h5><p><img src="https://gitee.com/fushengwuyu1993/images/raw/master/imgs/1581918508852.png" alt="1581918508852"></p>
<p>​    特性：</p>
<ul>
<li><p>pipline串联，热插拔</p>
</li>
<li><p>子模块均遵循检测-召回-排序流程</p>
</li>
<li><p>规则+模型混用</p>
</li>
<li><p>离线+在线</p>
</li>
</ul>
<p>在线方案：</p>
<ul>
<li>低延迟、低复杂度</li>
<li>高速1ms-3ms/句</li>
<li>用于线上实时预测</li>
</ul>
<p>离线方案：</p>
<ul>
<li>大规模、复杂模型</li>
<li>低速200ms-500ms/句</li>
<li>用于构造在线模型，训练数据</li>
</ul>
<h5 id="3-5-总结与改进"><a href="#3-5-总结与改进" class="headerlink" title="3.5 总结与改进"></a>3.5 总结与改进</h5><ol>
<li>优点：<ul>
<li>无监督，方便将该方法迁移到其他垂直领域，只需要重新无监督挖掘数据</li>
<li>系统架构方便插拔特殊编写纠错子模块</li>
</ul>
</li>
<li>缺点：<ul>
<li>很难迁移到通用领域</li>
<li>Pipline导致错误逐级传递</li>
<li>Pipline链越长，耗时越长</li>
</ul>
</li>
<li>改进思路<ul>
<li>强化上下文/全局的语义理解</li>
<li>训练预料去噪处理</li>
<li>端到端算法，如NMT（神经机器翻译）</li>
<li>语法错误（多字少字乱序）</li>
</ul>
</li>
</ol>
<h4 id="4-爱奇艺文本纠错方案"><a href="#4-爱奇艺文本纠错方案" class="headerlink" title="4. 爱奇艺文本纠错方案"></a>4. 爱奇艺文本纠错方案</h4><p>《FASPell: A Fast, Adaptable, Simple, Powerful Chinese Spell Checker Based On DAE-Decoder Paradigm》</p>
<h5 id="4-1-背景"><a href="#4-1-背景" class="headerlink" title="4.1 背景"></a>4.1 背景</h5><p>​    大部分的中文拼写检查模型都使用用一个范式，即讲每个汉字的固定相似字符集（混淆集或困惑集）作为候选项，然后使用过滤器选择最佳候选项作为错字的替换字符。这种设计面临着两个主要瓶颈：</p>
<ul>
<li><p>稀疏的中文拼写检查数据上的过拟合问题。</p>
<p>​    由于中文拼写检查数据需要乏味繁冗的专业人力工作，因为一直资源不足。为了防止模型的过拟合，        Wang等人（2018）提出了一种自动方法来生成伪拼写检查数据。 但是，当生成的数据达到40k句子时，其拼写检查模型的精度不再提高。 Zhao等人（2017）使用了大量的语言学规则来过滤候选项，但结果却比我们的表现差，尽管我们的模型没有利用任何语言学知识。</p>
</li>
<li><p>困惑集的使用带来的汉字字符相似度利用上的不灵活性和不充分性问题。</p>
<p>​    困惑集因为是固定的，因此并非在任何语境、场景下都能包含正确候选项（一个比较极端的例子是，如果困惑集按照繁体中文制定，那么繁体中文的 “體”和“休”肯定不在困惑集的同一组相似字符中，但是在简体中文中对应的“体”和“休”缺是相似字符，如果错误文本中是把“休”写成了“体”，那么繁体中文困惑集下就无法检出，必须专门再制定一个简体困惑集才可以），这会极大降低检测的召回率（不灵活性问题）；另外，困惑集中的字符的相似性的信息有损失，没有得到充分利用，因为一个字符在困惑集中相似字符是无差别对待的，然而事实上每两个字符间的相似度明显是有差别的，因此会影响检测的精确率（不充分性）。</p>
</li>
</ul>
<h5 id="4-2-设计"><a href="#4-2-设计" class="headerlink" title="4.2 设计"></a>4.2 设计</h5><p>​    FASPell提出通过设计中文拼写检查范式来避免传统模型的两个瓶颈。FASPell利用seq2seq的思想，包括去噪自编码器（DAE）和解码器。</p>
<ul>
<li><p>编码器DAE</p>
<p>DAE通过利用无监督预训练方法（BERT），减少了监督学习中所需的中文拼写检查数据量（&lt;10000个句子）。DAE可以将错误文本修改为正确文本的可能候选矩阵，解码器只需要在这个矩阵中寻求最佳候选项作为输出。DAE因为可以在大规模正常预料数据上无监督训练，而仅在中文拼写检测数据上做fine-tune，避免了过拟合问题。此外，只要DAE足够强大，所有语境上可能的候选字符都可以出现，且候选字符是根据上下文即时生成的，避免了困惑集带来的不灵活性。</p>
</li>
<li><p>解码器CSD</p>
<p>CSD巧妙的将预训练模型的置信度和字相似度结合起来，作为候选集的评价标准，消除困惑集的使用。CSD根据量化的字符相似度和DAE给出的符合语境的置信度来过滤出正确的替换字符，如此，字符相似性上的细微差别信息都可以得到充分利用。</p>
</li>
</ul>
<p>模型架构如图1所示：</p>
<p><img src="https://gitee.com/fushengwuyu1993/images/raw/master/imgs/1581923079272.png" alt="1581923079272"></p>
<p>​    可以看到，在FASPell中，DAE由BERT中的掩码语言模型（MLM）来充当，而解码器使用了置信度-相似度解码器(CSD)。</p>
<h5 id="4-3-CSD解码器"><a href="#4-3-CSD解码器" class="headerlink" title="4.3 CSD解码器"></a>4.3 CSD解码器</h5><p>​    CSD主要结合DAE的置信度和字符相似度，置信度直接由DAE给出，暂且不谈，这里详细说明字符相似度。</p>
<ol>
<li><p>字符相似度</p>
<ul>
<li><p>字音</p>
<p>采用中日韩统一表意文字（CJK）语言中的汉语发音，尽管目前只是对中文文本检错纠错，但是实验证明考虑诸如粤语、日语音读、韩语、越南语的汉字发音对提高拼写检查的性能是有帮助的，而过去的方法均只考虑了普通话拼音。</p>
</li>
<li><p>字形</p>
<p>采用Unicode标准的IDS表征，它可以准确的扫描汉字中各个笔画和他们的布局方式，这使得即使相同笔画和笔画顺序的汉字之间也拥有不为1的相似度。</p>
</li>
</ul>
<p>以午和牛，田和由为例：</p>
<p><img src="https://gitee.com/fushengwuyu1993/images/raw/master/imgs/1581929776094.png" alt="1581929776094"></p>
</li>
<li><p>训练CSD</p>
<p>CSD的训练阶段，利用训练集文本通过MLM输出的矩阵，逐行绘制置信度-字符相似度散点图，确定能将FP和 TP分开的最佳分界曲线。</p>
<p><img src="https://gitee.com/fushengwuyu1993/images/raw/master/imgs/1581930742369.png" alt="1581930742369"></p>
<p>​    如上图所示，红点代表正确检测并正确纠正的样本，蓝色圆圈代表正确检测但纠正错误的样本，叉叉代表错误检测的样本。图一并没有过滤候选集；图二倾向于错误检测性能，大部分正确检测的候选集保留了下来；图三更加倾向于错误纠正，FASPell采用此种曲线；图四采用加权确定阈值的方式来确定曲线$（0.8×confidence+0.2×similarity&lt;0.8）$。</p>
<p>​    在训练阶段，我们的目标在于确定一条合适的曲线，供于推理阶段使用。</p>
</li>
<li><p>推理</p>
<p>在推理阶段，逐行根据分界线过滤掉FP得到TP结果，然后将每行的结果取并集得到最终替换结果。以上面架构图为例片，句子首先通过fine-tune训练好的MLM模型，得到的候选字符矩阵通过CSD进行解码过滤，第一行候选项中只有“主”字没有被CSD过滤掉，第二行只有“著”字未被过滤掉，其它行候选项均被分界线过滤清除，得到最终输出结果，即“苦”字被替换为为“著”，“丰”被替换为“主”。</p>
</li>
</ol>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2021/07/20/%E4%BF%A1%E6%81%AF%E7%86%B5/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="sunshine">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="浮生物语的博客">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2021/07/20/%E4%BF%A1%E6%81%AF%E7%86%B5/" class="post-title-link" itemprop="url">信息熵笔记</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>
              

              <time title="创建时间：2021-07-20 00:00:00 / 修改时间：09:08:46" itemprop="dateCreated datePublished" datetime="2021-07-20T00:00:00+08:00">2021-07-20</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h4 id="一-熵"><a href="#一-熵" class="headerlink" title="一. 熵"></a>一. 熵</h4><ol>
<li><p>解释</p>
<ul>
<li>熵是不确定的度量</li>
<li>熵是信息的度量</li>
</ul>
</li>
<li><p>计算公式<br>$$<br>S = - \sum _{x} p(x)\log p(x) \tag{1}<br>$$</p>
<p>log可以取自然对数，也可以是以底为2的对数，任意大于1的底都是成立的。换底只不过换了信息的单位而已。</p>
</li>
</ol>
<p>对于连续的概率分布，熵的定义为：<br>$$<br>S=- \int p(x) \log p (x)dx \tag{2}<br>$$</p>
<ol start="3">
<li><p>联合熵<br>$$<br>S[p(x,y)]=-\sum_{x} \sum_{y}p(x,y)\ln p(x,y) \tag{3}<br>$$</p>
</li>
<li><p>条件熵<br>$$<br>S(Y|X)=S[p(x,y)] - S[p(x)] \tag{4}<br>$$<br>等价于：<br>$$<br>S(Y|X)=-\sum_{x} \sum_{y}p(x,y) \log p(y:x) \tag{5}<br>$$<br>通俗的说，本来的信息量有$$S[p(x,y)]$$ ，然后$$p(x)$$ 能带来$$S[p(x)]$$ 的信息，减去其不确定性，剩下的就是条件熵。</p>
</li>
<li><p>互信息</p>
<p>互信息可以度量两个随机事件“相关性”的量化<br>$$<br>S(X;Y)=\sum_{x}\sum_{y}p(x,y)\log \frac{p(x,y)}{p(x)p(y)} \tag{6}<br>$$</p>
<p>互信息就是随机事件X，以及知道随机事件Y条件下的不确定性，或者条件熵之间的差异。即。<br>$$<br>S(X;Y)=S(X) -S(X|Y) \tag{7}<br>$$</p>
</li>
<li><p>相对熵</p>
<p>相对熵也是来衡量相关性，但和互信息不同，它用来衡量两个取值为正数的函数的相似性。<br>$$<br>KL(f(x)||g(x))=\sum_{x \in X}f(x)\cdot \log \frac {f(x)}{g(x)} \tag{8}<br>$$</p>
<ul>
<li>对于两个完全相同的函数，他们的相对数为0</li>
<li>相对熵越大，两个函数差异越大；反之，相对熵越小，两函数差异越小</li>
<li>对于概率分布和概率密度分布，如果取值均大于0，相对熵可以度量两个随机分布的差异性</li>
</ul>
<p>相对熵是不对称的。<br>$$<br>KL(f(x)||g(x)) \ne KL(g(x)||f(x)) \tag{9}<br>$$<br>詹森和香农提出了一种相对熵的计算方法，将上面的不等式变为等式。<br>$$<br>JS(f(x)||g(x))=\frac{1}{2}[KL(f(x)||g(x))+KL(g(x)||f(x))] \tag{10}<br>$$</p>
</li>
</ol>
<h4 id="二-最大熵"><a href="#二-最大熵" class="headerlink" title="二. 最大熵"></a>二. 最大熵</h4><p>当我们想要得到一个随机事件的概率分布时，如果没有足够的信息能够确定这个概率分布（可能是不能确定分布，也可能是知道分布的类型，但是还有若干个参数没有确定），那么最“保险”的方案就是选择使得熵最大的分布。</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2021/07/20/%E5%B8%B8%E8%A7%81%E5%AE%89%E8%A3%85%E8%84%9A%E6%9C%AC/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="sunshine">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="浮生物语的博客">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2021/07/20/%E5%B8%B8%E8%A7%81%E5%AE%89%E8%A3%85%E8%84%9A%E6%9C%AC/" class="post-title-link" itemprop="url">常见安装脚本</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>
              

              <time title="创建时间：2021-07-20 00:00:00 / 修改时间：10:14:11" itemprop="dateCreated datePublished" datetime="2021-07-20T00:00:00+08:00">2021-07-20</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="1-安装python3-6-5"><a href="#1-安装python3-6-5" class="headerlink" title="1. 安装python3.6.5"></a>1. 安装python3.6.5</h2><ol>
<li><p>安装依赖包</p>
<ul>
<li><p>centos</p>
<blockquote>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum -y install zlib-devel bzip2-devel openssl-devel ncurses-devel sqlite-devel readline-devel tk-devel gdbm-devel db4-devel libpcap-devel xz-devel libffi-devel</span><br></pre></td></tr></table></figure></blockquote>
</li>
<li><p>ubuntu</p>
<blockquote>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get install zlib1g-dev libbz2-dev libssl-dev libncurses5-dev libsqlite3-dev libreadline-dev tk-dev libgdbm-dev libdb-dev libpcap-dev xz-utils libexpat1-dev liblzma-dev libffi-dev libc6-dev</span><br></pre></td></tr></table></figure></blockquote>
</li>
</ul>
</li>
<li><p>解压</p>
</li>
<li><p>安装</p>
<blockquote>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">./configure</span><br><span class="line">make &amp;&amp; make install</span><br></pre></td></tr></table></figure></blockquote>
</li>
<li><p>添加软连接</p>
<blockquote>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ln -s /usr/local/python3/bin/python3.6.7 /usr/bin/python3</span><br><span class="line">ln -s /usr/local/python3/bin/pip3.6.5 /usr/bin/pip3</span><br></pre></td></tr></table></figure></blockquote>
</li>
</ol>
<h2 id="2-安装neo4j"><a href="#2-安装neo4j" class="headerlink" title="2. 安装neo4j"></a>2. 安装neo4j</h2><ol>
<li><p>neo4j底层依赖java，请自行安装jdk</p>
</li>
<li><p>下载neo4j</p>
<p><a target="_blank" rel="noopener" href="https://neo4j.com/download/other-releases/#releases">https://neo4j.com/download/other-releases/#releases</a></p>
</li>
<li><p>解压</p>
</li>
<li><p>配置neo4j.conf文件，修改相应配置(配置行数针对3.4.5版本，其他版本自行寻找相应配置)</p>
<blockquote>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 修改第22行load csv时l路径，在前面加个<span class="comment">#，可从任意路径读取文件</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash">dbms.directories.import=import</span></span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 修改35行和36行，设置JVM初始堆内存和JVM最大堆内存</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 生产环境给的JVM最大堆内存越大越好，但是要小于机器的物理内存</span></span><br><span class="line">dbms.memory.heap.initial_size=5g</span><br><span class="line">dbms.memory.heap.max_size=10g</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 修改46行，可以认为这个是缓存，如果机器配置高，这个越大越好</span></span><br><span class="line">dbms.memory.pagecache.size=10g</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 修改54行，去掉改行的<span class="comment">#，可以远程通过ip访问neo4j数据库</span></span></span><br><span class="line">dbms.connectors.default_listen_address=0.0.0.0</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 默认 bolt端口是7687，http端口是7474，https关口是7473，不修改下面3项也可以</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 修改71行，去掉<span class="comment">#，设置http端口为7687，端口可以自定义，只要不和其他端口冲突就行</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash">dbms.connector.bolt.listen_address=:7687</span></span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 修改75行，去掉<span class="comment">#，设置http端口为7474，端口可以自定义，只要不和其他端口冲突就行</span></span></span><br><span class="line">dbms.connector.http.listen_address=:7474</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 修改79行，去掉<span class="comment">#，设置http端口为7473，端口可以自定义，只要不和其他端口冲突就行</span></span></span><br><span class="line">dbms.connector.https.listen_address=:7473</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 修改227行，去掉<span class="comment">#，允许从远程url来load csv</span></span></span><br><span class="line">dbms.security.allow_csv_import_from_file_urls=true</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 修改246行，允许使用neo4j-shell，类似于mysql 命令行之类的</span></span><br><span class="line">dbms.shell.enabled=true</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 修改235行，去掉<span class="comment">#，设置连接neo4j-shell的端口，一般都是localhost或者127.0.0.1，这样安全，其他地址的话，一般使用https就行</span></span></span><br><span class="line">dbms.shell.host=127.0.0.1</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 修改250行，去掉<span class="comment">#，设置neo4j-shell端口，端口可以自定义，只要不和其他端口冲突就行</span></span></span><br><span class="line">dbms.shell.port=1337</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 修改254行，设置neo4j可读可写</span></span><br><span class="line">dbms.read_only=false</span><br></pre></td></tr></table></figure></blockquote>
</li>
<li><p>启动，进入neo4j目录。</p>
<blockquote>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./bin/neo4j start</span><br></pre></td></tr></table></figure>
</blockquote>
<blockquote>
<p>Active database: graph.db<br>Directories in use:<br>  home:         /root/neo4j-community-3.4.5<br>  config:       /root/neo4j-community-3.4.5/conf<br>  logs:         /root/neo4j-community-3.4.5/logs<br>  plugins:      /root/neo4j-community-3.4.5/plugins<br>  import:       NOT SET<br>  data:         /root/neo4j-community-3.4.5/data<br>  certificates: /root/neo4j-community-3.4.5/certificates<br>  run:          /root/neo4j-community-3.4.5/run<br>Starting Neo4j.<br>Started neo4j (pid 19029). It is available at <a target="_blank" rel="noopener" href="http://0.0.0.0:7474/">http://0.0.0.0:7474/</a><br>There may be a short delay until the server is ready.<br>See /root/neo4j-community-3.4.5/logs/neo4j.log for current status.</p>
</blockquote>
</li>
<li><p>停止</p>
<blockquote>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/neo4j stop</span><br></pre></td></tr></table></figure>
</blockquote>
<blockquote>
<p>Stopping Neo4j.. stopped</p>
</blockquote>
</li>
</ol>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2021/07/20/%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B%E6%A2%B3%E7%90%86/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="sunshine">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="浮生物语的博客">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2021/07/20/%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B%E6%A2%B3%E7%90%86/" class="post-title-link" itemprop="url">预训练模型梳理</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>
              

              <time title="创建时间：2021-07-20 00:00:00 / 修改时间：10:15:32" itemprop="dateCreated datePublished" datetime="2021-07-20T00:00:00+08:00">2021-07-20</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>summary Table</p>
<table>
<thead>
<tr>
<th>模型</th>
<th>语言模型</th>
<th>特征抽取</th>
<th>上下文表征</th>
<th>亮点</th>
</tr>
</thead>
<tbody><tr>
<td>ELMO</td>
<td>BiLM</td>
<td>Bi-LSTM</td>
<td>单向</td>
<td>2个单向语言模型拼接</td>
</tr>
<tr>
<td>ULMFiT</td>
<td>LM</td>
<td>AWD-LSTM</td>
<td>单向</td>
<td>引入逐层解冻fine-tune中的灾难性问题</td>
</tr>
<tr>
<td>SiATL</td>
<td>LM</td>
<td>LSTM</td>
<td>单向</td>
<td>引入逐层解冻+辅助LM解决fine-tune中的灾难性问题</td>
</tr>
<tr>
<td>GPT1.0</td>
<td>LM</td>
<td>Transformer</td>
<td>单向</td>
<td>统一下游任务框架，验证Transformer在LM中的强大</td>
</tr>
<tr>
<td>GPT2.0</td>
<td>LM</td>
<td>Transformer</td>
<td>单向</td>
<td>没有特定的fine-tune流程，生成任务取得好的结果</td>
</tr>
<tr>
<td>BERT</td>
<td>MLM</td>
<td>Transformer</td>
<td>双向</td>
<td>MLM获取上下文相关的双向特征表示</td>
</tr>
<tr>
<td>MASS</td>
<td>LM+MLM</td>
<td>Transformer</td>
<td>单向/双向</td>
<td>改进BERT生成任务：统一为类seq2seq的预训练模型</td>
</tr>
<tr>
<td>UNILM</td>
<td>LM+MLM+S2SLM</td>
<td>Transformer</td>
<td>单向/双向</td>
<td>改进BERT生成任务，直接从mask矩阵的角度出发</td>
</tr>
<tr>
<td>ENRIE1.0</td>
<td>MLM（BPE）</td>
<td>Transformer</td>
<td>双向</td>
<td>引入知识：3种MASK策略（BPE）预测短语和实体</td>
</tr>
<tr>
<td>ENRIE</td>
<td>MLM+DEA</td>
<td>Transformer</td>
<td>双向</td>
<td>引入知识：讲实体向量和文本表示相融合</td>
</tr>
<tr>
<td>MTDNN</td>
<td>MLM</td>
<td>Transformer</td>
<td>双向</td>
<td>引入多任务学习：在下游阶段</td>
</tr>
<tr>
<td>ENRIE2.0</td>
<td>MLM+Multi-Task</td>
<td>Transformer</td>
<td>双向</td>
<td>引入多任务学习：在预训练阶段，连续增量学习</td>
</tr>
<tr>
<td>SpanBERT</td>
<td>MLM+SPO</td>
<td>Transformer</td>
<td>双向</td>
<td>不需要按照边界信息进行mask</td>
</tr>
<tr>
<td>RoBERTa</td>
<td>MLM</td>
<td>Transformer</td>
<td>双向</td>
<td>精细调参，舍弃NSP</td>
</tr>
<tr>
<td>XLNet</td>
<td>PLM</td>
<td>Transformer-XL</td>
<td>双向</td>
<td>排列语言模型+双注意力机制+Transformer</td>
</tr>
</tbody></table>
<h5 id="1-word2vec"><a href="#1-word2vec" class="headerlink" title="1. word2vec"></a>1. word2vec</h5><h5 id="2-ELMo"><a href="#2-ELMo" class="headerlink" title="2. ELMo"></a>2. ELMo</h5><p><img src="https://gitee.com/fushengwuyu1993/images/raw/master/imgs/1583220450290.png" alt="1583220450290"></p>
<ul>
<li><p>要点</p>
<ul>
<li>引入双向语言模型，2个单向的语言模型（向前和向后）的集成。</li>
<li>通过保存预训练好的2层BiLSTM，通过特征集成或finetune应用于下游任务。</li>
</ul>
</li>
<li><p>缺陷</p>
<ul>
<li>本质上是自回归语言模型，只能获取单向特征表示，不能同时获取上下文。</li>
<li>LSTM不能解决长距离依赖问题。</li>
</ul>
</li>
<li><p>为什么不能用BiLSTM构建双向语言模型</p>
<p>如果采用BiLSTM构建双向语言模型，会造成标签泄露的问题。因此ELMo前向和后向的LSTM参数独立，共享词向量，拼接构造语言模型。</p>
<p><img src="https://gitee.com/fushengwuyu1993/images/raw/master/imgs/1583461295578.png" alt="1583461295578"></p>
</li>
</ul>
<h5 id="3-GPT1-0-GPT2-0-OpenAI"><a href="#3-GPT1-0-GPT2-0-OpenAI" class="headerlink" title="3. GPT1.0/GPT2.0(OpenAI)"></a>3. GPT1.0/GPT2.0(OpenAI)</h5><ul>
<li><p>GPT1.0要点</p>
<ul>
<li><p>相比ELMo，将LSTM替换成了transformer，首次将Transformer应用与预训练模型。</p>
</li>
<li><p>finetune阶段引入语言模型辅助目标，解决finetune过程中的灾难性遗忘问题。</p>
</li>
</ul>
</li>
<li><p>GPT2.0要点</p>
<ul>
<li>不针对特定模型的精调过程：GPT2.0认为预训练中已经包含了许多特定任务所需的信息。</li>
<li>生成式任务效果比较好，使用了覆盖更广、质量更好的数据。</li>
</ul>
</li>
<li><p>缺点</p>
<ul>
<li>依然为单向的自回归语言模型，没有编码上下文的特征表示。</li>
</ul>
</li>
</ul>
<h5 id="4-BERT（重点介绍）"><a href="#4-BERT（重点介绍）" class="headerlink" title="4. BERT（重点介绍）"></a>4. BERT（重点介绍）</h5><ul>
<li><p>Transformer</p>
<p><img src="https://gitee.com/fushengwuyu1993/images/raw/master/imgs/1583486843525.png" alt="1583486843525"></p>
<p>$ Attention(Q,K,V) = softmax(\frac{QK^{T}}{\sqrt{d_{k}}})V$</p>
<ol>
<li><p>Multi-Head Attention和Scaled Dot-Product Attention</p>
<p>本质上是self attention通过attention mask动态编码变长序列，解决长依赖、无位置偏差、可并行计算。</p>
<ul>
<li><p>为什么是缩放点积，而不是点积模型？</p>
<p>当输入信息的维度较高时，点积模型的值通常有较大方差，从而导致softmax函数的梯度较小，因此缩放点积模型可以较好的解决这一问题。</p>
</li>
<li><p>为什么是双线性点积模型（经过线性变换$Q \ne K$）?</p>
<p>双线性点积模型，引入非对称性，根据健壮性（Attention mask对角线元素不一定是最大的，也就是说当前位置对自身的注意力得分不一定最高）。</p>
</li>
<li><p>相较与加性模型，点积模型具备哪些优势？</p>
<p>常用的attention机制有加性模型和点积模型，理论上两者的复杂度差不多，但是点积模型在实现上可以更好的利用矩阵乘积，从而效率更高。</p>
</li>
<li><p>多头机制为什么有效？</p>
<ul>
<li>类似于CNN中的通过多通道机制进行特征选择</li>
<li>Transformer中先通过切头（split），再分别进行Scale-Product Attention，可以使进行点积计算的维度d不会太大，同时缩小attention mask矩阵。</li>
</ul>
</li>
</ul>
</li>
<li><p>Position-wise Feed-Forward Networks</p>
<ul>
<li>FFN将每个位置的Multi-Head Attention结果隐射到一个更大的特征空间，然后使用ReLU引入非线性进行筛选，最后恢复原始维度。</li>
<li>Transformer放弃LSTM之后，FFN中的ReLU成为了一个主要的提供非线性变换的单元。</li>
</ul>
</li>
<li><p>Positional Encoding</p>
<p>Position Encoding是可学习的，编码范围不受限制。</p>
<p>$$PE_{(pos,2i)}=sin(pos/10000^{2i/d_{model}})$$</p>
<p>$$PE_{(pos,2i+1)}=cos(pos/10000^{2i/d_{model}})$$</p>
<ul>
<li>为什么引入$sin$和$cos$建模Position Encoding？<ol>
<li>为了使得模型实现相对位置的学习，两个位置pos和pos+k的位置编码是固定间距k的线性变化。</li>
<li>可以证明，间隔为k的任意两个位置编码的欧式距离是恒等的，只与k有关。</li>
</ol>
</li>
</ul>
</li>
</ol>
</li>
<li><p>BERT为什么如此有效？</p>
<ol>
<li>引入Masked Language Model（MLM）预训练目标，能够获取上下文相关的双向特征表示</li>
<li>引入Next Sentence Prediction（NSP）预训练目标，擅长处理句子或段落的匹配任务。</li>
<li>引入强大的特征抽取机制。<ul>
<li>Muti-Head self attention：多头机制类似于多通道特征抽取</li>
<li>self attention通过attention mask动态编码变长序列，解决长距离依赖、可并行计算</li>
<li>Feed-forward ：非线性层级特征</li>
<li>Layer Norm &amp; Residuals：加速训练，使深度网络更加健壮。</li>
</ul>
</li>
</ol>
<ul>
<li>BERT 通过不同的迁移学习应用与下游任务，BERT擅长处理NLU任务。</li>
<li>BERT通过MLM解决了深层BiLSTM构建双向模型中存在的‘标签泄露’问题，也就是‘see itself’。</li>
</ul>
</li>
<li><p>BERT的优缺点？</p>
<ul>
<li>优点：能够获取上下文相关的双向特征表示</li>
<li>缺点：<ul>
<li>生成任务表现不佳</li>
<li>采取独立性假设：没有考虑预测[MASK]之间的相关性，是对语言模型联合概率的有偏估计（不是密度估计）。</li>
<li>输入噪声[MASJ]，造成预训练-finetune两阶段之间的差异。</li>
<li>无法处理文档级别的NLP任务，只适合句子和段落级别的任务。</li>
</ul>
</li>
</ul>
</li>
<li><p>BERT基于‘字输入’还是‘词输入’好?(中文)</p>
<ol>
<li>如果基于’词输入‘，可能会出现’OOV‘问题，增大标签空间，需要利用更多预料去学习标签分布来拟合模型</li>
<li>随着Transformer特征抽取能力加强，分词不再成为必要，词级别的特征学习可以纳入内部特征进行表示学习。</li>
</ol>
</li>
</ul>
<h5 id="5-BERT改进系列模型"><a href="#5-BERT改进系列模型" class="headerlink" title="5. BERT改进系列模型"></a>5. BERT改进系列模型</h5><h6 id="5-1-改进生成任务"><a href="#5-1-改进生成任务" class="headerlink" title="5.1 改进生成任务"></a>5.1 改进生成任务</h6><ol>
<li><p>MASS</p>
<p><img src="https://gitee.com/fushengwuyu1993/images/raw/master/imgs/1583723052606.png" alt="1583723052606"></p>
<ul>
<li><p>统一预训练框架：通过类似于Seq2Seq的框架，在预训练阶段统一了BERT和LM模型</p>
</li>
<li><p>Encoder中理解unmasked tokens；Decoder中需要预测连续的[mask]tokens，获取更多的语言信息；Decoder从Encoder中抽取更多信息</p>
</li>
<li><p>当k=1或者n时，MASS的概率形式分别和BERT中的MLM以及GPT中标准的LM一致（k为mask的连续片段长度）</p>
</li>
</ul>
</li>
<li><p>UNILM</p>
<ul>
<li>统一预训练模型框架：直接从mask矩阵角度统一BERT和LM</li>
<li>3个Attention Mask矩阵：LM、MLM、Seq2Seq LM</li>
<li>UNILM中的LM并不是传统的LM模型，任需通过引入[MASK]实现。</li>
</ul>
</li>
</ol>
<h6 id="5-2-引入知识"><a href="#5-2-引入知识" class="headerlink" title="5.2 引入知识"></a>5.2 引入知识</h6><ol>
<li><p>ERNIE1.0(百度)</p>
<p>在预训练阶段引入知识（预先识别出的实体），引入三种[MASK]策略</p>
<ul>
<li>Basci-Level Masking：和BERT一样，对subword进行mask，无法获取高层次的语义。</li>
<li>Phrase-Level Masking：mask连续短语。</li>
<li>Entity-Level Masking：mask实体。</li>
</ul>
</li>
<li><p>ERNIE（THU）</p>
<p><img src="https://gitee.com/fushengwuyu1993/images/raw/master/imgs/1583731675001.png" alt="1583731675001"></p>
<ul>
<li>基于BERT预训练原生模型，讲文本中的实体对齐到外部的知识图谱，并通过知识嵌入得到实体向量作为ERNIR的输入。</li>
<li>由于语言表征的预训练过程和知识表征过程有很大的不同，会产生两个独立的向量空间，为解决这个问题，在有实体输入的位置，将实体向量和文本表示通过非线性变换进行融合，以融合词汇、句法和知识信息。</li>
<li>引入改进的预训练目标Denoising entity auto-encoder(DEA)：要求模型能够根据给定的实体序列和文本序列来预测对应的实体。</li>
</ul>
</li>
</ol>
<h6 id="5-3-引入多任务机制"><a href="#5-3-引入多任务机制" class="headerlink" title="5.3 引入多任务机制"></a>5.3 引入多任务机制</h6><p>​    多任务学习是指同时学习多个相关任务，让这些任务在学习过程中共享知识，利用多个任务之间的相关性来改善模型在每个任务的性能和泛华能力。</p>
<ol>
<li><p>MTDNN（微软）：在下游任务中引入多任务学习机制</p>
<p><img src="https://gitee.com/fushengwuyu1993/images/raw/master/imgs/1583732461374.png" alt="1583732461374"></p>
</li>
<li><p>ERNIE 2.0（百度）</p>
<p><img src="https://gitee.com/fushengwuyu1993/images/raw/master/imgs/1583735200104.png" alt="1583735200104"></p>
<ul>
<li>MTDNN是在下游任务引入多任务机制的，而ERNIE2.0是在预训练引入多任务学习（与先验知识库进行交互），使模型能够从不同的任务中学到更多的语言知识。</li>
<li>构建多个层次的任务全面捕捉训练预料中的词法、结构、语义的潜在知识。主要包含3个方面的任务：<ul>
<li>词法层面，word-aware任务：捕捉词汇层面的信息，如英文大小写预测。</li>
<li>结构层面，structure-aware任务：捕捉句法层次的信息，如句子顺序问题、句子距离问题。</li>
<li>语义层面，semantic-aware任务：捕捉语义方面的问题，如语义逻辑关系预测（因果，假设，递进，转折）。</li>
</ul>
</li>
<li>主要的方式是构建增量学习模型，通过多任务学习持续更新预训练模型，这种连续交替的学习范式不会使模型忘记之前学到的语言知识。</li>
</ul>
</li>
</ol>
<h6 id="5-4-改进mask策略"><a href="#5-4-改进mask策略" class="headerlink" title="5.4 改进mask策略"></a>5.4 改进mask策略</h6><p>​    原生BERT模型：按照subword维度进行mask，然后预测，局部的语言模型，缺乏全局建模的能力。</p>
<ul>
<li>BERT WWM(google)：进行whole word维度进行mask。</li>
<li>ERNIE系列：建模词、短语、实体的完整语义：通过先验知识将知识（短语、词、实体）进行整体mask；引入外部知识，按照entity维度进行mask，然后进行预测。</li>
<li>Span Bert：不需要按照先验的词、实体、短语等边界信息进行mask，而是采取随机mask<ul>
<li><strong>采用Span Masking</strong>：根据几何分布，随机选择一段空间长度，之后再根据均匀分布随机选择起始位置，最后按照长度mask，通过采样，平均被遮盖长度是3.8个词的长度。</li>
<li><strong>引入Span Boundary Objective</strong>：新的预训练目标旨在使被mask的Span 边界的词向量能学习到 Span中被mask的部分；新的预训练目标和MLM一起使用；</li>
</ul>
</li>
</ul>
<h6 id="5-5-精调"><a href="#5-5-精调" class="headerlink" title="5.5 精调"></a>5.5 精调</h6><ol>
<li>RoBERTa(FaceBook)<ul>
<li>丢弃NSP，效果更好</li>
<li>动态改变mask策略，把数据复制10份，然后统一进行随机mask</li>
<li>对学习率的峰值和warm-up跟新步数做出调整</li>
<li>在更长序列上训练，不对序列进行截断，使用全长度序列</li>
</ul>
</li>
</ol>
<h5 id="6-XLNet"><a href="#6-XLNet" class="headerlink" title="6. XLNet"></a>6. XLNet</h5><h6 id="6-1-提出的背景"><a href="#6-1-提出的背景" class="headerlink" title="6.1 提出的背景"></a>6.1 提出的背景</h6><ul>
<li>对于ELMO、GPT等预训练模型都是基于传统的语言模型（自回归语言模型AR），自回归语言模型天然适合处理生成任务，但是无法对双向上下文进行表征。</li>
<li>自编码语言模型（AE）虽然可以实现双向上下文表征，但是：<ul>
<li>BERT系列模型引入独立性假设，没有考虑预测[mask]之间的相关性。</li>
<li>MLM预训练目标的设置造成预训练过程和生成过程不一致。</li>
<li>预训练时的[mask]噪声在finetune阶段不会出现，造成两阶段不匹配问题。</li>
</ul>
</li>
</ul>
<h6 id="6-2-核心机制分析"><a href="#6-2-核心机制分析" class="headerlink" title="6.2 核心机制分析"></a>6.2 核心机制分析</h6><ul>
<li>使用自回归语言模型，为解决双向上下文问题，引入了排列语言模型PLM</li>
<li>PLM在预测时需要target的位置信息，此为引入了Two-Stream：Content流编码到当前时刻的所有内容，而Query流只能参考之前的历史信息以及当前要预测的位置信息。</li>
<li>为解决计算量过大的问题，采取随机采样语言排列+只预测1个句子后面的1/k的词。</li>
<li>融合Transformer-XL的优点处理长文本。</li>
</ul>
<ol>
<li><p>排列语言模型（Permutation LM，PLM）</p>
</li>
<li><p>Two-Stream Self-Attention</p>
</li>
<li><p>融入Transformer-XL</p>
</li>
</ol>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2021/07/20/tensorflow%20serving/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="sunshine">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="浮生物语的博客">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2021/07/20/tensorflow%20serving/" class="post-title-link" itemprop="url">tensorflow serving 总结文档</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>
              

              <time title="创建时间：2021-07-20 00:00:00 / 修改时间：10:19:49" itemprop="dateCreated datePublished" datetime="2021-07-20T00:00:00+08:00">2021-07-20</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h5 id="1-准备模型"><a href="#1-准备模型" class="headerlink" title="1. 准备模型"></a>1. 准备模型</h5><p>使用tf.keras训练一个简单的线性回归模型，保存为protobuf文件。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras <span class="keyword">import</span> models,layers,optimizers</span><br><span class="line"></span><br><span class="line"><span class="comment">## 样本数量</span></span><br><span class="line">n = <span class="number">800</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## 生成测试用数据集</span></span><br><span class="line">X = tf.random.uniform([n,<span class="number">2</span>],minval=-<span class="number">10</span>,maxval=<span class="number">10</span>) </span><br><span class="line">w0 = tf.constant([[<span class="number">2.0</span>],[-<span class="number">1.0</span>]])</span><br><span class="line">b0 = tf.constant(<span class="number">3.0</span>)</span><br><span class="line"></span><br><span class="line">Y = X@w0 + b0 + tf.random.normal([n,<span class="number">1</span>],</span><br><span class="line">    mean = <span class="number">0.0</span>,stddev= <span class="number">2.0</span>) <span class="comment"># @表示矩阵乘法,增加正态扰动</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## 建立模型</span></span><br><span class="line">tf.keras.backend.clear_session()</span><br><span class="line">inputs = layers.Input(shape = (<span class="number">2</span>,),name =<span class="string">&quot;inputs&quot;</span>) <span class="comment">#设置输入名字为inputs</span></span><br><span class="line">outputs = layers.Dense(<span class="number">1</span>, name = <span class="string">&quot;outputs&quot;</span>)(inputs) <span class="comment">#设置输出名字为outputs</span></span><br><span class="line">linear = models.Model(inputs = inputs,outputs = outputs)</span><br><span class="line">linear.summary()</span><br><span class="line"></span><br><span class="line"><span class="comment">## 使用fit方法进行训练</span></span><br><span class="line">linear.<span class="built_in">compile</span>(optimizer=<span class="string">&quot;rmsprop&quot;</span>,loss=<span class="string">&quot;mse&quot;</span>,metrics=[<span class="string">&quot;mae&quot;</span>])</span><br><span class="line">linear.fit(X,Y,batch_size = <span class="number">8</span>,epochs = <span class="number">100</span>)  </span><br><span class="line"></span><br><span class="line">tf.<span class="built_in">print</span>(<span class="string">&quot;w = &quot;</span>,linear.layers[<span class="number">1</span>].kernel)</span><br><span class="line">tf.<span class="built_in">print</span>(<span class="string">&quot;b = &quot;</span>,linear.layers[<span class="number">1</span>].bias)</span><br><span class="line"></span><br><span class="line"><span class="comment">## 将模型保存成pb格式文件</span></span><br><span class="line">export_path = <span class="string">&quot;linear_model/&quot;</span></span><br><span class="line">version = <span class="string">&quot;1&quot;</span>       <span class="comment">#后续可以通过版本号进行模型版本迭代与管理</span></span><br><span class="line">linear.save(export_path+version, save_format=<span class="string">&quot;tf&quot;</span>) </span><br></pre></td></tr></table></figure>

<p>查看模型</p>
<blockquote>
<p>saved_model_cli show –dir=’linear_model/1’ –all</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br></pre></td><td class="code"><pre><span class="line">MetaGraphDef <span class="keyword">with</span> tag-<span class="built_in">set</span>: <span class="string">&#x27;serve&#x27;</span> contains the following SignatureDefs:</span><br><span class="line"></span><br><span class="line">signature_def[<span class="string">&#x27;__saved_model_init_op&#x27;</span>]:</span><br><span class="line">  The given SavedModel SignatureDef contains the following <span class="built_in">input</span>(s):</span><br><span class="line">  The given SavedModel SignatureDef contains the following output(s):</span><br><span class="line">    outputs[<span class="string">&#x27;__saved_model_init_op&#x27;</span>] tensor_info:</span><br><span class="line">        dtype: DT_INVALID</span><br><span class="line">        shape: unknown_rank</span><br><span class="line">        name: NoOp</span><br><span class="line">  Method name <span class="keyword">is</span>: </span><br><span class="line"></span><br><span class="line">signature_def[<span class="string">&#x27;serving_default&#x27;</span>]:   <span class="comment"># 注意signature_def</span></span><br><span class="line">  The given SavedModel SignatureDef contains the following <span class="built_in">input</span>(s):</span><br><span class="line">    inputs[<span class="string">&#x27;inputs&#x27;</span>] tensor_info:   <span class="comment"># 注意inputs</span></span><br><span class="line">        dtype: DT_FLOAT</span><br><span class="line">        shape: (-<span class="number">1</span>, <span class="number">2</span>)</span><br><span class="line">        name: serving_default_inputs:<span class="number">0</span></span><br><span class="line">  The given SavedModel SignatureDef contains the following output(s):</span><br><span class="line">    outputs[<span class="string">&#x27;outputs&#x27;</span>] tensor_info:</span><br><span class="line">        dtype: DT_FLOAT</span><br><span class="line">        shape: (-<span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">        name: StatefulPartitionedCall:<span class="number">0</span></span><br><span class="line">  Method name <span class="keyword">is</span>: tensorflow/serving/predict</span><br><span class="line">WARNING:tensorflow:From /usr/local/lib/python3<span class="number">.6</span>/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:<span class="number">1786</span>: calling BaseResourceVariable.__init__ (<span class="keyword">from</span> tensorflow.python.ops.resource_variable_ops) <span class="keyword">with</span> constraint <span class="keyword">is</span> deprecated <span class="keyword">and</span> will be removed <span class="keyword">in</span> a future version.</span><br><span class="line">Instructions <span class="keyword">for</span> updating:</span><br><span class="line">If using Keras <span class="keyword">pass</span> *_constraint arguments to layers.</span><br><span class="line"></span><br><span class="line">Defined Functions:</span><br><span class="line">  Function Name: <span class="string">&#x27;__call__&#x27;</span></span><br><span class="line">    Option <span class="comment">#1</span></span><br><span class="line">      <span class="type">Callable</span> <span class="keyword">with</span>:</span><br><span class="line">        Argument <span class="comment">#1</span></span><br><span class="line">          inputs: TensorSpec(shape=(<span class="literal">None</span>, <span class="number">2</span>), dtype=tf.float32, name=<span class="string">&#x27;inputs&#x27;</span>)</span><br><span class="line">        Argument <span class="comment">#2</span></span><br><span class="line">          DType: <span class="built_in">bool</span></span><br><span class="line">          Value: <span class="literal">True</span></span><br><span class="line">        Argument <span class="comment">#3</span></span><br><span class="line">          DType: NoneType</span><br><span class="line">          Value: <span class="literal">None</span></span><br><span class="line">    Option <span class="comment">#2</span></span><br><span class="line">      <span class="type">Callable</span> <span class="keyword">with</span>:</span><br><span class="line">        Argument <span class="comment">#1</span></span><br><span class="line">          inputs: TensorSpec(shape=(<span class="literal">None</span>, <span class="number">2</span>), dtype=tf.float32, name=<span class="string">&#x27;inputs&#x27;</span>)</span><br><span class="line">        Argument <span class="comment">#2</span></span><br><span class="line">          DType: <span class="built_in">bool</span></span><br><span class="line">          Value: <span class="literal">False</span></span><br><span class="line">        Argument <span class="comment">#3</span></span><br><span class="line">          DType: NoneType</span><br><span class="line">          Value: <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">  Function Name: <span class="string">&#x27;_default_save_signature&#x27;</span></span><br><span class="line">    Option <span class="comment">#1</span></span><br><span class="line">      <span class="type">Callable</span> <span class="keyword">with</span>:</span><br><span class="line">        Argument <span class="comment">#1</span></span><br><span class="line">          inputs: TensorSpec(shape=(<span class="literal">None</span>, <span class="number">2</span>), dtype=tf.float32, name=<span class="string">&#x27;inputs&#x27;</span>)</span><br><span class="line"></span><br><span class="line">  Function Name: <span class="string">&#x27;call_and_return_all_conditional_losses&#x27;</span></span><br><span class="line">    Option <span class="comment">#1</span></span><br><span class="line">      <span class="type">Callable</span> <span class="keyword">with</span>:</span><br><span class="line">        Argument <span class="comment">#1</span></span><br><span class="line">          inputs: TensorSpec(shape=(<span class="literal">None</span>, <span class="number">2</span>), dtype=tf.float32, name=<span class="string">&#x27;inputs&#x27;</span>)</span><br><span class="line">        Argument <span class="comment">#2</span></span><br><span class="line">          DType: <span class="built_in">bool</span></span><br><span class="line">          Value: <span class="literal">False</span></span><br><span class="line">        Argument <span class="comment">#3</span></span><br><span class="line">          DType: NoneType</span><br><span class="line">          Value: <span class="literal">None</span></span><br><span class="line">    Option <span class="comment">#2</span></span><br><span class="line">      <span class="type">Callable</span> <span class="keyword">with</span>:</span><br><span class="line">        Argument <span class="comment">#1</span></span><br><span class="line">          inputs: TensorSpec(shape=(<span class="literal">None</span>, <span class="number">2</span>), dtype=tf.float32, name=<span class="string">&#x27;inputs&#x27;</span>)</span><br><span class="line">        Argument <span class="comment">#2</span></span><br><span class="line">          DType: <span class="built_in">bool</span></span><br><span class="line">          Value: <span class="literal">True</span></span><br><span class="line">        Argument <span class="comment">#3</span></span><br><span class="line">          DType: NoneType</span><br><span class="line">          Value: <span class="literal">None</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>注意：请牢记上面的signature_def值和inputs值及其shape，在grpc调用的时候需要用到。</p>
<h5 id="2-tensorflow-serving-docker方式安装"><a href="#2-tensorflow-serving-docker方式安装" class="headerlink" title="2. tensorflow/serving docker方式安装"></a>2. tensorflow/serving docker方式安装</h5><ol>
<li><p>拉取镜像</p>
<blockquote>
<p> docker pull tensorflow/serving:latest</p>
</blockquote>
<p>在docker hub中有四中镜像。</p>
<ul>
<li>:latest</li>
<li>:lasest-gpu</li>
<li>:lasest-devel</li>
<li>:lasest-devel-gpu</li>
</ul>
<p>两种划分共有4种镜像。CPU、GPU、稳定版、开发版。稳定版在dockerfile中启动tensorflow_model_server服务，创建容器即启动服务。开发版需要在创建容器之后，进入容器，手动启动tensorflow_model_server服务。</p>
<p>以下都已稳定版为例。</p>
</li>
<li><p>启动容器</p>
<blockquote>
<p>docker run -t -p 8501:8501 -p 8500:8500 -v /root/mutimodel/linear_model:/models/linear_model -e MODEL_NAME=linear_model tensorflow/serving</p>
</blockquote>
<p> ==备注：路径只需到模型这一级，不能精确到版本级别，比如：/root/mutimodel/linear_model而不是/root/mutimodel/linear_model/1，服务会默认加载最大版本号的模型。==</p>
<p> 参数解释：</p>
<ul>
<li><p>-p : 端口映射，tensorflow serving提供了两种调用方式：gRPC和REST，<br>gRPC的默认端口是8500，REST的默认端口是8501.</p>
</li>
<li><p>-v：目录映射，需要注意的是，在新版的docker中，已经移除了–mount type=bind,source=%source_path,target=$target_path的挂载目录方式。</p>
</li>
<li><p>-e：设置变量。</p>
<ul>
<li>可选参数: MODLE_NAME（默认值：model）</li>
<li>可选参数：MODEL_BASE_PATH（默认值/models）</li>
</ul>
<p>启动容器之后，相当于在容器中启动服务：</p>
<blockquote>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tensorflow_model_server --port=8500 --rest_api_port=8501 --model_name=$&#123;MODEL_NAME&#125; --model_base_path=$&#123;MODEL_BASE_PATH&#125;/$&#123;MODEL_NAME&#125;</span><br></pre></td></tr></table></figure></blockquote>
</li>
</ul>
<p> 如果需要修改相关参数配置，可以通过如下命令：</p>
<blockquote>
<p>docker run -p 8501:8501 -v /root/mutimodel/linear_model:/models/linear_model -t –entrypoint=tensorflow_model_server tensorflow/serving  –port=8500 –model_name=linear_model –model_base_path=/models/linear_model –rest_api_port=8501</p>
</blockquote>
<p> 参数解释：</p>
<ul>
<li>-t –entrypoint=tensorflow_model_server tensorflow/serving：如果使用稳定版的docker，启动docker之后是不能进入容器内部bash环境的，–entrypoint的作用是允许你“间接”进入容器内部，然后调用tensorflow_model_server命令来启动TensorFlow Serving，这样才能输入后面的参数。</li>
</ul>
<p> tensorflow serving的详细参数如下：</p>
 <figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">Flags:</span><br><span class="line">    --port=8500                         int32   Port to listen on for gRPC API</span><br><span class="line">    --grpc_socket_path=&quot;&quot;               string  If non-empty, listen to a UNIX socket for gRPC API on the given path. Can be either relative or absolute path.</span><br><span class="line">    --rest_api_port=0                   int32   Port to listen on for HTTP/REST API. If set to zero HTTP/REST API will not be exported. This port must be different than the one specified in --port.</span><br><span class="line">    --rest_api_num_threads=16           int32   Number of threads for HTTP/REST API processing. If not set, will be auto set based on number of CPUs.</span><br><span class="line">    --rest_api_timeout_in_ms=30000      int32   Timeout for HTTP/REST API calls.</span><br><span class="line">    --enable_batching=false             bool    enable batching</span><br><span class="line">    --batching_parameters_file=&quot;&quot;       string  If non-empty, read an ascii BatchingParameters protobuf from the supplied file name and use the contained values instead of the defaults.</span><br><span class="line">    --model_config_file=&quot;&quot;              string  If non-empty, read an ascii ModelServerConfig protobuf from the supplied file name, and serve the models in that file. This config file can be used to specify multiple models to serve and other advanced parameters including non-default version policy. (If used, --model_name, --model_base_path are ignored.)</span><br><span class="line">    --model_name=&quot;default&quot;              string  name of model (ignored if --model_config_file flag is set)</span><br><span class="line">    --model_base_path=&quot;&quot;                string  path to export (ignored if --model_config_file flag is set, otherwise required)</span><br><span class="line">    --max_num_load_retries=5            int32   maximum number of times it retries loading a model after the first failure, before giving up. If set to 0, a load is attempted only once. Default: 5</span><br><span class="line">    --load_retry_interval_micros=60000000   int64   The interval, in microseconds, between each servable load retry. If set negative, it doesn&#x27;t wait. Default: 1 minute</span><br><span class="line">    --file_system_poll_wait_seconds=1   int32   Interval in seconds between each poll of the filesystem for new model version. If set to zero poll will be exactly done once and not periodically. Setting this to negative value will disable polling entirely causing ModelServer to indefinitely wait for a new model at startup. Negative values are reserved for testing purposes only.</span><br><span class="line">    --flush_filesystem_caches=true      bool    If true (the default), filesystem caches will be flushed after the initial load of all servables, and after each subsequent individual servable reload (if the number of load threads is 1). This reduces memory consumption of the model server, at the potential cost of cache misses if model files are accessed after servables are loaded.</span><br><span class="line">    --tensorflow_session_parallelism=0  int64   Number of threads to use for running a Tensorflow session. Auto-configured by default.Note that this option is ignored if --platform_config_file is non-empty.</span><br><span class="line">    --tensorflow_intra_op_parallelism=0 int64   Number of threads to use to parallelize the executionof an individual op. Auto-configured by default.Note that this option is ignored if --platform_config_file is non-empty.</span><br><span class="line">    --tensorflow_inter_op_parallelism=0 int64   Controls the number of operators that can be executed simultaneously. Auto-configured by default.Note that this option is ignored if --platform_config_file is non-empty.</span><br><span class="line">    --ssl_config_file=&quot;&quot;                string  If non-empty, read an ascii SSLConfig protobuf from the supplied file name and set up a secure gRPC channel</span><br><span class="line">    --platform_config_file=&quot;&quot;           string  If non-empty, read an ascii PlatformConfigMap protobuf from the supplied file name, and use that platform config instead of the Tensorflow platform. (If used, --enable_batching is ignored.)</span><br><span class="line">    --per_process_gpu_memory_fraction=0.000000  float   Fraction that each process occupies of the GPU memory space the value is between 0.0 and 1.0 (with 0.0 as the default) If 1.0, the server will allocate all the memory when the server starts, If 0.0, Tensorflow will automatically select a value.</span><br><span class="line">    --saved_model_tags=&quot;serve&quot;          string  Comma-separated set of tags corresponding to the meta graph def to load from SavedModel.</span><br><span class="line">    --grpc_channel_arguments=&quot;&quot;         string  A comma separated list of arguments to be passed to the grpc server. (e.g. grpc.max_connection_age_ms=2000)</span><br><span class="line">    --enable_model_warmup=true          bool    Enables model warmup, which triggers lazy initializations (such as TF optimizations) at load time, to reduce first request latency.</span><br><span class="line">    --version=false                     bool    Display version</span><br></pre></td></tr></table></figure>

<p> 容器启动成功。</p>
<blockquote>
<p>…<br>tensorflow_serving/servables/tensorflow/saved_model_warmup.cc:105] No warmup data file found at /models/linear_model/1/assets.extra/tf_serving_warmup_requests<br>2020-03-19 01:25:24.979107: I tensorflow_serving/core/loader_harness.cc:87] Successfully loaded servable version {name: linear_model version: 1}<br>2020-03-19 01:25:24.982357: I tensorflow_serving/model_servers/server.cc:358] Running gRPC ModelServer at 0.0.0.0:8500 …<br>2020-03-19 01:25:24.982960: I tensorflow_serving/model_servers/server.cc:378] Exporting HTTP/REST API at:localhost:8501 …<br>[evhttp_server.cc : 238] NET_LOG: Entering the event loop …</p>
</blockquote>
<p> 可以看到，启动了grpc的8500端口和RESR的8501端口。</p>
</li>
</ol>
<h5 id="2-REST调用"><a href="#2-REST调用" class="headerlink" title="2. REST调用"></a>2. REST调用</h5><ul>
<li></li>
</ul>
<p>​    REST api方式调用很简单，可以通过curl或者postman发送一个post请求，也可以用python的requests模拟一个post请求。这里我们使用postman工具。</p>
<p><img src="/home/sunshine/Documents/%E5%8D%9A%E5%AE%A2/assets/1584583823994.png" alt="1584583823994"></p>
<p>​    可以看到正确返回结果。</p>
<p>​    注意事项：</p>
<ul>
<li>请求参数：“inputs”，这里对应于模型中的signature_def下面的inputs值。</li>
<li>参数形状：参见tensor_info的shape：（-1, 2）。</li>
<li>参数类型：参见tensor_info的dtype：DT_FLOAT（对应于np.float32）</li>
</ul>
<h5 id="3-grpc调用"><a href="#3-grpc调用" class="headerlink" title="3. grpc调用"></a>3. grpc调用</h5><ol>
<li><p>安装相应的包</p>
<blockquote>
<p> pip install tensorflow-serving-api</p>
</blockquote>
</li>
<li><p>编写代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> grpc</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> tensorflow_serving.apis <span class="keyword">import</span> predict_pb2</span><br><span class="line"><span class="keyword">from</span> tensorflow_serving.apis <span class="keyword">import</span> prediction_service_pb2_grpc</span><br><span class="line"></span><br><span class="line">options = [(<span class="string">&#x27;grpc.max_send_message_length&#x27;</span>, <span class="number">1000</span> * <span class="number">1024</span> * <span class="number">1024</span>),</span><br><span class="line">           (<span class="string">&#x27;grpc.max_receive_message_length&#x27;</span>, <span class="number">1000</span> * <span class="number">1024</span> * <span class="number">1024</span>)]</span><br><span class="line"></span><br><span class="line">channel = grpc.insecure_channel(<span class="string">&#x27;ip:8500&#x27;</span>, options=options)</span><br><span class="line">stub = prediction_service_pb2_grpc.PredictionServiceStub(channel)</span><br><span class="line"></span><br><span class="line">x = [[<span class="number">1.0</span>, <span class="number">2.0</span>]]</span><br><span class="line"></span><br><span class="line">request = predict_pb2.PredictRequest()</span><br><span class="line">request.model_spec.name = <span class="string">&quot;linear_model&quot;</span></span><br><span class="line">request.model_spec.signature_name = <span class="string">&#x27;serving_default&#x27;</span></span><br><span class="line">request.inputs[<span class="string">&#x27;inputs&#x27;</span>].CopyFrom(tf.make_tensor_proto(x, shape=(<span class="number">1</span>, <span class="number">2</span>)))</span><br><span class="line">response = stub.Predict(request, <span class="number">10.0</span>)</span><br><span class="line">output = tf.make_ndarray(response.outputs[<span class="string">&quot;outputs&quot;</span>])[<span class="number">0</span>][<span class="number">0</span>]</span><br><span class="line"><span class="built_in">print</span>(output)</span><br></pre></td></tr></table></figure>

<p>注意事项：</p>
<ul>
<li>request.model_spec.name：模型名</li>
<li>request.model_spec.signature_name：必须与模型中定义的一致，参照signature_def值（参见第一节查看模型）</li>
<li>request.inputs[‘inputs’]：inputs的key参见tensor_info的inputs值（第一节查看模型）</li>
</ul>
</li>
</ol>
<h5 id="4-多模型部署"><a href="#4-多模型部署" class="headerlink" title="4. 多模型部署"></a>4. 多模型部署</h5><p>​    单一模型部署，上面的方式即可完成。对于多个模型统一部署，基本流程与单模型一致，不同之处在于需要借助模型的配置文件来完成。</p>
<ol>
<li>model.config</li>
</ol>
<p>新建mutimodel文件夹，放置多个模型，并建一配置文件model.config.</p>
<blockquote>
<p>mutimodel</p>
<p>├── linear_model<br>│   └── 1<br>│       ├── assets<br>│       ├── saved_model.pb<br>│       └── variables<br>│           ├── variables.data-00000-of-00001<br>│           └── variables.index<br>├── model.config<br>├── router_model<br>│   └── 1<br>│       ├── assets<br>│       ├── saved_model.pb<br>│       └── variables<br>│           ├── variables.data-00000-of-00001<br>│           └── variables.index<br>└── textcnn_model<br>    └── 1<br>        ├── assets<br>        ├── saved_model.pb<br>        └── variables<br>            ├── variables.data-00000-of-00001<br>            └── variables.index</p>
<p>12 directories, 10 files</p>
</blockquote>
<p>​    model.conf配置如下：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">model_config_list &#123;</span><br><span class="line">  config &#123;</span><br><span class="line">    name: &#x27;linear&#x27;,</span><br><span class="line">    model_platform: &quot;tensorflow&quot;,</span><br><span class="line">    base_path: &#x27;/models/mutimodel/linear_model&#x27;</span><br><span class="line">  &#125;,</span><br><span class="line">  config &#123;</span><br><span class="line">    name: &#x27;textcnn&#x27;,</span><br><span class="line">    model_platform: &quot;tensorflow&quot;,</span><br><span class="line">    base_path: &#x27;/models/mutimodel/textcnn_model&#x27;</span><br><span class="line">  &#125;,</span><br><span class="line">  config &#123;</span><br><span class="line">    name: &#x27;router&#x27;,</span><br><span class="line">    model_platform: &quot;tensorflow&quot;,</span><br><span class="line">    base_path: &#x27;/models/mutimodel/router_model&#x27;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<ol start="2">
<li>启动容器</li>
</ol>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker run -p 8501:8501 -p 8500:8500 -v /root/mutimodel/:/models/mutimodel  -t tensorflow/serving --model_config_file=/models/mutimodel/model.config</span><br></pre></td></tr></table></figure>

<blockquote>
<p>…<br>2020-03-19 0/models/mutimodel/router_model/1/assets.extra/tf_serving_warmup_requests<br>2020-03-19 02:42:58.197083: I tensorflow_serving/core/loader_harness.cc:87] Successfully loaded servable version {name: router version: 1}<br>2020-03-19 02:42:58.199987: I tensorflow_serving/model_servers/server.cc:358] Running gRPC ModelServer at 0.0.0.0:8500 …<br>2020-03-19 02:42:58.200632: I tensorflow_serving/model_servers/server.cc:378] Exporting HTTP/REST API at:localhost:8501 …<br>[evhttp_server.cc : 238] NET_LOG: Entering the event loop …</p>
</blockquote>
<p>REST api 测试。</p>
<p><img src="/home/sunshine/Documents/%E5%8D%9A%E5%AE%A2/assets/1584585981550.png" alt="1584585981550"></p>
<p>正常访问。</p>
<h5 id="5-版本控制"><a href="#5-版本控制" class="headerlink" title="5. 版本控制"></a>5. 版本控制</h5><ol>
<li><p>服务端配置</p>
<p>tensorflow serving服务默认只会读取最大版本号的版本（按数字来标记版本号），实际上，我们可以通过提供不同的版本的模型，比如提供稳定版、测试版，来实现版本控制，只需要在在配置文件中配置model_version_policy。</p>
<figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">model_config_list &#123;</span><br><span class="line">  config &#123;</span><br><span class="line">    name: &#x27;linear&#x27;,</span><br><span class="line">    model_platform: &quot;tensorflow&quot;,</span><br><span class="line">    base_path: &#x27;/models/mutimodel/linear_model&#x27;</span><br><span class="line">    model_version_policy&#123;</span><br><span class="line">      specific&#123;</span><br><span class="line">            version: 1,</span><br><span class="line">            version: 2</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    version_labels&#123;</span><br><span class="line">        key: &quot;stable&quot;,</span><br><span class="line">        value: 1    </span><br><span class="line">    &#125;</span><br><span class="line">    version_labels&#123;</span><br><span class="line">        key: &quot;test&quot;,</span><br><span class="line">        value: 2    </span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>这里我们同时提供版本号为1和版本号为2的版本，并分别为其取别名stable和test。这样做的好处在于，用户只需要定向到stable或者test版本，而不必关心具体的某个版本号，同时，在不通知用户的情况下，可以调整版本号，比如版本2稳定后，可以升级为稳定版，只需要将stable对应的value改为2即可。同样，若需要版本回滚，将value修改为之前的1即可。</p>
<p>启动服务</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker run -p 8501:8501 -p 8500:8500 -v /root/mutimodel/:/models/mutimodel  -t tensorflow/serving --model_config_file=/models/mutimodel/model.config --allow_version_labels_for_unavailable_models=true</span><br></pre></td></tr></table></figure>

<p>说明：根据官方说明，添加别名只能针对已经加载的模型（先启动服务，再更新配置文件），若想在启动服务的时候设置别名，需要设置allow_version_labels_for_unavailable_models=true。</p>
<p>官方说明如下：</p>
<blockquote>
<p>Please note that labels can only be assigned to model versions that are <em>already</em> loaded and available for serving. Once a model version is available, one may reload the model config on the fly to assign a label to it. This can be achieved using a<a target="_blank" rel="noopener" href="https://github.com/tensorflow/serving/blob/master/tensorflow_serving/apis/model_service.proto#L22">HandleReloadConfigRequest</a> RPC or if the server is set up to periodically poll the filesystem for the config file, as described <a target="_blank" rel="noopener" href="https://www.tensorflow.org/tfx/serving/serving_config#reloading_model_server_configuration">above</a>.</p>
<p>If you would like to assign a label to a version that is not yet loaded (for ex. by supplying both the model version and the label at startup time) then you must set the <code>--allow_version_labels_for_unavailable_models</code> flag to true, which allows new labels to be assigned to model versions that are not loaded yet.</p>
</blockquote>
</li>
<li><p>客户端调用</p>
<p>特别说明：version_label设置别名的方式只适用于grpc调用方式，而不适用与REST调用。</p>
<ul>
<li><p>REST 调用，直接制定版本号。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">curl -d &#x27;&#123;&quot;inputs&quot;:[[1.0, 2.0]]&#125;&#x27; -X POST http://localhost:8501/v1/models/linear/versions/1:predict</span><br><span class="line">&#123;</span><br><span class="line">    &quot;outputs&quot;: [</span><br><span class="line">        [</span><br><span class="line">            2.18523026</span><br><span class="line">        ]</span><br><span class="line">    ]</span><br></pre></td></tr></table></figure></li>
<li><p>gRPC方式</p>
<p>使用别名：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">channel = grpc.insecure_channel(<span class="string">&#x27;49.233.155.170:8500&#x27;</span>)</span><br><span class="line">stub = prediction_service_pb2_grpc.PredictionServiceStub(channel)</span><br><span class="line">x = [[<span class="number">1.0</span>, <span class="number">2.0</span>]]</span><br><span class="line">request = predict_pb2.PredictRequest()</span><br><span class="line">request.model_spec.name = <span class="string">&quot;linear&quot;</span></span><br><span class="line">request.model_spec.version_label = <span class="string">&quot;stable&quot;</span></span><br><span class="line">request.model_spec.signature_name = <span class="string">&#x27;serving_default&#x27;</span></span><br><span class="line">request.inputs[<span class="string">&#x27;inputs&#x27;</span>].CopyFrom(tf.make_tensor_proto(x, shape=(<span class="number">1</span>, <span class="number">2</span>)))</span><br><span class="line">response = stub.Predict(request, <span class="number">10.0</span>)</span><br><span class="line">output = tf.make_ndarray(response.outputs[<span class="string">&quot;outputs&quot;</span>])[<span class="number">0</span>][<span class="number">0</span>]</span><br><span class="line"><span class="built_in">print</span>(output)</span><br></pre></td></tr></table></figure>

<p>使用版本号：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">channel = grpc.insecure_channel(<span class="string">&#x27;49.233.155.170:8500&#x27;</span>)</span><br><span class="line">stub = prediction_service_pb2_grpc.PredictionServiceStub(channel)</span><br><span class="line">x = [[<span class="number">1.0</span>, <span class="number">2.0</span>]]</span><br><span class="line">request = predict_pb2.PredictRequest()</span><br><span class="line">request.model_spec.name = <span class="string">&quot;linear&quot;</span></span><br><span class="line">request.model_spec.version.value = <span class="number">1</span></span><br><span class="line">request.model_spec.signature_name = <span class="string">&#x27;serving_default&#x27;</span></span><br><span class="line">request.inputs[<span class="string">&#x27;inputs&#x27;</span>].CopyFrom(tf.make_tensor_proto(x, shape=(<span class="number">1</span>, <span class="number">2</span>)))</span><br><span class="line">response = stub.Predict(request, <span class="number">10.0</span>)</span><br><span class="line">output = tf.make_ndarray(response.outputs[<span class="string">&quot;outputs&quot;</span>])[<span class="number">0</span>][<span class="number">0</span>]</span><br><span class="line"><span class="built_in">print</span>(output)</span><br></pre></td></tr></table></figure>

<p>==区别：model_spec.version_label与model_spec.version.value。==</p>
</li>
</ul>
</li>
</ol>
<h5 id="6-热更新"><a href="#6-热更新" class="headerlink" title="6. 热更新"></a>6. 热更新</h5><p>服务启动后，可以通过重新加载配置文件的方式来实现模型的热更新。可以通过一下两种方式来实现。</p>
<ol>
<li><p><a target="_blank" rel="noopener" href="https://github.com/tensorflow/serving/blob/master/tensorflow_serving/apis/model_service.proto#L22">HandleReloadConfigRequest</a> （grpc）</p>
<p>比如我们想新增模型textcnn和router。先更新其配置文件model.config为：</p>
<figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">model_config_list &#123;</span><br><span class="line">  config &#123;</span><br><span class="line">    name: &quot;linear&quot;</span><br><span class="line">    base_path: &quot;/models/mutimodel/linear_model&quot;</span><br><span class="line">    model_platform: &quot;tensorflow&quot;</span><br><span class="line">    model_version_policy &#123;</span><br><span class="line">      specific &#123;</span><br><span class="line">        versions: 1</span><br><span class="line">        versions: 2</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    version_labels &#123;</span><br><span class="line">      key: &quot;stable&quot;</span><br><span class="line">      value: 1</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  config &#123;</span><br><span class="line">    name: &quot;textcnn&quot;</span><br><span class="line">    base_path: &quot;/models/mutimodel/textcnn_model&quot;</span><br><span class="line">    model_platform: &quot;tensorflow&quot;</span><br><span class="line">  &#125;</span><br><span class="line">  config &#123;</span><br><span class="line">    name: &quot;router&quot;</span><br><span class="line">    base_path: &quot;/models/mutimodel/router_model&quot;</span><br><span class="line">    model_platform: &quot;tensorflow&quot;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>gRPC代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> google.protobuf <span class="keyword">import</span> text_format</span><br><span class="line"><span class="keyword">from</span> tensorflow_serving.apis <span class="keyword">import</span> model_management_pb2</span><br><span class="line"><span class="keyword">from</span> tensorflow_serving.apis <span class="keyword">import</span> model_service_pb2_grpc</span><br><span class="line"><span class="keyword">from</span> tensorflow_serving.config <span class="keyword">import</span> model_server_config_pb2</span><br><span class="line"></span><br><span class="line">config_file = <span class="string">&quot;model.config&quot;</span></span><br><span class="line">stub = model_service_pb2_grpc.ModelServiceStub(channel)</span><br><span class="line">request = model_management_pb2.ReloadConfigRequest()</span><br><span class="line"></span><br><span class="line"><span class="comment"># # read config file</span></span><br><span class="line">config_content = <span class="built_in">open</span>(config_file, <span class="string">&quot;r&quot;</span>).read()</span><br><span class="line">model_server_config = model_server_config_pb2.ModelServerConfig()</span><br><span class="line">model_server_config = text_format.Parse(text=config_content, message=model_server_config)</span><br><span class="line">request.config.CopyFrom(model_server_config)</span><br><span class="line">request_response = stub.HandleReloadConfigRequest(request, <span class="number">10</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> request_response.status.error_code == <span class="number">0</span>:</span><br><span class="line">    <span class="built_in">open</span>(config_file, <span class="string">&quot;w&quot;</span>).write(<span class="built_in">str</span>(request.config))</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;TF Serving config file updated.&quot;</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;Failed to update config file.&quot;</span>)</span><br><span class="line">        <span class="built_in">print</span>(request_response.status.error_code)</span><br><span class="line">        <span class="built_in">print</span>(request_response.status.error_message)</span><br></pre></td></tr></table></figure>

<p>测试textcnn模型。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">   </span><br><span class="line">(train_data, train_labels), (test_data, test_labels) = datasets.imdb.load_data(num_words=<span class="number">10000</span>)</span><br><span class="line">test_data = pad_sequences(test_data, maxlen=<span class="number">200</span>)</span><br><span class="line">test_data = test_data.astype(np.float32)</span><br><span class="line">request = predict_pb2.PredictRequest()</span><br><span class="line">request.model_spec.name = <span class="string">&#x27;textcnn&#x27;</span></span><br><span class="line">request.model_spec.signature_name = <span class="string">&#x27;serving_default&#x27;</span></span><br><span class="line">request.inputs[<span class="string">&#x27;input_1&#x27;</span>].CopyFrom(tf.make_tensor_proto(np.array(test_data[<span class="number">0</span>]), shape=(<span class="number">1</span>, <span class="number">200</span>)))</span><br><span class="line">   </span><br><span class="line">start = time.time()</span><br><span class="line">response = stub.Predict(request, <span class="number">10.0</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;cost time = &quot;</span>, time.time() - start)</span><br><span class="line">res_from_server_np = tf.make_ndarray(response.outputs[<span class="string">&quot;dense&quot;</span>])[<span class="number">0</span>][<span class="number">0</span>]</span><br><span class="line">label = <span class="number">1</span> <span class="keyword">if</span> res_from_server_np &gt; <span class="number">0.5</span> <span class="keyword">else</span> <span class="number">0</span></span><br><span class="line"><span class="built_in">print</span>(label)</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cost time =  0.1668863296508789</span><br><span class="line">0</span><br></pre></td></tr></table></figure>

<p>模型新增成功。</p>
</li>
<li><p>–model_config_file_poll_wait_seconds</p>
</li>
</ol>
<p>在启动服务的时候，指定重新加载配置文件的时间间隔60s。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker run -p 8501:8501 -p 8500:8500 -v /root/mutimodel/:/models/mutimodel  -t tensorflow/serving --model_config_file=/models/mutimodel/model.config --allow_version_labels_for_unavailable_models=true --model_config_file_poll_wait_seconds=60</span><br></pre></td></tr></table></figure>

<p>立即调用textcnn，可以看到报如下错误。很明显，此时服务并没有加载textcnn模型。</p>
<blockquote>
<p>grpc._channel._Rendezvous: &lt;_Rendezvous of RPC that terminated with:<br>    status = StatusCode.NOT_FOUND<br>    details = “Servable not found for request: Latest(textcnn)”<br>    debug_error_string = “{“created”:”@1584608241.949779831”,”description”:”Error received from peer ipv4:49.233.155.170:8500”,”file”:”src/core/lib/surface/call.cc”,”file_line”:1055,”grpc_message”:”Servable not found for request: Latest(textcnn)”,”grpc_status”:5}”</p>
<blockquote>
</blockquote>
</blockquote>
<p>60s之后，观察到服务出现变化，显示已经加载模型textcnn和router。</p>
<p><img src="https://gitee.com/fushengwuyu1993/images/raw/master/imgs/1584608837466.png" alt="1584608837466"></p>
<p>此时，再次调用textcnn模型</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cost time =  0.1185760498046875</span><br><span class="line">0</span><br></pre></td></tr></table></figure>

<p>正确返回，模型更新成功。</p>
<p>引用：</p>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/zong596568821xp/article/details/102953720">https://blog.csdn.net/zong596568821xp/article/details/102953720</a></p>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/weixin_44899143/article/details/90715186?depth_1-utm_source=distribute.pc_relevant.none-task&amp;utm_source=distribute.pc_relevant.none-task#model_config_file_43">https://blog.csdn.net/weixin_44899143/article/details/90715186?depth_1-utm_source=distribute.pc_relevant.none-task&amp;utm_source=distribute.pc_relevant.none-task#model_config_file_43</a></p>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/JerryZhang__/article/details/86516428">https://blog.csdn.net/JerryZhang__/article/details/86516428</a></p>
<p><a target="_blank" rel="noopener" href="https://stackoverflow.com/questions/54440762/tensorflow-serving-update-model-config-add-additional-models-at-runtime">https://stackoverflow.com/questions/54440762/tensorflow-serving-update-model-config-add-additional-models-at-runtime</a></p>
<p><a target="_blank" rel="noopener" href="https://www.tensorflow.org/tfx/serving/serving_config">https://www.tensorflow.org/tfx/serving/serving_config</a></p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2021/07/20/%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96%E6%80%BB%E7%BB%93/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="sunshine">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="浮生物语的博客">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2021/07/20/%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96%E6%80%BB%E7%BB%93/" class="post-title-link" itemprop="url">关系抽取总结</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2021-07-20 00:00:00" itemprop="dateCreated datePublished" datetime="2021-07-20T00:00:00+08:00">2021-07-20</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2021-07-27 14:57:32" itemprop="dateModified" datetime="2021-07-27T14:57:32+08:00">2021-07-27</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/NLP/" itemprop="url" rel="index"><span itemprop="name">NLP</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>实体关系抽取（Entity and Relation Extraction，ERE）是信息抽取的关键任务之一。ERE是一个级联任务，分为两个子任务：实体抽取和关系抽取。主流的抽取模式有两类：Pipline和联合抽取。</p>
<p>对比联合模型，Pipline的优缺点：</p>
<ul>
<li><p>易于实现，实体和关系任务解耦，灵活性高，可以使用独立的数据集。</p>
</li>
<li><p>暴露偏差：关系训练输入的是gold实体，而预测时候输入的是实体模型预测的实体</p>
</li>
<li><p>实体冗余：存在大量的没有关系的实体，提升错误率，增加计算复杂度</p>
</li>
<li><p>交互缺失：忽略了两个任务之间的内在联系和依赖关系</p>
</li>
</ul>
<h3 id="1-pipline"><a href="#1-pipline" class="headerlink" title="1. pipline"></a>1. pipline</h3><h4 id="1-1-NER"><a href="#1-1-NER" class="headerlink" title="1.1 NER"></a>1.1 NER</h4><ol>
<li><p>序列标注：SoftMax和CRF</p>
<p>每个token只能属于一个标签，不能解决重叠实体问题</p>
<ul>
<li><p>采用token-level的多label分类，将Softmax替换为Sigmoid。这种方式会导致label之间的依赖关系缺失，可采用后处理规则进行约束</p>
<p><img src="https://gitee.com/fushengwuyu1993/images/raw/master/imgs/image-20210521163318056.png" alt="image-20210521163318056"></p>
</li>
<li><p>Neural Architectures for Nested NER through Linearization</p>
<p>采取CRF，但是设置多个标签层，然后讲所有标签层合并。增加lable数量，导致label不平衡问题</p>
<p><img src="https://gitee.com/fushengwuyu1993/images/raw/master/imgs/image-20210521163800149.png" alt="image-20210521163800149"></p>
</li>
</ul>
</li>
<li><p>指针网络</p>
<ul>
<li><p>MRC-QA+单层指针网络（A Unified MRC Framework for Named Entity Recognition ）</p>
<p>构建query问题指代所要抽取的实体类型，同时引入先验知识。</p>
<p><img src="https://gitee.com/fushengwuyu1993/images/raw/master/imgs/image-20210521164345702.png" alt="image-20210521164345702"></p>
</li>
<li><p>多层指针网络</p>
<p>构建多层指针网络，每层对应一个实体类型</p>
<p><img src="https://gitee.com/fushengwuyu1993/images/raw/master/imgs/image-20210521164426461.png" alt="image-20210521164426461"></p>
</li>
</ul>
<p>注意：</p>
<ul>
<li>MRC-QA会引入query对实体类型编码，需要对原始文本重复编码以构造不同实体类型的query，将会大大增加计算量</li>
<li>多层指针网络（n个2元sigmoid分类），会导致样本tag空间稀疏，收敛较慢。</li>
</ul>
</li>
<li><p>片段排列+分类（Span-Level Model for Relation Extraction）</p>
<p>针对Span排列的方式，显示所有可能的span排列，针对每个独立的span进行分类。由于选择的每个span都是独立的，所有该方式可以解决重叠实体问题。</p>
<p><img src="https://gitee.com/fushengwuyu1993/images/raw/master/imgs/image-20210521165013140.png" alt="image-20210521165013140"></p>
<p>若文本过长，会产生大量的负样本，所以在实践中需要选择合理的span长度（窗口）。</p>
<ul>
<li><p><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2012.05426v5.pdf">Empirical Analysis of Unlabeled Entity Problem in Named Entity Recognition</a></p>
<p>利用负采样技巧，大大提升实体识别效果。</p>
<p><img src="https://gitee.com/fushengwuyu1993/images/raw/master/imgs/image-20210610093043724.png" alt="image-20210610093043724"><br>$$<br>s_{i, j}=h_i \oplus h_j \oplus (h_i-h_j)\oplus(h_i \odot h_j)<br>$$</p>
</li>
</ul>
</li>
<li><p>MRC（A Unified MRC Framework for Named Entity Recognition）</p>
<p><img src="https://gitee.com/fushengwuyu1993/images/raw/master/imgs/image-20210525085754303.png" alt="image-20210525085754303"></p>
<p>实验证明，MRC效果的提升主要来自于基于自然语言的标签描述引入了更多的先验信息，对数据稀少的标签提升比较明显。</p>
<ul>
<li><p>query问题设置标准比较模糊，不同的query构建方式导致不同的实验效果</p>
</li>
<li><p>针对一条样本，需要构造多个不同的query，重复编码，增加计算量</p>
</li>
<li><p>标签不平衡问题，真实场景下，大部分文本中只存在少量类别的实体，绝大部分query对对应了负样本。针对该，该团队提出了DSC loss，参考：<a href="https://link.zhihu.com/?target=https://arxiv.org/pdf/1911.02855.pdf">Dice Loss for Data-imbalanced NLP Tasks</a></p>
</li>
</ul>
</li>
<li><p>bi-affine（Named Entity Recognition as Dependency Parsing）</p>
<p>将实体识别任务转化为start和end索引问题，采用biaffine模型对句子中的tokens的start和end对进行评分。最终biaffine模型的输出为$l\times l\times c$ 的矩阵（l为句子长度，c为标签类别数）</p>
</li>
</ol>
<p>$$<br>h_s(i) = FFNN_s(x_{s_i})<br>$$</p>
<p>$$<br>h_e(i) = FFNN_e(x_{e_i})<br>$$</p>
<p>$$<br>    r_m(i)=h_s(i)^TU_mh_e(i)+W_m(h_s(i)\oplus h_e(i))+b_m<br>$$</p>
<p>   <img src="https://gitee.com/fushengwuyu1993/images/raw/master/imgs/image-20210521170107671.png" alt="image-20210521170107671"></p>
<p>   备注：</p>
<ul>
<li>线性模型（linear）： $Wx^T$</li>
<li>双线性模型（blinear）: $xWy^T$</li>
<li>仿射模型（affine）: $Wx^T+b$ 或者写作 $W[x:1]$</li>
<li>双仿射模型（bi-affine）: $[x:1]W[y:1]$</li>
</ul>
<h4 id="1-2-关系分类"><a href="#1-2-关系分类" class="headerlink" title="1.2 关系分类"></a>1.2 关系分类</h4><ol>
<li><p><strong>Matching the Blanks: Distributional Similarity for Relation Learning</strong></p>
<p><img src="https://gitee.com/fushengwuyu1993/images/raw/master/imgs/image-20210521171350234.png" alt="image-20210521171350234"></p>
<p>基于bert，采用6中不同结构来进行实体pair的pooling，然后讲pooling后的编码进行关系分类。实验显示（f）结果最好。</p>
<p><img src="https://gitee.com/fushengwuyu1993/images/raw/master/imgs/image-20210521171610550.png" alt="image-20210521171610550"></p>
</li>
<li><p><strong>Extracting Multiple-Relations in One-Pass with Pre-Trained Transformers</strong></p>
<p><img src="https://gitee.com/fushengwuyu1993/images/raw/master/imgs/image-20210521171853468.png" alt="image-20210521171853468"></p>
<p>Pipline方式下的关系分类，同一个句子通常会有多个不同的实体对关系，一般的做法是构造多个实体对，进行多次关系分类，本质是上一个muti pass问题，同一个句子会进行多次计算，增加计算时间。</p>
<ul>
<li><p>本文将多次关系分类问题转化为one pass问题。一条样本输入模型，即可完成多个关系的分类。</p>
</li>
<li><p>本文将还编码词和实体之间的相对距离计算Entity-Aware Self-Attention。$w_{d(i-j)}$ 代表实体$x_i$ 到token $x_j$的相对距离的embedding。</p>
<p><img src="https://gitee.com/fushengwuyu1993/images/raw/master/imgs/image-20210610142844105.png" alt="image-20210610142844105"></p>
<p>在标准self-attention的基础上增加了实体距离信息。<br>$$<br>Q_{south}=h_{south}W^Q<br>$$</p>
<p>$$<br>K_{in}=h_{in}W^K+A^K_{south_in}<br>$$</p>
<p>$$<br>V_{in}=h_{in}W^V+B^V_{south_in}<br>$$</p>
<p>$$<br>Z_{south_in}=softmax(\frac{Q_{south}K_{in}}{\sqrt{d_{k}}})V_{in}<br>$$</p>
<p>实体距离信息计算如下：</p>
<ul>
<li>if south is entity: $A^K_{south_in}=W^K_{d(index(south), index(in))}$</li>
<li>if in is entity: $B^V_{south_in}=W^V_{d(index(south), index(in))}$</li>
<li>else: $A^K_{south_in}=O$</li>
</ul>
</li>
</ul>
</li>
<li><p>Enriching Pre-trained Language Model with Entity Information for Relation Classification</p>
<p><img src="https://gitee.com/fushengwuyu1993/images/raw/master/imgs/image-20210522110111197.png" alt="image-20210522110111197"></p>
</li>
<li><p><strong>Simultaneously Self-Attending to All Mentions for Full-Abstract Biological Relation Extraction</strong></p>
<ul>
<li>采用one-pass对所有实体进行关系分类，从所有实体mention中定位关系</li>
<li>文档级别关系抽取，引入NER辅助进行多任务学习</li>
<li>关系分类采用Bi-affine，而不是采用Softmax</li>
</ul>
<p>使用Tansformer编码，对每个token通过两个独立的MLP进行三元组中的head和tail表征，最后使用Bi-affine计算每个三元组的得分。</p>
<p><img src="https://gitee.com/fushengwuyu1993/images/raw/master/imgs/image-20210522110921353.png" alt="image-20210522110921353"></p>
</li>
<li><p><strong>A Frustratingly Easy Approach for Joint Entity and Relation Extraction</strong></p>
<ul>
<li><p>实体模型采用Span-level NER的方式</p>
</li>
<li><p>关系模型：将实体边界和实体类型作为标记符加入到实体span前后</p>
</li>
<li><p>近似模型：将实体边界和标记符放到文本之后，与原文对应的实体共享位置向量。具体实现中，attention层，文本token只attend文本token，不去attend标记符token，而标记符token可以attend原文token。</p>
</li>
<li><p>跨句信息：通过窗口滑动的方式引入跨句信息，即文本输入的左右上下文中分别滑动$(W-n)/2$ 个词，n为文本长度，W为固定窗口大小。<img src="https://gitee.com/fushengwuyu1993/images/raw/master/imgs/image-20210522111559571.png" alt="image-20210522111559571"></p>
<p> attention mask实现：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Compute the attention mask matrix</span></span><br><span class="line">        attention_mask = []</span><br><span class="line">        <span class="keyword">for</span> _, from_mask <span class="keyword">in</span> <span class="built_in">enumerate</span>(input_mask):</span><br><span class="line">            attention_mask_i = []</span><br><span class="line">            <span class="keyword">for</span> to_mask <span class="keyword">in</span> input_mask:</span><br><span class="line">                <span class="keyword">if</span> to_mask &lt;= <span class="number">1</span>:</span><br><span class="line">                    attention_mask_i.append(to_mask)</span><br><span class="line">                <span class="keyword">elif</span> from_mask == to_mask <span class="keyword">and</span> from_mask &gt; <span class="number">0</span>:</span><br><span class="line">                    attention_mask_i.append(<span class="number">1</span>)</span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    attention_mask_i.append(<span class="number">0</span>)</span><br><span class="line">            attention_mask.append(attention_mask_i)</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">input_mask = [1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 3]</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">[1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]</span><br><span class="line">[1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]</span><br><span class="line">[1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]</span><br><span class="line">[1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]</span><br><span class="line">[1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]</span><br><span class="line">[1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]</span><br><span class="line">[1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]</span><br><span class="line">[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]</span><br><span class="line">[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]</span><br><span class="line">[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]</span><br><span class="line">[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]</span><br><span class="line">[1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1]</span><br><span class="line">[1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1]</span><br><span class="line">[1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1]</span><br><span class="line">[1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1]</span><br></pre></td></tr></table></figure></li>
</ul>
</li>
</ol>
<h3 id="2-Joint-Model"><a href="#2-Joint-Model" class="headerlink" title="2. Joint Model"></a>2. Joint Model</h3><p>联合模型就是只有一个模型，将两个子任务统一建模。联合抽取可以进一步利用两个任务之间的潜在信息，缓解错误传播的缺点。</p>
<p>联合抽取的难点在于何如加强实体模型和关系模型之间的交互，比如实体模型和关系模型的输出之间存在一定的约束，在建模时考虑此种约束有利于联合模型的性能。</p>
<ul>
<li><p>共享参数的联合模型</p>
<p>通过共享参数（共享输入特征或者内部隐藏状态）实现联合，这种方式对子模型没有限制，但是由于使用独立的解码算法，导致实体模型和关系模型之间的交互不强</p>
</li>
<li><p>联合解码的联合模型</p>
</li>
</ul>
<h4 id="2-1-共享参数的联合抽取方法"><a href="#2-1-共享参数的联合抽取方法" class="headerlink" title="2.1 共享参数的联合抽取方法"></a>2.1 共享参数的联合抽取方法</h4><p>基于参数共享的联合抽取方法的解码主要包括：序列标注CRF/Softmax、指针网络、分类Softmax、seq2seq等。最终的loss为实体loss和关系loss相加。</p>
<ol>
<li><p>多头选择+sigmoid： <strong>Joint entity recognition and relation extraction as a multi-head selection problem</strong></p>
<p><img src="https://gitee.com/fushengwuyu1993/images/raw/master/imgs/image-20210522114945385.png" alt="image-20210522114945385"></p>
<p>先抽取实体，再利用实体边界信息进行关系抽取</p>
<ul>
<li><p>实体抽取：BIO标注，CRF解码</p>
</li>
<li><p>关系抽取：sigmoid多头选择。对于含有n的token的句子，最终构成的关系矩阵为$n\times r \times n $ ，其中r为关系数。</p>
</li>
<li><p>引入实体识别后的entity label embedding（BIO）进行关系抽取，训练是使用gold label，预测时使用predict label。</p>
</li>
</ul>
</li>
<li><p>SPO+指针网络： <strong>Joint Extraction of Entities and Relations Based on a Novel Decomposition Strategy</strong></p>
<p><img src="https://gitee.com/fushengwuyu1993/images/raw/master/imgs/image-20210524105215439.png" alt="image-20210524105215439"></p>
<p><img src="https://gitee.com/fushengwuyu1993/images/raw/master/imgs/image-20210524105239802.png" alt="image-20210524105239802"></p>
<ul>
<li><p>spo问题，先抽S，再抽PO</p>
</li>
<li><p>在训练时，subject的选取是随机的，并没有将所有的subject统一进行po抽取，所以需要增大epochs训练，保证训练充分。ps：可以遍历的方式训练所有的subject（大约能提高1个百分点）</p>
</li>
</ul>
</li>
<li><p>LIC2020冠军方案</p>
<p><img src="https://gitee.com/fushengwuyu1993/images/raw/master/imgs/image-20210524113526222.png" alt="image-20210524113526222"></p>
<ul>
<li>spo抽取，先抽s，再抽o，最后抽取p</li>
<li>随机的把subject加到句子的开头，用sep分割组成新的输入，预测o。预测p同理</li>
</ul>
</li>
</ol>
<h4 id="2-2-基于联合解码的联合抽取方法"><a href="#2-2-基于联合解码的联合抽取方法" class="headerlink" title="2.2 基于联合解码的联合抽取方法"></a>2.2 基于联合解码的联合抽取方法</h4><p>​    基于共享参数的联合抽取方法中，并没有显示的刻画两个任务之间的交互。同时，训练和预测仍然存在gap。</p>
<ol>
<li><p><strong>Joint Extraction of Entities and Overlapping Relations Using Position-Attentive Sequence Labeling</strong></p>
<p><img src="https://gitee.com/fushengwuyu1993/images/raw/master/imgs/image-20210524115043806.png" alt="image-20210524115043806"></p>
<p><img src="https://gitee.com/fushengwuyu1993/images/raw/master/imgs/image-20210610105307448.png" alt="image-20210610105307448"></p>
<p>标记过程如下：</p>
<p>对于含有n个token的句子，为每个token创建一个长度为n的序列并标记，所以总共会标注n个长度为n的序列。根据不同的查询位置p（目标单词所在句子中的位置）对n个不同的标记序列进行标记</p>
<ul>
<li>若查询位置p在实体的开始处，则在p处标记实体的类型</li>
<li>若p处的实体为subject，则在与p处实体有关系的其他实体（object）用关系类型标记</li>
<li>若p处的实体为object，则其余位置标记为“O”</li>
</ul>
</li>
<li><p><strong>Joint extraction of entities and relations based on a novel tagging scheme</strong></p>
<p><img src="https://gitee.com/fushengwuyu1993/images/raw/master/imgs/image-20210524115546893.png" alt="image-20210524115546893"></p>
<p><img src="https://gitee.com/fushengwuyu1993/images/raw/master/imgs/image-20210524120026450.png" alt="image-20210524120026450"></p>
<p>该方案是LIC2020和LIC2021关系抽取的baseline方案，统一了实体和关系的SPO标注框架</p>
<ul>
<li>token level的多标签分类，单个token对应多个不同的label</li>
<li>假定存在R个关系，则label一共有（2*R+2）个。</li>
<li>该框架不发解决实体重叠的关系抽取</li>
</ul>
</li>
<li><p>TPLinker: Single-stage Joint Extraction of Entities and Relations Through Token Pair Linking</p>
<p>TPLinker整体标注框架是基于token pair进行的，本质上是一个span矩阵（类似于多头标注、bi-affine）。</p>
<p><img src="https://gitee.com/fushengwuyu1993/images/raw/master/imgs/image-20210524120815690.png" alt="image-20210524120815690"></p>
<p>TPLinker通过链接三种类型的span矩阵来实现编码（关系类别总数为R）</p>
<ul>
<li>紫色标注：EH to ET，表示实体的首位关系，表示为一个$N \times N$ 的矩阵，如两个实体：New York City:M(New, City) =1; De Blasio:M(De, Blasio) =1</li>
<li>红色标注：SH to OH,表示subject和object的头token的关系，表示为R个$N \times N$的矩阵。如三元组(New York City, mayor,De Blasio):M(New, De)=1</li>
<li>蓝色标注：ST to OT，表示subject和object的尾部token间的关系，表示为R个$N \times N$矩阵；如三元组(New York City, mayor,De Blasio):M(City, Blasio)=1</li>
</ul>
<p>最终，会得到2*R+1个矩阵。为防止稀疏计算，下三角不参与计算，如果关系存在与下三角，则将其转置为上三角，并将标记1替换为2.</p>
<p><img src="https://gitee.com/fushengwuyu1993/images/raw/master/imgs/image-20210524120802248.png" alt="image-20210524120802248"></p>
<p>通过解码结构可以看到，每个token pair对应了2*R+1个label。对于N个token的序列，最终会展开为一个$N \times (N+1)/2$ 的 序列，也就是将token pair的每个token编码拼接在一起。ps：一般来说，显卡都是支持不了一次性预测$N \times (N+1)/2$的序列，源码中设置了参数p（0-1），表示为单轮预测序列长度为：$N \times p$</p>
<p>解码过程为：</p>
<ol>
<li>解码EH-to-ET可以得到句子中所有的实体，用实体头token idx作为key，实体作为value，存入字典D中；</li>
<li>对每种关系r，解码ST-to-OT得到token对存入集合E中，解码SH-to-OH得到token对并在D中关联其token idx的实体value；</li>
<li>对上一步中得到的SH-to-OH token对的所有实体value对，在集合E中依次查询是否其尾token对在E中，进而可以得到三元组信息。</li>
</ol>
<p>结合上图的具体case,我们具体描述一下解码过程：</p>
<p>解码EH-to-ET中得到3个实体：{New York,New York City,De Blasio}; 字典D为：<code>&#123;New:(New York,New York City),De:(De Blasio)&#125;</code></p>
<p>以关系“<strong>mayor</strong>”为例,</p>
<ol>
<li>解码ST-to-OT得到集合E：{(City,Blasio)};    解码SH-to-OH得到{(New,De)}，其在字典D中可关联的subject实体集合为: {New York,New York City};object集合{De Blasio};</li>
<li>遍历上述subject集合和object集合，并在集合E中查询尾token，发现只有一个实体三元组{New York City,mayor,De Blasio}</li>
</ol>
<p>以关系“<strong>born in</strong>”为例,</p>
<ol>
<li>解码ST-to-OT得到集合E：{(Blasio,York),(Blasio,City)};解码SH-to-OH得到{(De,New)}，其在字典D中可关联的subject实体集合为{De Blasio};object集合为{New York,New York City};</li>
<li>遍历上述subject集合和object集合，并在集合E中查询尾token，可得到2个实体三元组：{De Blasio,born in,New York}和{De Blasio,born in,New York City}</li>
</ol>
<p>由于关系live in与born in一样，所以我们最终可得到5个三元组：</p>
<p>(New York City, mayor, De Blasio), (De Blasio, born in, New York), (De Blasio, born in, New York City), (De Blasio, live in, New York), (De Blasio, live in, New York City)</p>
</li>
</ol>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2021/07/20/%E4%BE%9D%E5%AD%98%E5%8F%A5%E6%B3%95%E5%88%86%E6%9E%90%E6%80%BB%E7%BB%93/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="sunshine">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="浮生物语的博客">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2021/07/20/%E4%BE%9D%E5%AD%98%E5%8F%A5%E6%B3%95%E5%88%86%E6%9E%90%E6%80%BB%E7%BB%93/" class="post-title-link" itemprop="url">依存句法关系总结</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>
              

              <time title="创建时间：2021-07-20 00:00:00 / 修改时间：10:15:01" itemprop="dateCreated datePublished" datetime="2021-07-20T00:00:00+08:00">2021-07-20</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h4 id="1-基本概念"><a href="#1-基本概念" class="headerlink" title="1. 基本概念"></a>1. 基本概念</h4><p>依存句法分析（Dependency Parsing，DP）通过分析语言单位内成分之间的依存关系，揭示其句法结构。直观来讲，就是分析句子中的“主谓宾”、“定状补”这些语法成分，并分析各成分的关系。对句法结构进行分析，一方面是语言理解的自身需求，句法分析是语言理解的基础，另外一方面，句法分析也为其他自然语言处理任务提供支持。比如：句法驱动的统计机器翻译需要对源语言或目标语言进行句法分析。</p>
<h5 id="1-1-谓词"><a href="#1-1-谓词" class="headerlink" title="1.1 谓词"></a>1.1 谓词</h5><p>依存句法认为“谓词”中的动词是一个句子的核心，其他成分与动词直接或者间接的产生联系。</p>
<h5 id="1-2-依存理论"><a href="#1-2-依存理论" class="headerlink" title="1.2 依存理论"></a>1.2 依存理论</h5><p>依存理论中，“依存”指的是词与词之间处于支配与被支配的关系，这种关系具有方向性。处于支配地位的词称之为支配者（head），处于被支配地位的成分称之为从属者（dependency）。</p>
<p>依存语法存在一个基本假设，句法分析核心是词与词的依存关系，一个依存关系连接两个词：head和dependency。依存关系可以细分为不同类型，表示具体的两个词的依存关系。</p>
<h5 id="1-3-依存关系"><a href="#1-3-依存关系" class="headerlink" title="1.3 依存关系"></a>1.3 依存关系</h5><table>
<thead>
<tr>
<th>关系类型</th>
<th>Tag</th>
<th>Description</th>
<th>Example</th>
</tr>
</thead>
<tbody><tr>
<td>主谓关系</td>
<td>SBV</td>
<td>subject-verb</td>
<td>我送她一束花 (我 &lt;– 送)</td>
</tr>
<tr>
<td>动宾关系</td>
<td>VOB</td>
<td>直接宾语，verb-object</td>
<td>我送她一束花 (送 –&gt; 花)</td>
</tr>
<tr>
<td>间宾关系</td>
<td>IOB</td>
<td>间接宾语，indirect-object</td>
<td>我送她一束花 (送 –&gt; 她)</td>
</tr>
<tr>
<td>前置宾语</td>
<td>FOB</td>
<td>前置宾语，fronting-object</td>
<td>他什么书都读 (书 &lt;– 读)</td>
</tr>
<tr>
<td>兼语</td>
<td>DBL</td>
<td>double</td>
<td>他请我吃饭 (请 –&gt; 我)</td>
</tr>
<tr>
<td>定中关系</td>
<td>ATT</td>
<td>attribute</td>
<td>红苹果 (红 &lt;– 苹果)</td>
</tr>
<tr>
<td>状中结构</td>
<td>ADV</td>
<td>adverbial</td>
<td>非常美丽 (非常 &lt;– 美丽)</td>
</tr>
<tr>
<td>动补结构</td>
<td>CMP</td>
<td>complement</td>
<td>做完了作业 (做 –&gt; 完)</td>
</tr>
<tr>
<td>并列关系</td>
<td>COO</td>
<td>coordinate</td>
<td>大山和大海 (大山 –&gt; 大海)</td>
</tr>
<tr>
<td>介宾关系</td>
<td>POB</td>
<td>preposition-object</td>
<td>在贸易区内 (在 –&gt; 内)</td>
</tr>
<tr>
<td>左附加关系</td>
<td>LAD</td>
<td>left adjunct</td>
<td>大山和大海 (和 &lt;– 大海)</td>
</tr>
<tr>
<td>右附加关系</td>
<td>RAD</td>
<td>right adjunct</td>
<td>孩子们 (孩子 –&gt; 们)</td>
</tr>
<tr>
<td>独立结构</td>
<td>IS</td>
<td>independent structure</td>
<td>两个单句在结构上彼此独立</td>
</tr>
<tr>
<td>核心关系</td>
<td>HED</td>
<td>head</td>
<td>指整个句子的核心</td>
</tr>
</tbody></table>
<h4 id="2-基本方法"><a href="#2-基本方法" class="headerlink" title="2. 基本方法"></a>2. 基本方法</h4><ul>
<li><p>基于转移的方法</p>
<p>基于转移的方法通过shift-reduce两个基本动作，将序列转为树结构。首先用一个 buffer 来存储所有未处理的输入句子，并用一个栈来存储当前的分析状态。动作可以分为：</p>
<ol>
<li>shift，即将 buffer 中的一个词移到栈中；</li>
<li>$left_arc(x)$，即栈顶两个词 a,b 为 a&lt;-b 的依赖关系，关系种类为 x；</li>
<li>$right_arc(x)$，即栈顶两个词 a,b 为 a-&gt;b 的依赖关系，关系种类为 x。后两种动作为 reduce 动作。</li>
</ol>
<p>目前，基于转移的方法最好模型是stack lstm。 通过三个 LSTM 来分别建模栈状态、待输入序列和动作序列。 其中因为栈需要入栈和出栈，因此作者提出了一个 Stack LSTM 来建模栈状态。</p>
<p><img src="https://gitee.com/fushengwuyu1993/images/raw/master/imgs/1587606360367.png" alt="1587606360367"></p>
<p>论文地址： <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1505.08075.pdf">https://arxiv.org/pdf/1505.08075.pdf</a></p>
</li>
<li><p>基于图的方法</p>
<p>目前的依存句法分析中，<strong>最流行的方法是基于图的方法经典的方法是 Biaffine 模型</strong>。直接用神经网络来预测每两个词之间存在依存关系的概率，这样我们就得到一个全连接图，图上每个边代表了节点 a 指向节点 b 的概率。然后使用MST等方法来来将图转换为一棵树。</p>
<p>Biaffine 模型其实和我们目前全连接自注意力模型非常类似。Biaffine 模型十分简单，并且容易理解，并且在很多数据集上都取得了目前最好的结果。</p>
<p><img src="https://gitee.com/fushengwuyu1993/images/raw/master/imgs/1587606231909.png" alt="1587606231909"></p>
<p>论文地址：<a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1611.01734.pdf">https://arxiv.org/pdf/1611.01734.pdf</a></p>
</li>
<li><p>联合模型(深度学习)</p>
<ol>
<li><p>词性标注&amp;句法分析</p>
<p>联合词性标注和句法分析的模型有很多，可以是基于转移的方法，也可以是基于图的方法，这里介绍一个简单思路。首先利用lstm来预测词性，然后联合词性信息和词信息一起用另外一个lstm来建模，并用Biaffine模型来做句法分析。</p>
<p><img src="https://gitee.com/fushengwuyu1993/images/raw/master/imgs/1587606449299.png" alt="1587606449299"></p>
<p>论文地址：<a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1807.03955.pdf">https://arxiv.org/pdf/1807.03955.pdf</a></p>
</li>
<li><p>中文分词&amp;句法分析</p>
<p>中文的句法分析是基于词级别的，所以在句法分析之前，会做分词。为了避免流水线模式的错误积累，很容易想到的就是分词和词法分析联合建模。</p>
<p>这里主要介绍一下邱希鹏教授实验室提出的模型：joint CWS。</p>
<p><img src="https://gitee.com/fushengwuyu1993/images/raw/master/imgs/1587606912240.png" alt="1587606912240"></p>
<p>其中两个关键点：</p>
<ul>
<li>biaffine parsing</li>
<li>‘app’ 作为特殊的依赖关系</li>
</ul>
<p>其实方法很简单，只需要将词内部的字之间加上一个特殊的依赖关系“app”，然后将词级别的依存关系转换为字级别的依存关系。并且用 biaffine 模型来进行同时预测。</p>
<p>论文地址：<a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1904.04697.pdf">https://arxiv.org/pdf/1904.04697.pdf</a></p>
</li>
</ol>
</li>
</ul>
<h4 id="3-常用工具"><a href="#3-常用工具" class="headerlink" title="3. 常用工具"></a>3. 常用工具</h4><p><a target="_blank" rel="noopener" href="https://www.jianshu.com/p/867bd48cd9ad">https://www.jianshu.com/p/867bd48cd9ad</a></p>
<h5 id="3-1-LTP"><a href="#3-1-LTP" class="headerlink" title="3.1 LTP"></a>3.1 LTP</h5><ol>
<li><p>安装</p>
<blockquote>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install pyltp</span><br></pre></td></tr></table></figure></blockquote>
</li>
<li><p>下载数据包</p>
<p>ltp_data_v3.4.0： 链接: <a target="_blank" rel="noopener" href="https://pan.baidu.com/s/1aDrb95ylZHoTPKJY6K1Slw">https://pan.baidu.com/s/1aDrb95ylZHoTPKJY6K1Slw</a>  密码: ehe2</p>
</li>
<li><p>测试代码</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyltp <span class="keyword">import</span> Parser, Postagger, Segmentor</span><br><span class="line"></span><br><span class="line">text = <span class="string">&#x27;HanLP是一系列模型与算法组成的自然语言处理工具包，目标是普及自然语言处理在生产环境中的应用。&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 分词</span></span><br><span class="line">segmentor = Segmentor()</span><br><span class="line">segmentor.load(<span class="string">&quot;/home/sunshine/datasets/other/ltp_data_v3.4.0/cws.model&quot;</span>)</span><br><span class="line">tokens = segmentor.segment(text)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 词性</span></span><br><span class="line">postagger = Postagger()</span><br><span class="line">postagger.load(<span class="string">&#x27;/home/sunshine/datasets/other/ltp_data_v3.4.0/pos.model&#x27;</span>)</span><br><span class="line">postags = postagger.postag(tokens)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 依存句法分析</span></span><br><span class="line">parser = Parser()</span><br><span class="line">parser.load(<span class="string">&#x27;/home/sunshine/datasets/other/ltp_data_v3.4.0/parser.model&#x27;</span>)</span><br><span class="line">arcs = parser.parse(tokens, postags)</span><br><span class="line"></span><br><span class="line">i = <span class="number">1</span></span><br><span class="line">result = <span class="built_in">zip</span>(tokens, postags, arcs)</span><br><span class="line"><span class="keyword">for</span> item <span class="keyword">in</span> result:</span><br><span class="line">    <span class="built_in">print</span>(i, item[<span class="number">0</span>], item[<span class="number">1</span>], item[<span class="number">2</span>].head, item[<span class="number">2</span>].relation)</span><br><span class="line">    i += <span class="number">1</span></span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">1 HanLP ws 2 SBV</span><br><span class="line">2 是 v 0 HED</span><br><span class="line">3 一 m 4 ATT</span><br><span class="line">4 系列 q 5 ATT</span><br><span class="line">5 模型 n 8 SBV</span><br><span class="line">6 与 c 7 LAD</span><br><span class="line">7 算法 n 5 COO</span><br><span class="line">8 组成 v 12 ATT</span><br><span class="line">9 的 u 8 RAD</span><br><span class="line">10 自然 n 11 ATT</span><br><span class="line">11 语言 n 12 SBV</span><br><span class="line">12 处理 v 2 VOB</span><br><span class="line">13 工具包 n 12 VOB</span><br><span class="line">14 ， wp 2 WP</span><br><span class="line">15 目标 n 16 SBV</span><br><span class="line">16 是 v 2 COO</span><br><span class="line">17 普及 v 16 VOB</span><br><span class="line">18 自然 n 19 ATT</span><br><span class="line">19 语言 n 20 ATT</span><br><span class="line">20 处理 v 17 VOB</span><br><span class="line">21 在 p 26 ATT</span><br><span class="line">22 生产 v 23 ATT</span><br><span class="line">23 环境 n 24 ATT</span><br><span class="line">24 中 nd 21 POB</span><br><span class="line">25 的 u 21 RAD</span><br><span class="line">26 应用 v 20 VOB</span><br><span class="line">27 。 wp 2 WP</span><br></pre></td></tr></table></figure></li>
</ol>
<h5 id="3-2-stanfordNLP"><a href="#3-2-stanfordNLP" class="headerlink" title="3.2 stanfordNLP"></a>3.2 stanfordNLP</h5><h6 id="3-2-1-StanordCoreNLP"><a href="#3-2-1-StanordCoreNLP" class="headerlink" title="3.2.1 StanordCoreNLP"></a>3.2.1 StanordCoreNLP</h6><p>Github地址：<a target="_blank" rel="noopener" href="https://github.com/Lynten/stanford-corenlp">https://github.com/Lynten/stanford-corenlp</a></p>
<p>官网：<a target="_blank" rel="noopener" href="https://stanfordnlp.github.io/CoreNLP/">https://stanfordnlp.github.io/CoreNLP/</a></p>
<ol>
<li><p>安装</p>
<blockquote>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install stanfordcorenlp</span><br></pre></td></tr></table></figure></blockquote>
</li>
<li><p>安装java环境（略）</p>
</li>
<li><p>下载数据包</p>
<p>链接: <a target="_blank" rel="noopener" href="https://pan.baidu.com/s/1kD3gaxVwvxZGaEN3EDedvA">https://pan.baidu.com/s/1kD3gaxVwvxZGaEN3EDedvA</a> 提取码: m72n</p>
<p>数据包下载之后，解压stanford-corenlp-full-2018-02-27.zip，将stanford-chinese-corenlp-2018-02-27-models.jar拷贝至stanford-corenlp-full-2018-02-27.zip解压目录。</p>
</li>
<li><p>测试代码</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> stanfordcorenlp <span class="keyword">import</span> StanfordCoreNLP</span><br><span class="line">text = <span class="string">&#x27;HanLP是一系列模型与算法组成的自然语言处理工具包，目标是普及自然语言处理在生产环境中的应用。&#x27;</span></span><br><span class="line">nlp = StanfordCoreNLP(<span class="string">&quot;/home/sunshine/datasets/other/standfordCoreNLP/stanford-corenlp-full-2018-02-27&quot;</span>, lang=<span class="string">&#x27;zh&#x27;</span>)</span><br><span class="line">tokens = nlp.word_tokenize(text)</span><br><span class="line">postags = nlp.pos_tag(text)</span><br><span class="line">result = nlp.dependency_parse(text)</span><br><span class="line">i = <span class="number">1</span></span><br><span class="line"><span class="keyword">for</span> item <span class="keyword">in</span> <span class="built_in">zip</span>(tokens, postags, result):</span><br><span class="line">    <span class="built_in">print</span>(i, item[<span class="number">0</span>], item[<span class="number">1</span>][<span class="number">1</span>], item[<span class="number">2</span>][<span class="number">1</span>], item[<span class="number">2</span>][<span class="number">2</span>])</span><br><span class="line">    i += <span class="number">1</span></span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">1 HanLP NR 0 12</span><br><span class="line">2 是 VC 12 1</span><br><span class="line">3 一 CD 12 2</span><br><span class="line">4 系列 M 11 3</span><br><span class="line">5 模型 NN 3 4</span><br><span class="line">6 与 CC 7 5</span><br><span class="line">7 算法 NN 7 6</span><br><span class="line">8 组成 VV 8 7</span><br><span class="line">9 的 DEC 11 8</span><br><span class="line">10 自然 NN 8 9</span><br><span class="line">11 语言 NN 11 10</span><br><span class="line">12 处理 VV 12 11</span><br><span class="line">13 工具包 NN 12 13</span><br><span class="line">14 ， PU 12 14</span><br><span class="line">15 目标 NN 17 15</span><br><span class="line">16 是 VC 17 16</span><br><span class="line">17 普及 VV 12 17</span><br><span class="line">18 自然 NN 19 18</span><br><span class="line">19 语言 NN 17 19</span><br><span class="line">20 处理 VV 17 20</span><br><span class="line">21 在 P 23 21</span><br><span class="line">22 生产 NN 23 22</span><br><span class="line">23 环境 NN 26 23</span><br><span class="line">24 中 LC 23 24</span><br><span class="line">25 的 DEG 23 25</span><br><span class="line">26 应用 NN 20 26</span><br><span class="line">27 。 PU 12 27</span><br></pre></td></tr></table></figure></li>
<li><p>依存句法解释</p>
<blockquote>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br></pre></td><td class="code"><pre><span class="line">&gt; &gt; ROOT：要处理文本的语句</span><br><span class="line">&gt; &gt; IP：简单从句</span><br><span class="line">&gt; &gt; NP：名词短语</span><br><span class="line">&gt; &gt; VP：动词短语</span><br><span class="line">&gt; &gt; PU：断句符，通常是句号、问号、感叹号等标点符号</span><br><span class="line">&gt; &gt; LCP：方位词短语</span><br><span class="line">&gt; &gt; PP：介词短语</span><br><span class="line">&gt; &gt; CP：由‘的’构成的表示修饰性关系的短语</span><br><span class="line">&gt; &gt; DNP：由‘的’构成的表示所属关系的短语</span><br><span class="line">&gt; &gt; ADVP：副词短语</span><br><span class="line">&gt; &gt; ADJP：形容词短语</span><br><span class="line">&gt; &gt; DP：限定词短语</span><br><span class="line">&gt; &gt; QP：量词短语</span><br><span class="line">&gt; &gt; NN：常用名词</span><br><span class="line">&gt; &gt; NR：固有名词</span><br><span class="line">&gt; &gt; NT：时间名词</span><br><span class="line">&gt; &gt; PN：代词</span><br><span class="line">&gt; &gt; VV：动词</span><br><span class="line">&gt; &gt; VC：是</span><br><span class="line">&gt; &gt; CC：表示连词</span><br><span class="line">&gt; &gt; VE：有</span><br><span class="line">&gt; &gt; VA：表语形容词</span><br><span class="line">&gt; &gt; AS：内容标记（如：了）</span><br><span class="line">&gt; &gt; VRD：动补复合词</span><br><span class="line">&gt; &gt; CD: 表示基数词</span><br><span class="line">&gt; &gt; DT: determiner 表示限定词</span><br><span class="line">&gt; &gt; EX: existential there 存在句</span><br><span class="line">&gt; &gt; FW: foreign word 外来词</span><br><span class="line">&gt; &gt; IN: preposition or conjunction, subordinating 介词或从属连词</span><br><span class="line">&gt; &gt; JJ: adjective or numeral, ordinal 形容词或序数词</span><br><span class="line">&gt; &gt; JJR: adjective, comparative 形容词比较级</span><br><span class="line">&gt; &gt; JJS: adjective, superlative 形容词最高级</span><br><span class="line">&gt; &gt; LS: list item marker 列表标识</span><br><span class="line">&gt; &gt; MD: modal auxiliary 情态助动词</span><br><span class="line">&gt; &gt; PDT: pre-determiner 前位限定词</span><br><span class="line">&gt; &gt; POS: genitive marker 所有格标记</span><br><span class="line">&gt; &gt; PRP: pronoun, personal 人称代词</span><br><span class="line">&gt; &gt; RB: adverb 副词</span><br><span class="line">&gt; &gt; RBR: adverb, comparative 副词比较级</span><br><span class="line">&gt; &gt; RBS: adverb, superlative 副词最高级</span><br><span class="line">&gt; &gt; RP: particle 小品词</span><br><span class="line">&gt; &gt; SYM: symbol 符号</span><br><span class="line">&gt; &gt; TO:”to” as preposition or infinitive marker 作为介词或不定式标记</span><br><span class="line">&gt; &gt; WDT: WH-determiner WH限定词</span><br><span class="line">&gt; &gt; WP: WH-pronoun WH代词</span><br><span class="line">&gt; &gt; WP$: WH-pronoun, possessive WH所有格代词</span><br><span class="line">&gt; &gt; WRB:Wh-adverb WH副词</span><br><span class="line">&gt; &gt; </span><br><span class="line">&gt; &gt; 关系表示</span><br><span class="line">&gt; &gt; abbrev: abbreviation modifier，缩写</span><br><span class="line">&gt; &gt; acomp: adjectival complement，形容词的补充；</span><br><span class="line">&gt; &gt; advcl : adverbial clause modifier，状语从句修饰词</span><br><span class="line">&gt; &gt; advmod: adverbial modifier状语</span><br><span class="line">&gt; &gt; agent: agent，代理，一般有by的时候会出现这个</span><br><span class="line">&gt; &gt; amod: adjectival modifier形容词</span><br><span class="line">&gt; &gt; appos: appositional modifier,同位词</span><br><span class="line">&gt; &gt; attr: attributive，属性</span><br><span class="line">&gt; &gt; aux: auxiliary，非主要动词和助词，如BE,HAVE SHOULD/COULD等到</span><br><span class="line">&gt; &gt; auxpass: passive auxiliary 被动词</span><br><span class="line">&gt; &gt; cc: coordination，并列关系，一般取第一个词</span><br><span class="line">&gt; &gt; ccomp: clausal complement从句补充</span><br><span class="line">&gt; &gt; complm: complementizer，引导从句的词好重聚中的主要动词</span><br><span class="line">&gt; &gt; conj : conjunct，连接两个并列的词。</span><br><span class="line">&gt; &gt; cop: copula。系动词（如be,seem,appear等），（命题主词与谓词间的）连系</span><br><span class="line">&gt; &gt; csubj : clausal subject，从主关系</span><br><span class="line">&gt; &gt; csubjpass: clausal passive subject 主从被动关系</span><br><span class="line">&gt; &gt; dep: dependent依赖关系</span><br><span class="line">&gt; &gt; det: determiner决定词，如冠词等</span><br><span class="line">&gt; &gt; dobj : direct object直接宾语</span><br><span class="line">&gt; &gt; expl: expletive，主要是抓取there</span><br><span class="line">&gt; &gt; infmod: infinitival modifier，动词不定式</span><br><span class="line">&gt; &gt; iobj : indirect object，非直接宾语，也就是所以的间接宾语；</span><br><span class="line">&gt; &gt; mark: marker，主要出现在有“that” or “whether”“because”, “when”,</span><br><span class="line">&gt; &gt; mwe: multi-word expression，多个词的表示</span><br><span class="line">&gt; &gt; neg: negation modifier否定词</span><br><span class="line">&gt; &gt; nn: noun compound modifier名词组合形式</span><br><span class="line">&gt; &gt; npadvmod: noun phrase as adverbial modifier名词作状语</span><br><span class="line">&gt; &gt; nsubj : nominal subject，名词主语</span><br><span class="line">&gt; &gt; nsubjpass: passive nominal subject，被动的名词主语</span><br><span class="line">&gt; &gt; num: numeric modifier，数值修饰</span><br><span class="line">&gt; &gt; number: element of compound number，组合数字</span><br><span class="line">&gt; &gt; parataxis: parataxis: parataxis，并列关系</span><br><span class="line">&gt; &gt; partmod: participial modifier动词形式的修饰</span><br><span class="line">&gt; &gt; pcomp: prepositional complement，介词补充</span><br><span class="line">&gt; &gt; pobj : object of a preposition，介词的宾语</span><br><span class="line">&gt; &gt; poss: possession modifier，所有形式，所有格，所属</span><br><span class="line">&gt; &gt; possessive: possessive modifier，这个表示所有者和那个’S的关系</span><br><span class="line">&gt; &gt; preconj : preconjunct，常常是出现在 “either”, “both”, “neither”的情况下</span><br><span class="line">&gt; &gt; predet: predeterminer，前缀决定，常常是表示所有</span><br><span class="line">&gt; &gt; prep: prepositional modifier</span><br><span class="line">&gt; &gt; prepc: prepositional clausal modifier</span><br><span class="line">&gt; &gt; prt: phrasal verb particle，动词短语</span><br><span class="line">&gt; &gt; punct: punctuation，这个很少见，但是保留下来了，结果当中不会出现这个</span><br><span class="line">&gt; &gt; purpcl : purpose clause modifier，目的从句</span><br><span class="line">&gt; &gt; quantmod: quantifier phrase modifier，数量短语</span><br><span class="line">&gt; &gt; rcmod: relative clause modifier相关关系</span><br><span class="line">&gt; &gt; ref : referent，指示物，指代</span><br><span class="line">&gt; &gt; rel : relative</span><br><span class="line">&gt; &gt; root: root，最重要的词，从它开始，根节点</span><br><span class="line">&gt; &gt; tmod: temporal modifier</span><br><span class="line">&gt; &gt; xcomp: open clausal complement</span><br><span class="line">&gt; &gt; xsubj : controlling subject 掌控者</span><br><span class="line">&gt; &gt; 中心语为谓词</span><br><span class="line">&gt; &gt; subj — 主语</span><br><span class="line">&gt; &gt; nsubj — 名词性主语（nominal subject） （同步，建设）</span><br><span class="line">&gt; &gt; top — 主题（topic） （是，建筑）</span><br><span class="line">&gt; &gt; npsubj — 被动型主语（nominal passive subject），专指由“被”引导的被动句中的主语，一般是谓词语义上的受事 （称作，镍）</span><br><span class="line">&gt; &gt; csubj — 从句主语（clausal subject），中文不存在</span><br><span class="line">&gt; &gt; xsubj — x主语，一般是一个主语下面含多个从句 （完善，有些）</span><br><span class="line">&gt; &gt; 中心语为谓词或介词</span><br><span class="line">&gt; &gt; obj — 宾语</span><br><span class="line">&gt; &gt; dobj — 直接宾语 （颁布，文件）</span><br><span class="line">&gt; &gt; iobj — 间接宾语（indirect object），基本不存在</span><br><span class="line">&gt; &gt; range — 间接宾语为数量词，又称为与格 （成交，元）</span><br><span class="line">&gt; &gt; pobj — 介词宾语 （根据，要求）</span><br><span class="line">&gt; &gt; lobj — 时间介词 （来，近年）</span><br><span class="line">&gt; &gt; 中心语为谓词</span><br><span class="line">&gt; &gt; comp — 补语</span><br><span class="line">&gt; &gt; ccomp — 从句补语，一般由两个动词构成，中心语引导后一个动词所在的从句(IP) （出现，纳入）</span><br><span class="line">&gt; &gt; xcomp — x从句补语（xclausal complement），不存在</span><br><span class="line">&gt; &gt; acomp — 形容词补语（adjectival complement）</span><br><span class="line">&gt; &gt; tcomp — 时间补语（temporal complement） （遇到，以前）</span><br><span class="line">&gt; &gt; lccomp — 位置补语（localizer complement） （占，以上）</span><br><span class="line">&gt; &gt; — 结果补语（resultative complement）</span><br><span class="line">&gt; &gt; 中心语为名词</span><br><span class="line">&gt; &gt; mod — 修饰语（modifier）</span><br><span class="line">&gt; &gt; pass — 被动修饰（passive）</span><br><span class="line">&gt; &gt; tmod — 时间修饰（temporal modifier）</span><br><span class="line">&gt; &gt; rcmod — 关系从句修饰（relative clause modifier） （问题，遇到）</span><br><span class="line">&gt; &gt; numod — 数量修饰（numeric modifier） （规定，若干）</span><br><span class="line">&gt; &gt; ornmod — 序数修饰（numeric modifier）</span><br><span class="line">&gt; &gt; clf — 类别修饰（classifier modifier） （文件，件）</span><br><span class="line">&gt; &gt; nmod — 复合名词修饰（noun compound modifier） （浦东，上海）</span><br><span class="line">&gt; &gt; amod — 形容词修饰（adjetive modifier） （情况，新）</span><br><span class="line">&gt; &gt; advmod — 副词修饰（adverbial modifier） （做到，基本）</span><br><span class="line">&gt; &gt; vmod — 动词修饰（verb modifier，participle modifier）</span><br><span class="line">&gt; &gt; prnmod — 插入词修饰（parenthetical modifier）</span><br><span class="line">&gt; &gt; neg — 不定修饰（negative modifier） (遇到，不)</span><br><span class="line">&gt; &gt; det — 限定词修饰（determiner modifier） （活动，这些）</span><br><span class="line">&gt; &gt; possm — 所属标记（possessive marker），NP</span><br><span class="line">&gt; &gt; poss — 所属修饰（possessive modifier），NP</span><br><span class="line">&gt; &gt; dvpm — DVP标记（dvp marker），DVP （简单，的）</span><br><span class="line">&gt; &gt; dvpmod — DVP修饰（dvp modifier），DVP （采取，简单）</span><br><span class="line">&gt; &gt; assm — 关联标记（associative marker），DNP （开发，的）</span><br><span class="line">&gt; &gt; assmod — 关联修饰（associative modifier），NP|QP （教训，特区）</span><br><span class="line">&gt; &gt; prep — 介词修饰（prepositional modifier） NP|VP|IP（采取，对）</span><br><span class="line">&gt; &gt; clmod — 从句修饰（clause modifier） （因为，开始）</span><br><span class="line">&gt; &gt; plmod — 介词性地点修饰（prepositional localizer modifier） （在，上）</span><br><span class="line">&gt; &gt; asp — 时态标词（aspect marker） （做到，了）</span><br><span class="line">&gt; &gt; partmod– 分词修饰（participial modifier） 不存在</span><br><span class="line">&gt; &gt; etc — 等关系（etc） （办法，等）</span><br><span class="line">&gt; &gt; 中心语为实词</span><br><span class="line">&gt; &gt; conj — 联合(conjunct)</span><br><span class="line">&gt; &gt; cop — 系动(copula) 双指助动词？？？？</span><br><span class="line">&gt; &gt; cc — 连接(coordination)，指中心词与连词 （开发，与）</span><br><span class="line">&gt; &gt; 其它</span><br><span class="line">&gt; &gt; attr — 属性关系 （是，工程）</span><br><span class="line">&gt; &gt; cordmod– 并列联合动词（coordinated verb compound） （颁布，实行）</span><br><span class="line">&gt; &gt; mmod — 情态动词（modal verb） （得到，能）</span><br><span class="line">&gt; &gt; ba — 把字关系</span><br><span class="line">&gt; &gt; tclaus — 时间从句 （以后，积累）</span><br><span class="line">&gt; &gt; — semantic dependent</span><br><span class="line">&gt; &gt; cpm — 补语化成分（complementizer），一般指“的”引导的CP （振兴，的）</span><br></pre></td></tr></table></figure>
<blockquote>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">```</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">###### 3.2.2 stanza</span><br><span class="line"></span><br><span class="line">github: &lt;https://github.com/stanfordnlp/stanza&gt;</span><br><span class="line"></span><br><span class="line">stanza同样是stanford发布的版本。</span><br><span class="line"></span><br><span class="line">1. 安装</span><br><span class="line"></span><br><span class="line">```shell</span><br><span class="line">pip install stanza</span><br></pre></td></tr></table></figure></blockquote>
</blockquote>
</li>
<li><p>下载模型</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> stanza</span><br><span class="line">stanza.download(<span class="string">&#x27;zh&#x27;</span>) </span><br></pre></td></tr></table></figure>

<p>我这里提供一份中文的模型包供大家下载。</p>
<p>链接: <a target="_blank" rel="noopener" href="https://pan.baidu.com/s/1hb9ATqpOGC9sHBHZ2hNdeg">https://pan.baidu.com/s/1hb9ATqpOGC9sHBHZ2hNdeg</a> 提取码: fqdm</p>
</li>
<li><p>测试代码</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> stanza</span><br><span class="line">nlp = stanza.Pipeline(<span class="string">&#x27;zh&#x27;</span>) <span class="comment"># This sets up a default neural pipeline in English</span></span><br><span class="line">doc = nlp(<span class="string">&quot;HanLP是一系列模型与算法组成的自然语言处理工具包，目标是普及自然语言处理在生产环境中的应用。&quot;</span>)</span><br><span class="line">doc.sentences[<span class="number">0</span>].print_dependencies()</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">(&#x27;HanLP&#x27;, &#x27;14&#x27;, &#x27;nsubj&#x27;)</span><br><span class="line">(&#x27;是&#x27;, &#x27;14&#x27;, &#x27;cop&#x27;)</span><br><span class="line">(&#x27;一&#x27;, &#x27;4&#x27;, &#x27;nummod&#x27;)</span><br><span class="line">(&#x27;系列&#x27;, &#x27;5&#x27;, &#x27;clf&#x27;)</span><br><span class="line">(&#x27;模型&#x27;, &#x27;8&#x27;, &#x27;nsubj&#x27;)</span><br><span class="line">(&#x27;与&#x27;, &#x27;7&#x27;, &#x27;cc&#x27;)</span><br><span class="line">(&#x27;算法&#x27;, &#x27;5&#x27;, &#x27;conj&#x27;)</span><br><span class="line">(&#x27;组成&#x27;, &#x27;14&#x27;, &#x27;acl:relcl&#x27;)</span><br><span class="line">(&#x27;的&#x27;, &#x27;8&#x27;, &#x27;mark:relcl&#x27;)</span><br><span class="line">(&#x27;自然&#x27;, &#x27;12&#x27;, &#x27;nmod&#x27;)</span><br><span class="line">(&#x27;语言&#x27;, &#x27;12&#x27;, &#x27;compound&#x27;)</span><br><span class="line">(&#x27;处&#x27;, &#x27;13&#x27;, &#x27;nmod&#x27;)</span><br><span class="line">(&#x27;理工&#x27;, &#x27;14&#x27;, &#x27;nsubj&#x27;)</span><br><span class="line">(&#x27;具包&#x27;, &#x27;0&#x27;, &#x27;root&#x27;)</span><br><span class="line">(&#x27;，&#x27;, &#x27;14&#x27;, &#x27;punct&#x27;)</span><br><span class="line">(&#x27;目标&#x27;, &#x27;17&#x27;, &#x27;nsubj&#x27;)</span><br><span class="line">(&#x27;是&#x27;, &#x27;14&#x27;, &#x27;parataxis&#x27;)</span><br><span class="line">(&#x27;普及&#x27;, &#x27;17&#x27;, &#x27;xcomp&#x27;)</span><br><span class="line">(&#x27;自然&#x27;, &#x27;20&#x27;, &#x27;nmod&#x27;)</span><br><span class="line">(&#x27;语言&#x27;, &#x27;21&#x27;, &#x27;nsubj&#x27;)</span><br><span class="line">(&#x27;处理&#x27;, &#x27;18&#x27;, &#x27;ccomp&#x27;)</span><br><span class="line">(&#x27;在&#x27;, &#x27;27&#x27;, &#x27;det&#x27;)</span><br><span class="line">(&#x27;生产&#x27;, &#x27;24&#x27;, &#x27;nmod&#x27;)</span><br><span class="line">(&#x27;环境&#x27;, &#x27;22&#x27;, &#x27;nmod&#x27;)</span><br><span class="line">(&#x27;中&#x27;, &#x27;24&#x27;, &#x27;acl&#x27;)</span><br><span class="line">(&#x27;的&#x27;, &#x27;22&#x27;, &#x27;case:dec&#x27;)</span><br><span class="line">(&#x27;应用&#x27;, &#x27;18&#x27;, &#x27;obj&#x27;)</span><br><span class="line">(&#x27;。&#x27;, &#x27;14&#x27;, &#x27;punct&#x27;)</span><br></pre></td></tr></table></figure></li>
</ol>
<h5 id="3-3-HaNLP"><a href="#3-3-HaNLP" class="headerlink" title="3.3 HaNLP"></a>3.3 HaNLP</h5><p>官网：<a target="_blank" rel="noopener" href="http://hanlp.linrunsoft.com/">http://hanlp.linrunsoft.com/</a></p>
<p>在线演示：<a target="_blank" rel="noopener" href="http://hanlp.com/">http://hanlp.com/</a></p>
<h6 id="3-3-1-pyhanlp-hanlp1-x"><a href="#3-3-1-pyhanlp-hanlp1-x" class="headerlink" title="3.3.1 pyhanlp(hanlp1.x)"></a>3.3.1 pyhanlp(hanlp1.x)</h6><p>Github地址：<a target="_blank" rel="noopener" href="https://github.com/hankcs/pyhanlp">https://github.com/hankcs/pyhanlp</a></p>
<ol>
<li><p>安装</p>
<blockquote>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install pyhanlp</span><br></pre></td></tr></table></figure></blockquote>
</li>
<li><p>下载数据包</p>
<p>data：链接: <a target="_blank" rel="noopener" href="https://pan.baidu.com/s/169Fgb6vhfsx10O2xEomY1Q">https://pan.baidu.com/s/169Fgb6vhfsx10O2xEomY1Q</a> 提取码: r4zv</p>
<p>将下载的数据包解压至%python_lib%/site-packages/pyhanlp/static文件夹。我这里提供的是1.7.5版本，同样支持1.7.7版本的pyhanlp。</p>
<p>默认会自动下载相关的jar包。</p>
</li>
<li><p>测试代码</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyhanlp <span class="keyword">import</span> HanLP</span><br><span class="line">    <span class="built_in">print</span>(HanLP.parseDependency(<span class="string">&quot;HanLP是一系列模型与算法组成的自然语言处理工具包，目标是普及自然语言处理在生产环境中的应用&quot;</span>))</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">1	HanLP	HanLP	ws	nx	_	2	主谓关系	_	_</span><br><span class="line">2	是	是	v	v	_	0	核心关系	_	_</span><br><span class="line">3	一系列	一系列	n	n	_	4	定中关系	_	_</span><br><span class="line">4	模型	模型	n	n	_	7	主谓关系	_	_</span><br><span class="line">5	与	与	p	p	_	7	状中结构	_	_</span><br><span class="line">6	算法	算法	n	n	_	5	介宾关系	_	_</span><br><span class="line">7	组成	组成	v	v	_	10	定中关系	_	_</span><br><span class="line">8	的	的	u	u	_	7	右附加关系	_	_</span><br><span class="line">9	自然语言处理	自然语言处理	nz	nz	_	10	定中关系	_	_</span><br><span class="line">10	工具包	工具包	n	n	_	2	动宾关系	_	_</span><br><span class="line">11	，	，	wp	w	_	2	标点符号	_	_</span><br><span class="line">12	目标	目标	n	n	_	13	主谓关系	_	_</span><br><span class="line">13	是	是	v	v	_	2	并列关系	_	_</span><br><span class="line">14	普及	普及	v	v	_	13	动宾关系	_	_</span><br><span class="line">15	自然语言处理	自然语言处理	nz	nz	_	19	主谓关系	_	_</span><br><span class="line">16	在	在	p	p	_	19	状中结构	_	_</span><br><span class="line">17	生产环境	生产环境	n	n	_	16	介宾关系	_	_</span><br><span class="line">18	中的	中的	v	v	_	19	状中结构	_	_</span><br><span class="line">19	应用	应用	v	vn	_	14	动宾关系	_	_</span><br></pre></td></tr></table></figure></li>
</ol>
<h6 id="3-3-2-hanlp2-0"><a href="#3-3-2-hanlp2-0" class="headerlink" title="3.3.2 hanlp2.0"></a>3.3.2 hanlp2.0</h6><ol>
<li><p>安装</p>
<blockquote>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install hanlp</span><br></pre></td></tr></table></figure>
</blockquote>
<p>hanlp2.0是基于tensorflow2.1训练的网络模型，线上提供了很多训练好的预训练模型，问题在于基本上不可能自动下载成功，需要手动下载模型并存放到相应的位置。</p>
</li>
<li><p>查看已经提供的模型</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> hanlp</span><br><span class="line"><span class="keyword">for</span> k,v <span class="keyword">in</span> hanlp.pretrained.ALL.items():</span><br><span class="line">    <span class="built_in">print</span>(k, v)</span><br></pre></td></tr></table></figure></li>
<li><p>测试代码</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">tokenizer = hanlp.load(<span class="string">&#x27;CTB6_CONVSEG&#x27;</span>)</span><br><span class="line">tagger = hanlp.load(<span class="string">&#x27;CTB5_POS_RNN&#x27;</span>)</span><br><span class="line">syntactic_parser = hanlp.load(<span class="string">&#x27;CTB7_BIAFFINE_DEP_ZH&#x27;</span>)</span><br><span class="line"></span><br><span class="line">pipeline = hanlp.pipeline() \</span><br><span class="line">.append(hanlp.utils.rules.split_sentence, output_key=<span class="string">&#x27;sentences&#x27;</span>) \</span><br><span class="line">.append(tokenizer, output_key=<span class="string">&#x27;tokens&#x27;</span>) \</span><br><span class="line">.append(tagger, output_key=<span class="string">&#x27;part_of_speech_tags&#x27;</span>) \</span><br><span class="line">.append(syntactic_parser, input_key=(<span class="string">&#x27;tokens&#x27;</span>, <span class="string">&#x27;part_of_speech_tags&#x27;</span>), output_key=<span class="string">&#x27;syntactic_dependencies&#x27;</span>,</span><br><span class="line">        conll=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">text = <span class="string">&#x27;HanLP是一系列模型与算法组成的自然语言处理工具包，目标是普及自然语言处理在生产环境中的应用&#x27;</span></span><br><span class="line"></span><br><span class="line">doc = pipeline(text)</span><br><span class="line">tokens = doc.tokens[<span class="number">0</span>]</span><br><span class="line">pos = doc.part_of_speech_tags[<span class="number">0</span>]</span><br><span class="line">dependencies = doc.syntactic_dependencies[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(tokens)):</span><br><span class="line">    <span class="built_in">print</span>(i, tokens[i], pos[i], dependencies[i][<span class="number">0</span>], dependencies[i][<span class="number">1</span>])</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">0 HanLP NN 2 top</span><br><span class="line">1 是 VC 0 root</span><br><span class="line">2 一系列 NN 6 nn</span><br><span class="line">3 模型 NN 6 conj</span><br><span class="line">4 与 CC 6 cc</span><br><span class="line">5 算法 NN 7 nsubj</span><br><span class="line">6 组成 VV 10 rcmod</span><br><span class="line">7 的 DEC 7 cpm</span><br><span class="line">8 自然 NN 10 nn</span><br><span class="line">9 语言 NN 11 nsubj</span><br><span class="line">10 处理 VV 2 ccomp</span><br><span class="line">11 工具包 PU 11 punct</span><br><span class="line">12 ， PU 2 punct</span><br><span class="line">13 目标 NN 15 top</span><br><span class="line">14 是 VC 2 conj</span><br><span class="line">15 普及 VV 15 ccomp</span><br><span class="line">16 自然 NN 18 nn</span><br><span class="line">17 语言 NN 16 dobj</span><br><span class="line">18 处理 VV 16 conj</span><br><span class="line">19 在 P 25 assmod</span><br><span class="line">20 生产 NN 22 nn</span><br><span class="line">21 环境 NN 23 lobj</span><br><span class="line">22 中 LC 20 plmod</span><br><span class="line">23 的 DEG 20 assm</span><br><span class="line">24 应用 NN 19 dobj</span><br></pre></td></tr></table></figure></li>
</ol>
<h4 id="4-数据集"><a href="#4-数据集" class="headerlink" title="4. 数据集"></a>4. 数据集</h4><ul>
<li><p>Penn Treebank</p>
<p>Penn Treebank是一个项目的名称，项目目的是对语料进行标注，标注内容包括词性标注以及句法分析。</p>
</li>
<li><p>SemEval-2016 Task 9</p>
<p>中文语义依存图数据：<a target="_blank" rel="noopener" href="http://ir.hit.edu.cn/2461.html">http://ir.hit.edu.cn/2461.html</a></p>
<p>下载地址：<a target="_blank" rel="noopener" href="https://github.com/HIT-SCIR/SemEval-2016">https://github.com/HIT-SCIR/SemEval-2016</a></p>
</li>
<li><p>evsam05</p>
<p>链接: <a target="_blank" rel="noopener" href="https://pan.baidu.com/s/1cFQBNcd-HnuTPUlGT7h9wg">https://pan.baidu.com/s/1cFQBNcd-HnuTPUlGT7h9wg</a> 提取码: tjdx </p>
</li>
<li><p>CoNLL任务</p>
<ul>
<li><a target="_blank" rel="noopener" href="http://universaldependencies.org/conll18/">http://universaldependencies.org/conll18/</a></li>
<li><a target="_blank" rel="noopener" href="http://ufal.mff.cuni.cz/conll2009-st/">http://ufal.mff.cuni.cz/conll2009-st/</a></li>
<li><a target="_blank" rel="noopener" href="https://www.clips.uantwerpen.be/conll2008/">https://www.clips.uantwerpen.be/conll2008/</a></li>
<li><a target="_blank" rel="noopener" href="https://www.clips.uantwerpen.be/conll2007/">https://www.clips.uantwerpen.be/conll2007/</a></li>
</ul>
</li>
</ul>
<h4 id="5-可视化工具"><a href="#5-可视化工具" class="headerlink" title="5. 可视化工具"></a>5. 可视化工具</h4><ol>
<li><p>conllu.js</p>
<p><a target="_blank" rel="noopener" href="https://github.com/spyysalo/conllu.js">https://github.com/spyysalo/conllu.js</a></p>
</li>
<li><p>DependencyViewer.exe </p>
<p><a target="_blank" rel="noopener" href="http://nlp.nju.edu.cn/tanggc/tools/DependencyViewer.html">http://nlp.nju.edu.cn/tanggc/tools/DependencyViewer.html</a></p>
</li>
</ol>
<p>参考：</p>
<p><a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s/AP4TCnRfIccqAxDu4FlBew">https://mp.weixin.qq.com/s/AP4TCnRfIccqAxDu4FlBew</a></p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2021/07/20/%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1%E6%A6%82%E8%BF%B0/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="sunshine">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="浮生物语的博客">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2021/07/20/%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1%E6%A6%82%E8%BF%B0/" class="post-title-link" itemprop="url">知识图谱概述</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>
              

              <time title="创建时间：2021-07-20 00:00:00 / 修改时间：10:15:48" itemprop="dateCreated datePublished" datetime="2021-07-20T00:00:00+08:00">2021-07-20</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h4 id="1-知识图谱概述与架构"><a href="#1-知识图谱概述与架构" class="headerlink" title="1. 知识图谱概述与架构"></a>1. 知识图谱概述与架构</h4><h5 id="1-1-web发展路线"><a href="#1-1-web发展路线" class="headerlink" title="1.1 web发展路线"></a>1.1 web发展路线</h5><ul>
<li>web 1.0时代：文档互联</li>
<li>web 2.0 时代：数据互联</li>
<li>web 3.0时代：知识互联，知识图谱强大的语义理解和开放互联能力为基础</li>
</ul>
<p>RDF（resource description framework）和OWL（web ontology language），基于使用本体模式来形式化的表达数据中的隐含语义的目的。知识图谱是基于语义网的相关研究，是对语义网标准与技术的一次扬弃与升华。</p>
<h5 id="1-2-知识图谱"><a href="#1-2-知识图谱" class="headerlink" title="1.2 知识图谱"></a>1.2 知识图谱</h5><p>   知识图谱2015年，goole为解决收索引擎的能力，增强用户的搜索质量与体验，正是提出知识图谱。目前已广泛用于智能搜索，智能问答，个性化推荐等领域。</p>
<ul>
<li><p>定义</p>
<p> 狭义的讲（维基百科）,知识图谱是google用于增强其搜索功能的知识库。本质上讲，知识图谱是一种揭示实体之间关系的语义网络，对现实世界的事物以及相互关系进行形式化的描述。目前的知识图谱广泛的指各大规模的知识库。</p>
</li>
<li><p>表示</p>
<ul>
<li><p>三元组：$G=(E, R, S)$</p>
<ul>
<li>$E={e_{1}, e_{2}, … e_{n}}$ 是知识库中实体集合。</li>
<li>$R={r_{1}, r_{2}, … r_{n}}$ 是知识库中的关系集合。</li>
<li>$S ={ r | r \in E × R × E}$ 代表知识库中三元组集合</li>
</ul>
</li>
<li><p>三元组的基本形式</p>
<ul>
<li><p>实体：知识图谱中的最基本元素</p>
</li>
<li><p>关系：连接两个实体，刻画它们之间的联系</p>
</li>
<li><p>概念：主要指集合、类别、对象类型、事物的种类。例如：人物、地理等</p>
</li>
<li><p>属性：对象可能具有的属性、特征、特点、参数等。例如：国籍、姓名、生日等。</p>
</li>
<li><p>属性值：对象属性的值。</p>
<p>每个实体（概念的外延）可用全局唯一确定的ID来标识，属性对（attribute-value par, AVP）用来刻画实体的内在特性。</p>
</li>
</ul>
</li>
</ul>
</li>
<li><p>分类</p>
<ul>
<li>通用知识图谱：注重广度，覆盖行业多，范围大，但准确度不够高。主要应用与智能搜索。</li>
<li>行业知识图谱（垂直领域）：依靠特定行业的数据来构建，具有特定的行业意义。专业性较强。</li>
</ul>
</li>
<li><p>知识图谱架构</p>
<ul>
<li><p>逻辑结构</p>
<ul>
<li>模式层： 构建于数据层之上，通过本体库来规范数据层的一些列事实表达。</li>
<li>数据层：事实数据，知识以事实为单位存储。常用的图数据库有：Neo4j， gStore， Twitter的FlockDB， sones的GraphDB等。</li>
<li>本体：本体是结构化知识库的概率模板。层次结构强，冗余程度小。</li>
</ul>
</li>
<li><p>体系结构</p>
<p> 知识图谱的体系结构指构建模式。如下图所示。</p>
<pre><code>![1577761955307](./1577761955307.png)
</code></pre>
<ul>
<li>自顶向下(top-down)：先定义本体与数据模式，再将实体加入到知识库。例如：Freebase。</li>
<li>自底向上(bottom-up)：从一些开放链路数据中提取实体，选择置信度较高的实体加入知识库，最后再构建本体模式。目前，大多数采用自底向上的模式构建知识图谱，典型的有Google的Knowledge Vault。</li>
</ul>
</li>
</ul>
</li>
</ul>
<h4 id="2-大规模知识库"><a href="#2-大规模知识库" class="headerlink" title="2. 大规模知识库"></a>2. 大规模知识库</h4><h5 id="2-1-开放链接知识库"><a href="#2-1-开放链接知识库" class="headerlink" title="2.1 开放链接知识库"></a>2.1 开放链接知识库</h5><ul>
<li><p>Freebase：Metaweb(创建)-&gt;Google（收购）。Freebase在人工构建的基础上，融合了维基百科、IMDB、Flick等语料库。截止2014年底，Freebase包含6800万实体，10亿条关系信息，24亿条事实三元组信息。2015年6月，Freebase整体移入WikiData。</p>
</li>
<li><p>Wikidata：维基媒体基金会主持的一个自由的协作式多语言辅助知识库。Wikidata中的数据主要以文档的形式进行存储，目前已包含了超过1 700万个文档。其中的每个文档都有一个主题或一个管理页面，且被唯一的数字标识。</p>
</li>
<li><p>DBpedia：DBpedia[18]是由德国莱比锡大学和曼海姆大学的科研人员创建的多语言综合型知识库，在LOD项目中处于最核心的地位。截止至2014年年底，DBpedia中的事实三元组 数量已经超过了30亿条。</p>
</li>
<li><p>YAGO：YAGO[19]是由德国马普所(max planck institute，MPI)的科研人员构建的综合型知识库。YAGO整合了维基百科、WordNet以及GeoNames等数据源。2012年发布的第二版本，包含了超过1000万的实体以及超过1.2亿的事实。</p>
</li>
</ul>
<h5 id="2-2-垂直行业知识库"><a href="#2-2-垂直行业知识库" class="headerlink" title="2.2 垂直行业知识库"></a>2.2 垂直行业知识库</h5><ul>
<li><p>IMDB：关于电影、演员、电视节目的知识库。截止到2012年2月，IMDB共收集了2 132 383部作品资料和4 530 159名人物资料。</p>
<pre><code>  MusicBrainz：一个结构化的音乐维基百科，致力于收藏所有的音乐元数据，并向大众用户开放。
</code></pre>
</li>
<li><p>ConceptNet：语义知识网络。与链路数据和Google知识图谱相比，ConceptNet更加侧重与词与词的关系。ConceptNet完全免费开放，并支持多种语言。</p>
</li>
</ul>
<h4 id="3-知识图谱的关键技术"><a href="#3-知识图谱的关键技术" class="headerlink" title="3. 知识图谱的关键技术"></a>3. 知识图谱的关键技术</h4><h5 id="3-1-知识抽取"><a href="#3-1-知识抽取" class="headerlink" title="3.1 知识抽取"></a>3.1 知识抽取</h5><p>知识抽取主要面向开放的链接数据，通过自动化技术抽取出可用的知识单元，知识单元包括：实体、关系、属性。</p>
<ul>
<li><p>实体抽取（NER）</p>
<ul>
<li>基于规则和词典</li>
<li>基于统计机器学习：隐马尔科夫模型（HMM）、条件马尔科夫模型（CMM）、最大熵模型（MaxEnt）、条件随机场（CRF）。</li>
<li>基于深度学习：LSTM+CRF、LSTM+CNNs+CRF、 BERT、Attention</li>
</ul>
</li>
<li><p>关系抽取</p>
<p>目标在于解决实体间语义链接的问题，早期的关系抽取主要是通过构造人工语义规则和模板，发展至今，实体间的关系模型成为主流抽取方法。</p>
<ul>
<li><p>基于模板：二元开放式  vs  n元开放式</p>
</li>
<li><p>基于监督学习</p>
<p>基于监督学习的关系抽取方法核心在于将关系抽取转化为分类问题。在大量标注数据的基础上，训练监督模型进行关系抽取，一般步骤如下：a. 预定义关系类型， b. 人工标注数据 c. 设计关系识别所需要的特征 d. 选择分类模型 e. 训练模型</p>
<p>传统的基于监督学习的关系抽取严重依赖与特征工程，而深度学习的方法自动学习特征，不再需要人工构建各种特征，大大简化了人工操作。</p>
<ul>
<li><p>基于深度学习流水线的关系抽取方法</p>
<p>CR-CNN模型、Attention CNNs模型、Attention BLSTM模型 …</p>
</li>
<li><p>基于深度学习的联合关系抽取方法</p>
</li>
</ul>
</li>
<li><p>基于若监督学习的关系抽取方法</p>
<p>监督学习需要大量的标注预料，当预料不足时，弱监督学习可以只利用少量标注数据进行模型学习。</p>
<ul>
<li><p>远程监督方法</p>
<p>远程监督方法通过讲知识图谱与非机构化文本对齐的方式自动构建大量的训练预料，减少模型对人工标注训练数据的依赖。远程监督的基本假设是如果两个实体在知识图谱中存在某种关系，则包含两个实体的句子均表达了这种关系。例如：在某知识图谱中存在实体关系创始人（乔布斯，苹果公司），那么，包含实体乔布斯和苹果公司的句子“乔布斯是苹果公司的联合创始人和CEO” 可以被用作关系创始人的训练正例。远程监督的一般步骤为：</p>
<ol>
<li>从知识图谱中抽取存在的目标关系的实体对</li>
<li>从非机构化文本中抽取包含实体对的句子作为训练样例</li>
<li>训练监督学习模型进行关系抽取</li>
</ol>
</li>
<li><p>Bootstrapping方法</p>
<p>Boostrapping方法利用少量的实例作为初始种子集合，然后在种子集合上学习关系抽取的模板，再利用模板抽取更多的实例，加入种子集合中，通过不断的迭代，Boostrapping可以从文本中抽取关系的大量实例。</p>
</li>
</ul>
</li>
</ul>
</li>
<li><p>属性抽取</p>
<p>针对实体而言，通过属性形成对实体的完整刻画。实体的属性抽取可以转化为关系抽取问题。</p>
</li>
<li><p>事件抽取</p>
<p>事件抽取指从自然语言中抽取出用户感兴趣的事件信息，并以结构化的形式呈现出来。事件指发生的事件，通常具有时间、地点、参与者等属性。事件的发生可能因为一个动作的产生或者系统状态的改变。一般地，事件抽取任务包含的子任务有:</p>
<ul>
<li>识别事件触发词及事件类型</li>
<li>识别事件元素同时判断其角色</li>
<li>抽取描述事件的词或者句子</li>
<li>事件属性标注</li>
<li>事件共指消解</li>
</ul>
<p>同样的，事件抽取可分为以下两类：</p>
<ul>
<li><p>基于流水线的事件抽取</p>
<p>流水线方法将事件抽取任务划分为一系列基于分类的子任务，每个子任务由一个机器学习器负责实施。</p>
</li>
<li><p>联合抽取</p>
<p>流水线方法存在误差传递问题，导致误差不断积累，事件抽取性能急剧衰减。在联合抽取方法中，事件的所有相关信息会通过一个模型同时抽取出来。</p>
<ul>
<li>联合推断：建立事件抽取子任务的模型，然后将各个模型的目标函数进行组合，形成联合推断的目标函数，通过对联合目标函数的优化，获得事件抽取各个子任务的结果。</li>
<li>在充分分析子任务之间的关系之后，基于概率图模型进行联合建模，获得事件抽取的总体结果。</li>
</ul>
</li>
</ul>
</li>
</ul>
<h5 id="3-2-知识表示"><a href="#3-2-知识表示" class="headerlink" title="3.2 知识表示"></a>3.2 知识表示</h5><pre><code> 知识表示主要有两种：基于离散符号的知识表示和基于连续向量的知识表示方法
</code></pre>
<p>​    基于离散符号化的表示方法可以很有效的将数据结构化，节点对应着三元组的头实体和尾实体，边对应着三元组的关系。但是它并不能在计算机中表达相应的语义层面的信息，也不能进行语义计算。</p>
<ul>
<li><p>基于离散符号的知识表示</p>
<p>随着语义网的发展，早期web的标准语言HTML和XML无法适应语义网对知识表示的要求，W3C提出了新的标准语言：RDF、RDFS和OWL</p>
<ul>
<li><p>RDF</p>
<p>知识总是以三元组的形式出现，表示为：（subject，predicate，object）。例如：“IBM邀请Jeff Pan作为讲者，演讲主题是知识图谱”，可以以下RDF三元组：（IBM-Talk，speaker，Jeff），（IBM-Talk，theme，KG）。</p>
<p>RDF中的主语是一个个体，个体是类的实例。谓语是一个属性。宾语可以是一个个体，如（IBM-Talk，speaker，Jeff），也可以是一个数据类型的实例，例如：（IBM-Talk，TalkDate，“05-10-2012”^xsd:date）</p>
</li>
<li><p>RDFS</p>
<p>RDFS在RDF的基础上定义了类和属性的模式，RDF Schema(简称  RDFS)提供了对类和属性的简单描述。</p>
<p>RDFS提供了最基本的对类和属性的描述原语：</p>
<ul>
<li>rdf:type： 用于指定个体的类</li>
<li>rdfs:subClassOf：指定父类</li>
<li>rdfs:subPropertyOf：属性的父属性</li>
<li>rdfs:domain：属性的定义域</li>
<li>rdfs:range：属性的值域</li>
</ul>
</li>
<li><p>OWL</p>
<p>相对于RDF和RDFS，OWL能够表达更丰富的信息，应用与更加复杂的场景。OWL的常见词汇有：</p>
<ul>
<li><p>等价性声明：声明两个类、属性、实例是等价的。例如：exp:运动员 owl:equivalentClass exp:体育选手；exp:获得 owl:equivalentProperty exp:取得;exp:运动员 A owl:sameIndividualAs exp:小明</p>
</li>
<li><p>属性传递声明：声明一个属性是传递关系，例如：exp:ancestor rdf:type owl:TransitiveProperty 指的是exp:ancestor是一个传递关系。</p>
</li>
<li><p>属性互逆声明：声明两个属性有互逆的关系，owl:inverseOf</p>
</li>
<li><p>属性的函数性声明：声明一个属性是函数。例如：exp:hasMother rdf:type owl:FunctionalProperty 指的是exp:hasmother是一个函数，即一个生物只有一个母亲。</p>
</li>
<li><p>属性的对称性声明：声明一个属性是对称的。owl:SymmetricProperty</p>
</li>
<li><p>属性的全称限定声明：声明一个属性是全称限定的。例如：</p>
<blockquote>
<p>exp:Person owl:allValuesFrom exp:Woman </p>
</blockquote>
<blockquote>
<p>exp:Person owl:onProperty exp:hasMother</p>
</blockquote>
<p>   上诉说明exp:haMother在主语exp:Person类的条件下，宾语的取值只能来自于exp:Women类。</p>
</li>
<li><p>属性的存在限定声明。例如：</p>
<blockquote>
<p>exp:SemanticWebPaper owl:someValuesFrom exp:AAAI</p>
<p>exp:SemanticWebPaper owl:onProperty exp:publishedIn</p>
</blockquote>
<p>上诉表明，exp:publishedIn的取值部分来自于exp:AAAI</p>
</li>
<li><p>属性的基数限定声明：声明一个属性的基数，例如：</p>
<blockquote>
<p>exp:Person owl:cardinality “1”^^xsd:integer</p>
<p>exp:Person owl:onProperty exp:hasMother</p>
</blockquote>
<p>上述表明，exp:hasMother在主语属于exp:person类的条件下，宾语的取值只能有一个，“1”的数据类型被声明为xsd:integer。</p>
</li>
<li><p>相交的类声明：声明一个类是等价与两个类相交。例如:</p>
<blockquote>
<p>exp:Mother owl:intersectionOf _tmp</p>
<p>_tmp rdf:type rdfs:Collection</p>
<p>_tmp rdfs:member exp:Person</p>
<p>_tmp:rdfs:member exp:HasChildren</p>
</blockquote>
<p>上述说明，exp:Mother是exp:Person和exp:HasChildren两个类的交集。</p>
</li>
</ul>
</li>
</ul>
</li>
<li><p>连续向量的表示方法</p>
<p>KG embedding主要是将KG中实体与关系隐射到一个低维的向量空间。KG embedding也是通过机器学习的方法对模型进行学习，与one-hot、word2vec的最大区别在于，它需要进行监督学习。</p>
<ul>
<li><p>转移距离模型（Translation Distance Model）</p>
<p>transD模型的主要思想是讲衡量向量化的知识图谱中三元组的合理性问题，转化为衡量头实体和尾实体的距离问题。核心在于如何设计得分函数，得分函数通常被设计成利用关系把头实体转移到尾实体的合理性的函数。</p>
<p>TransE受到词向量中平移不变性的启发，把实体和关系表示成向量，对某一个具体的关系(h, r, t)，把关系的向量表示解释成头实体的向量到尾实体的向量的转移向量，即满足关系$h+r \approx t$关系。</p>
<p>$$<br>vec(Rome)+vec(is-capital-of) \approx vec(Italy)<br>$$</p>
</li>
<li><p>语义匹配模型（Semantic Matching Models）</p>
<p>语义匹配模型更加注重挖掘向量化后的实体和关系的潜在语义，该方向上的模型主要是RESCAL以及它的延伸模型。</p>
<p>在RESCAL模型中，知识库中的三元组(h,r,t)集合被表示为一个三阶张量，该张量可以分解为一个核心张量和一个因子矩阵，核心张量中的每个二维矩阵切片代表一个关系，因子矩阵中的每一行代表一个实体。三阶张量中的值表示对应三元组成立的概率，如果概率大于某个阈值，则三元组成立，否则不成立。其得分函数如下：<br>$$<br>f_{r}(h,t)=h^{T}M_{r}t=\sum_{i=0}^{d-1}\sum_{j=0}^{d-1}[M_{r}]<em>{ij}\cdot[h]</em>{i}\cdot[r]_{j}<br>$$</p>
</li>
<li><p>考虑附加信息的模型</p>
<p>除了仅仅依靠知识图谱中的三元组构造KG embedding的模型，还有一些模型考虑额外的附加信息进行提升。</p>
<p>通常考虑的附加信息有：实体类型、关系路劲、文本描述、逻辑规则等。</p>
</li>
</ul>
</li>
</ul>
<h5 id="3-3-知识融合"><a href="#3-3-知识融合" class="headerlink" title="3.3 知识融合"></a>3.3 知识融合</h5><p>​    知识图谱中的知识来源广泛，存在着数据质量良莠不齐、来源于不同数据源的知识重复、知识间的关联不够明确等问题。</p>
<p>​    知识融合是高层次的知识组织，使来自不同知识源的知识在同一框架规范下进行异构数据整合、消歧、加工、推理验证、更新等步骤，形成高质量的知识库。</p>
<ol>
<li><p>实体对齐</p>
<p>实体对齐又称为实体匹配，主要目的在于消除异构数据中实体冲突、指向不明等不一致性问题。</p>
<p>实体对齐主要面临以下几个挑战：</p>
<ul>
<li>计算复杂度：匹配算法的计算复杂度会随着知识库的规模呈二次增长。</li>
<li>数据质量：不同知识库的数据质量良莠不齐。</li>
<li>先验训练数据：难以获取先验数据，大部分情况下，只能手动构造。</li>
</ul>
<p>知识库实体对齐的主要流程如下：</p>
<ol>
<li>将待对齐数据进行分区索引</li>
<li>利用相似度函数或者相似算法查找匹配实例</li>
<li>使用实体对齐算法进行实例融合</li>
<li>将步骤2和步骤3结合，形成最终的对齐结果</li>
</ol>
<p>知识融合主要分为：本体对齐、实体对齐。两者的基本流程大致相似，如下所示：</p>
<p><img src="https://gitee.com/fushengwuyu1993/images/raw/master/imgs/1578539136186.png" alt="1578539136186"></p>
<ul>
<li><p>数据预处理</p>
<p>数据预处理阶段，原始数据的质量会直接影响到最终链接的结果，不同的数据集对同一实体的描述方式往往是不相同的，对这些数据进行归一化是提高后续链接精确度的重要步骤</p>
<ul>
<li>语法正规化<ul>
<li>语法匹配：如联系电话的表示方法</li>
<li>综合属性：如家庭地址的表达方法</li>
</ul>
</li>
<li>数据正规化<ul>
<li>移除空格、{}等符号</li>
<li>用正式名字替换昵称和缩写等</li>
</ul>
</li>
</ul>
</li>
<li><p>分块</p>
<p>分块是从给定的知识库中的所有实体对中，选出潜在匹配的记录对作为候选项，尽可能的缩小候选项，减少数据量、</p>
<p>Hash函数的分块</p>
<ul>
<li><p>给定记录$x$，$hash(x)=h_{i}$ 则x映射到关键字$h_{i}$ 绑定的块$C_{i}$ 上。</p>
</li>
<li><p>近邻分块</p>
<p>canopy聚类、排序邻居算法、Red-Blue Set Cover等</p>
</li>
</ul>
</li>
<li><p>负载均衡</p>
<p>负载均衡 (Load Balance)来保证所有块中的实体数目相当,从而保证分块对性能的提升程度。最简单的方法是多次Map-Reduce操作。</p>
</li>
<li><p>记录链接</p>
<p>假定两个实体$X={x_{0}, x_{1},…,x_{n}} ，Y={y_{0}, y_{1},…,y_{n}}$ ，$x_{i}$是实体X第$i$个属性的值。</p>
<ul>
<li><p>属性相似度</p>
<p>综合单个属性相似度得到属性相似度向量：<br>$$<br>[sim(x_{1},y_{1}),sim(x_{2},y_{2}),…,sim(x_{n},y_{n})]<br>$$<br>属性相似度的计算方式通常有以下几类：</p>
<ul>
<li>编辑距离：最小编辑距离(Levenstein)、Wagner and Fisher Distance、Edit Distance with affine gaps</li>
<li>集合相似度计算：Dice系数、Jaccard系数</li>
<li>基于向量的相似度计算：TF-IDF</li>
</ul>
</li>
<li><p>实体相似度</p>
<p>根据属性相似度向量得到一个实体的相似度。计算实体相似度方法主要有以下三大类。</p>
<ul>
<li><p>聚合</p>
<ul>
<li><p>加权平均</p>
<p>对相似度向量各个分量加权求和，得到最终的实体相似度:<br>$$<br>S = w_{1}\ast sim(x_{1}, y_{1}) +…+w_{n} \ast sim(x_{n}, y_{n})<br>$$</p>
</li>
<li><p>规则</p>
<p>可以为每个相似度分量设置一个阈值，若果超过改阈值则将两实体融合。<br>$$<br>sim(x_{1}, y_{1}) &gt;T_{1} and(or) … sim(x_{n}, y_{n}) &gt;T_{n}<br>$$</p>
</li>
<li><p>分类器</p>
<p>常用的分类模型，但存在最大问题在于如何生成训练集合。</p>
</li>
</ul>
</li>
<li><p>聚类</p>
<ul>
<li>层次聚类</li>
<li>相关性聚类</li>
<li>Canopy + Kmeans</li>
</ul>
</li>
<li><p>表示学习：知识嵌入</p>
<p>将知识图谱中的实体和关系都隐射到低维向量空间，直接用距离公式来计算各个实体间的相似度。这种方法不依赖任何的问题信息，直接提取数据的深度特征。</p>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><p>质量评估</p>
<p>​    对知识库的质量评估通常和实体对齐任务一起进行，其意义在于对知识的可信度量化，保留置信度较高的，舍弃置信度较低的，确保知识的质量。</p>
</li>
<li><p>知识更新</p>
<p>随着知识储备和业务需求的不断递增，知识图谱的内容需要与时俱进，不断迭代更新，扩展现有的知识，增加新的知识。</p>
<p>根据知识图谱的逻辑结构，更新主要包括：模式（本体）层的更新和数据层的更新</p>
<ul>
<li><p>模式层的更新</p>
<p>本体元素的更新，包括：概念的增、删、改，概念属性的更新以及概念的上下位关系的更新等。</p>
</li>
<li><p>数据层的更新</p>
</li>
</ul>
</li>
</ol>
<h5 id="3-4-知识推理"><a href="#3-4-知识推理" class="headerlink" title="3.4 知识推理"></a>3.4 知识推理</h5><p>​    对于推理规则的挖掘，主要还是依赖于实体及实体关系间的丰富同现情况，知识推理的对象可以是实体、关系、属性、本体库中的概念的层次结构等。</p>
<ol>
<li><p>基于逻辑的推理</p>
<ul>
<li>一阶谓词逻辑推理：以命题为基本进行推理，命题包含个体和谓词。逻辑中的个体对应实体，谓词对应关系或个体的属性。</li>
<li>描述逻辑：在命题逻辑之上发展而来，追求表示能力与推理复杂度之间的平衡。</li>
</ul>
</li>
<li><p>基于图的推理</p>
<p>利用关系路劲中的蕴含信息，通过图中两个实体间的多步路劲来预测他们之间的语义关系。</p>
</li>
<li><p>时序预测推理</p>
</li>
<li><p>基于强化学习的知识图谱推理</p>
</li>
<li><p>开源的知识推理工具</p>
<ul>
<li>jena：开源支持语义网络和数据链接应用的java框架。</li>
<li>drools：基于Charles Forgy 的RETE算法的规则引擎的java实现。</li>
</ul>
</li>
</ol>
<h4 id="4-典型应用"><a href="#4-典型应用" class="headerlink" title="4. 典型应用"></a>4. 典型应用</h4><p>​    知识图谱为互联网上海量、异构、动态的大数据表达、组织、管理以及利用提供了一种更为有效的方式，使得网络的智能化水平更高，更加接近人类的认知思维。</p>
<h5 id="4-1-智能搜索"><a href="#4-1-智能搜索" class="headerlink" title="4.1 智能搜索"></a>4.1 智能搜索</h5><p>​    基于知识图谱的智能搜索是一种基于长尾的搜索，并将结果以知识卡片的形式展示出来（参考google）。查询请求主要经过两个阶段：查询式语义理解和知识检索。</p>
<ol>
<li><p>语义理解</p>
<p>语义分析主要包含以下阶段。</p>
<ul>
<li>查询文本预处理：分词、词性标注、文本纠错</li>
<li>描述归一化：与知识库中的相关知识匹配</li>
<li>语境分析：不同语境（上下文），查询对象有所差别，因此知识图谱需要结合用户当时的情感，给出相应的反馈。</li>
<li>查询扩展：明确查询意图及相关概念之后，需要加入当前语境下的相关概念进行扩展。</li>
</ul>
</li>
<li><p>知识检索</p>
<p>经过查询式分析后的标准查询语句进入知识库检索引擎，引擎会在知识库中检索相应的实体及其相关属性、关系，通过对知识库的深层挖掘和提炼后，引擎给出具有重要性排序的知识体系。</p>
</li>
<li><p>常见的基于知识图谱的搜索引擎</p>
<ul>
<li>国外： Google Search、微软的Bing Search。</li>
<li>国内：搜狗的知立方、百度的知心。</li>
</ul>
</li>
</ol>
<h5 id="4-2-智能问答"><a href="#4-2-智能问答" class="headerlink" title="4.2 智能问答"></a>4.2 智能问答</h5><p>​    问答系统是信息检索系统的一种高级形式，能 够以准确简洁的自然语言为用户提供问题的解答。之所以说问答是一种高级形式的检索，是因为在问答系统中同样有查询式理解与知识检索这两个重要的过程，并且与智能搜索中相应过程中的相关细节是完全一致的。多数问答系统更倾向于将给定的问 题分解为多个小的问题，然后逐一去知识库中抽取 匹配的答案，并自动检测其在时间与空间上的吻合 度等，最后将答案进行合并，以直观的方式展现给用户。</p>
<p>​    目前，常见基于知识图谱的问答平台有</p>
<ul>
<li>国外：华盛顿大学的Paralex系统、苹果公司的Siri、亚马逊的Evi。</li>
<li>国内：百度机器人小度、聚问网络的在线问答系统OASK。</li>
</ul>
<h5 id="4-3-垂直行业的应用"><a href="#4-3-垂直行业的应用" class="headerlink" title="4.3 垂直行业的应用"></a>4.3 垂直行业的应用</h5><ul>
<li>金融： 识别反欺诈、定制化销售策略。</li>
<li>医疗：疾病图谱、中医图谱。</li>
<li>电商：商品展示</li>
</ul>
<p>​      </p>
<p>​      </p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  


  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/"><i class="fa fa-angle-left" aria-label="上一页"></i></a><a class="page-number" href="/">1</a><span class="page-number current">2</span>
  </nav>



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">sunshine</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/%E5%BD%92%E6%A1%A3/">
        
          <span class="site-state-item-count">20</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
        <span class="site-state-item-count">1</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
        <span class="site-state-item-count">4</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2021</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">sunshine</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://muse.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Muse</a> 强力驱动
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="//cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js"></script>
  <script src="//cdn.jsdelivr.net/gh/fancyapps/fancybox@3/dist/jquery.fancybox.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/muse.js"></script>


<script src="/js/next-boot.js"></script>




  















  

  
      

<script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      loader: {
          load: ['[tex]/mhchem'],
        source: {
          '[tex]/amsCd': '[tex]/amscd',
          '[tex]/AMScd': '[tex]/amscd'
        }
      },
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
          packages: {'[+]': ['mhchem']},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              let target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    (function () {
      var script = document.createElement('script');
      script.src = '//cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js';
      script.defer = true;
      document.head.appendChild(script);
    })();
  } else {
    MathJax.startup.document.state(0);
    MathJax.texReset();
    MathJax.typeset();
  }
</script>

    

  

</body>
</html>
